# Step1 工具配置（示例）
[postgres]
dsn = "postgresql://logbook_svc:***@<server-ip>:5432/proj_a"

# 管理员 DSN（可选，用于自动创建数据库）
# 当目标数据库不存在时，使用此 DSN 连接 PostgreSQL 服务器创建数据库
# 通常连接到 postgres 或 template1 系统数据库
# 也可通过环境变量 ENGRAM_PG_ADMIN_DSN 注入
# admin_dsn = "postgresql://postgres:***@<server-ip>:5432/postgres"

# search_path 配置（可选）
# 用于多租户/测试隔离场景，设置数据库连接的 search_path
# 支持两种格式：
#   1. 字符串（逗号分隔）: "logbook, scm, public"
#   2. 列表: ["logbook", "scm", "public"]
# 如果不包含 public，将自动追加 public 作为兜底
# search_path = "logbook, scm, identity, analysis, governance"

[project]
# 项目标识（用于 SCM 路径规范中的 <project_key> 层级）
# 新版 SCM 路径格式: scm/<project_key>/<repo_id>/<source_type>/<rev_or_sha>/<sha256>.<ext>
project_key = "proj_a"

# ---------------------------------------------------------------------------
# 制品存储配置
# ---------------------------------------------------------------------------
[artifacts]
# 后端类型: local | file | object
# - local: 本地文件系统（默认），使用 root 指定目录
# - file: file:// URI 直读写，适用于 NFS/SMB 共享
# - object: 对象存储（S3/MinIO 兼容）
backend = "local"

# local 后端: 制品根目录
# 支持相对路径或绝对路径
# Windows: 'C:\artifacts' 或 '\\fileserver\artifacts\proj_a'
# Linux: '/mnt/artifacts' 或相对路径 './.agentx/artifacts'
root = "./.agentx/artifacts"

# local 后端: 允许的路径前缀（可选，安全策略）
# - 不设置或为空：允许所有路径（默认宽松模式，适合开发环境）
# - 设置为列表：只允许匹配前缀的路径（适合团队/生产部署收紧访问范围）
# 
# 示例：只允许 SCM、附件和导出目录
# allowed_prefixes = ["scm/", "attachments/", "exports/"]
#
# 安全说明：
# - 无论是否设置此选项，系统都会自动防止路径穿越攻击（../ 等）
# - 此选项用于进一步限制可访问的目录范围
# allowed_prefixes = []

# ---------------------------------------------------------------------------
# 制品存储策略配置
# 控制路径限制、覆盖策略、大小限制等安全与行为策略
# ---------------------------------------------------------------------------
[artifacts.policy]

# 文件权限模式（八进制，如 0644 表示 rw-r--r--）
# 不设置则使用系统 umask 决定
# file_mode = 0644

# 目录权限模式（八进制，如 0755 表示 rwxr-xr-x）
# 不设置则使用系统 umask 决定
# dir_mode = 0755

# 覆盖策略：控制当目标文件已存在时的行为
# - "allow": 允许覆盖（默认）
# - "deny": 禁止覆盖，文件存在时报错
# - "allow_same_hash": 仅允许相同内容覆盖（内容哈希必须匹配）
#
# 使用场景：
# - allow: 适合开发环境，允许重复执行
# - deny: 适合生产环境，防止意外覆盖历史数据
# - allow_same_hash: 适合幂等操作，允许重试但防止数据篡改
overwrite_policy = "allow"

# 最大制品大小限制（字节）
# 0 = 无限制（默认）
# 适用于所有后端（local/file/object）
# 示例: 104857600 = 100MB, 1073741824 = 1GB
max_size_bytes = 0

# 路径最大长度限制（字节）
# 超过此长度的路径将被拒绝
# 默认 4096，适配多数文件系统限制
# max_path_length = 4096

# ---------------------------------------------------------------------------
# file 后端配置（file:// URI 直读写）
# ---------------------------------------------------------------------------
[artifacts.file]

# 允许读写的根路径列表（安全策略）
# - 不设置：允许所有路径（默认，适合开发环境）
# - 空列表 []：拒绝所有路径
# - 设置为列表：只允许在这些根路径下读写
#
# 示例（Linux/macOS NFS 挂载点）：
# allowed_roots = ["/mnt/nfs/artifacts", "/mnt/shared/exports"]
#
# 示例（Windows UNC 路径）：
# allowed_roots = ["\\\\fileserver\\artifacts", "\\\\nas\\shared"]
# 
# 或使用 file:// URI 格式：
# allowed_roots = ["file:///mnt/nfs/artifacts", "file://fileserver/shared"]
#
# 安全说明：
# - 系统会自动防止路径穿越攻击（../ 等）
# - 此选项限制 file:// 后端可访问的根目录范围
# allowed_roots = []

# 是否使用原子写入（临时文件 + rename）
# - false（默认）：直接写入目标文件
# - true：先写入临时文件，再原子重命名
#
# 原子写入兼容性说明：
# - 本地文件系统：完全支持，推荐启用
# - NFS v3：不保证跨目录原子性，同目录通常可行
# - NFS v4：通常支持，建议测试验证
# - SMB/CIFS：Windows 原生支持，Linux 挂载取决于 mount 选项
# - 注意：如果原子写入失败，系统会自动回退到直接写入
# use_atomic_write = false

# ---------------------------------------------------------------------------
# file 后端迁移工具使用说明
# ---------------------------------------------------------------------------
# artifact_migrate.py 支持 file 后端作为迁移源或目标。
#
# 迁移示例：
#   # file:// 到 local 迁移
#   python artifact_migrate.py --source-backend file --target-backend local \
#     --source-uri-root /mnt/nfs/artifacts --prefix scm/ --target-root /local/artifacts
#
#   # file:// 到 file:// 迁移（跨 NFS 共享）
#   python artifact_migrate.py --source-backend file --target-backend file \
#     --source-uri-root /mnt/nfs1/artifacts --target-uri-root /mnt/nfs2/artifacts \
#     --prefix scm/ --execute
#
#   # file:// 到 object 迁移
#   python artifact_migrate.py --source-backend file --target-backend object \
#     --source-uri-root /mnt/nfs/artifacts --prefix scm/ --execute
#
# 参数说明：
#   --source-uri-root: file 后端的源 allowed_roots（可多次指定）
#   --target-uri-root: file 后端的目标 allowed_roots（可多次指定）
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# 对象存储配置（object 后端）
# ---------------------------------------------------------------------------
# 【重要】敏感凭证必须通过环境变量注入，禁止明文写入配置文件！
#
# 环境变量配置（必须）：
#   ENGRAM_S3_ENDPOINT     S3/MinIO 端点 URL（开发: http://minio:9000，生产: https://minio:9000）
#   ENGRAM_S3_ACCESS_KEY   访问密钥（禁止写入配置文件，生产应使用应用用户而非 root）
#   ENGRAM_S3_SECRET_KEY   密钥（禁止写入配置文件）
#   ENGRAM_S3_BUCKET       存储桶名称
#   ENGRAM_S3_VERIFY_SSL   SSL 证书验证（生产 true，开发自签名证书可设 false）
#
# 安全建议（生产环境）：
#   1. 使用 HTTPS endpoint（MINIO_FORCE_HTTPS=true）
#   2. 配置独立应用用户（MINIO_APP_USER），避免使用 root
#   3. 应用用户仅授予指定前缀的最小权限
#   4. Bucket 强制设为 private（minio_init 自动处理）
#
[artifacts.object]

# prefix: 对象键前缀（可选，非敏感）
# 用于在同一 bucket 中隔离不同项目/环境的制品
# 示例: "proj_a/artifacts" -> s3://bucket/proj_a/artifacts/scm/...
prefix = ""

# region: 存储区域（非敏感，可在配置文件中设置）
region = "us-east-1"

# sse: 服务端加密类型
# 可选值: "AES256" (S3 托管密钥) | "aws:kms" (KMS 密钥)
# 不设置表示不启用服务端加密
# sse = "AES256"

# storage_class: 存储类别
# 可选值: STANDARD | STANDARD_IA | ONEZONE_IA | GLACIER | DEEP_ARCHIVE | INTELLIGENT_TIERING
# 默认使用 S3 的默认存储类别 (通常是 STANDARD)
# storage_class = "STANDARD"

# acl: 访问控制列表策略
# 可选值: private | public-read | public-read-write | authenticated-read | aws-exec-read | bucket-owner-read | bucket-owner-full-control
# 默认为 private
# acl = "private"

# connect_timeout: 连接超时秒数
# 建立 TCP 连接的最大等待时间
connect_timeout = 10.0

# read_timeout: 读取超时秒数
# 读取响应数据的最大等待时间，大文件下载时可能需要增大此值
read_timeout = 60.0

# retries: 最大重试次数
# 请求失败时的自动重试次数，使用指数退避策略
retries = 3

# verify_ssl: SSL 证书验证
# - true（默认）：验证服务器证书（生产环境必须）
# - false：跳过证书验证（仅用于开发环境自签名证书）
# 
# 【安全提示】verify_ssl=true 时不允许使用 http:// 端点
# 如需使用 http://（如开发环境 MinIO），必须设置 verify_ssl=false
# verify_ssl = true

# ca_bundle: 自定义 CA 证书包路径（可选）
# 当使用自签名 CA 时，指定 CA 证书路径以验证服务器证书
# 设置后优先使用此证书进行验证（即使 verify_ssl=false）
#
# 示例：
# ca_bundle = "/etc/ssl/certs/my-ca.pem"
# ca_bundle = "C:\\certs\\my-ca.pem"  # Windows
#
# 也可通过环境变量 ENGRAM_S3_CA_BUNDLE 注入
# ca_bundle = ""

# multipart_threshold: Multipart 上传阈值（字节）
# 超过此大小的文件将使用分片上传，边读边算 sha256
# 默认 5MB (S3 multipart 最小分片大小)
multipart_threshold = 5242880

# multipart_chunk_size: Multipart 分片大小（字节）
# 每个分片的大小，建议 8MB 以获得较好的上传性能
multipart_chunk_size = 8388608

# ---------------------------------------------------------------------------
# Artifact Key 与 Physical URI 规范
# ---------------------------------------------------------------------------
# 
# Step1 在数据库中存储制品引用时，区分两类 URI：
#
# 1. Artifact Key（逻辑键）- **DB 默认格式**
#    格式：无 scheme 的相对路径，如 "scm/proj_a/1/svn/r100/abc123.diff"
#    优点：与物理存储解耦，后端切换（local → object）无需修改 DB
#    存储位置：patch_blobs.uri、attachments.uri 等字段
#
# 2. Physical URI（物理地址）- **特例输入，需谨慎使用**
#    格式：带 scheme 的完整路径，如 "s3://bucket/key" 或 "file:///path"
#    风险：绑定特定后端，后端切换时需迁移所有记录
#    处理：使用 artifact_migrate.py --update-db 批量转换为 artifact key
#
# 【最佳实践】
# - 生产环境始终使用 artifact key 格式存储
# - 仅在外部系统集成时允许 physical uri 输入
# - 迁移前使用 --dry-run 验证，迁移后校验记录数一致性
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# 生命周期规则 (ILM) 配置
# 用于自动清理过期对象，减少存储成本
# ---------------------------------------------------------------------------
# 
# MinIO/S3 生命周期规则通过对象存储服务配置，非应用层配置。
# 以下为推荐的默认规则（可通过 mc ilm 或 AWS S3 API 应用）：
#
#   前缀            过期天数    说明
#   tmp/            7          临时文件（处理中间产物）
#   exports/        90         导出文件（备份、报表等）
#   .trash/         30         软删除回收站
#   (全局)          1 天       未完成的 multipart upload 清理
#
# 应用方式 (MinIO):
#   mc ilm import ALIAS/BUCKET < templates/s3_lifecycle_policy.json
#
# 应用方式 (AWS S3):
#   aws s3api put-bucket-lifecycle-configuration \
#     --bucket BUCKET_NAME \
#     --lifecycle-configuration file://templates/s3_lifecycle_policy.json
#
# 参考模板: templates/s3_lifecycle_policy.json
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# S3 安全加固配置（生产环境强烈建议）
# ---------------------------------------------------------------------------
#
# 1. 启用 Bucket Versioning（防止误删除，支持版本恢复）
#    mc version enable ALIAS/BUCKET
#    aws s3api put-bucket-versioning --bucket BUCKET --versioning-configuration Status=Enabled
#
# 2. 可选：启用 Object Lock（防止删除，需创建 Bucket 时启用）
#    mc mb --with-lock ALIAS/BUCKET
#    aws s3api create-bucket --bucket BUCKET --object-lock-enabled-for-bucket
#
# 3. artifact_gc.py 生产建议参数：
#    - 始终使用 --trash-prefix .trash/ 进行软删除
#    - 使用 --require-trash 强制禁止硬删除
#    - 硬删除需显式 --force-hard-delete 确认
#
#    示例：
#    python artifact_gc.py --prefix scm/ --trash-prefix .trash/ --delete
#    python artifact_gc.py --prefix scm/ --require-trash --delete  # 报错，缺少 --trash-prefix
#
# 详细配置脚本: scripts/ops/s3_hardening.sh
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# 旧版对象存储配置（向后兼容，建议迁移到 [artifacts.object]）
# ---------------------------------------------------------------------------
# 以下配置项与 [artifacts.object] 等价，新配置建议使用 [artifacts.object] 节
# object_endpoint = ""        -> 使用环境变量 ENGRAM_S3_ENDPOINT
# object_bucket = ""          -> 使用环境变量 ENGRAM_S3_BUCKET
# object_region = "us-east-1" -> [artifacts.object].region
# object_prefix = ""          -> [artifacts.object].prefix
# object_sse = "AES256"       -> [artifacts.object].sse
# object_storage_class = ""   -> [artifacts.object].storage_class
# object_acl = "private"      -> [artifacts.object].acl
# object_connect_timeout      -> [artifacts.object].connect_timeout
# object_read_timeout         -> [artifacts.object].read_timeout
# object_retries              -> [artifacts.object].retries
# object_max_size_bytes       -> [artifacts.policy].max_size_bytes
# object_multipart_threshold  -> [artifacts.object].multipart_threshold
# object_multipart_chunk_size -> [artifacts.object].multipart_chunk_size

# ---------------------------------------------------------------------------
# 制品存储环境变量说明
# ---------------------------------------------------------------------------
# 环境变量优先级高于配置文件，用于凭证注入：
#
# 通用:
#   ENGRAM_ARTIFACTS_BACKEND   覆盖 backend 配置
#   ENGRAM_ARTIFACTS_ROOT      覆盖 root 配置 (local 后端)
#
# 对象存储 (object 后端) - 【敏感项必须使用环境变量】:
#   ENGRAM_S3_ENDPOINT         S3/MinIO 端点 URL
#   ENGRAM_S3_ACCESS_KEY       访问密钥【禁止明文写入配置文件】
#   ENGRAM_S3_SECRET_KEY       密钥【禁止明文写入配置文件】
#   ENGRAM_S3_BUCKET           存储桶名称
#   ENGRAM_S3_REGION           区域（默认 us-east-1）
#   ENGRAM_S3_PREFIX           对象键前缀（可选）
#   ENGRAM_S3_VERIFY_SSL       SSL 证书验证（true/false，默认 true）
#   ENGRAM_S3_CA_BUNDLE        自定义 CA 证书路径（可选）
#
# 示例 (bash):
#   export ENGRAM_ARTIFACTS_BACKEND=object
#   export ENGRAM_S3_ENDPOINT=https://minio.example.com
#   export ENGRAM_S3_ACCESS_KEY=minioadmin      # 敏感！禁止写入配置文件
#   export ENGRAM_S3_SECRET_KEY=minioadmin      # 敏感！禁止写入配置文件
#   export ENGRAM_S3_BUCKET=artifacts
#
# 示例 (PowerShell):
#   $env:ENGRAM_ARTIFACTS_BACKEND = "object"
#   $env:ENGRAM_S3_ENDPOINT = "https://minio.example.com"
#   $env:ENGRAM_S3_ACCESS_KEY = "minioadmin"    # 敏感！禁止写入配置文件
#   $env:ENGRAM_S3_SECRET_KEY = "minioadmin"    # 敏感！禁止写入配置文件
#   $env:ENGRAM_S3_BUCKET = "artifacts"
# ---------------------------------------------------------------------------

# ---------------------------------------------------------------------------
# SCM 路径规范配置
# 新版制品路径格式: scm/<project_key>/<repo_id>/<source_type>/<rev_or_sha>/<sha256>.<ext>
# ---------------------------------------------------------------------------
[scm.paths]
# 是否启用旧版路径回退读取（向后兼容）
# 当新版路径不存在时，自动尝试读取旧版路径格式
# 旧版 SVN: scm/<repo_id>/svn/r<rev>.<ext>
# 旧版 Git: scm/<repo_id>/git/commits/<sha>.<ext>
legacy_fallback = true

# ---------------------------------------------------------------------------
# SCM (Source Control Management) 配置
# 用于配置版本控制系统的连接参数和同步策略
# 
# 【向后兼容说明】
# 新版本使用 [scm.gitlab.*] 和 [scm.svn.*] 作为统一配置键名。
# 旧版本的 [gitlab.*] 和 [svn.*] 配置仍然有效，系统会自动回退读取。
# 建议逐步迁移到新的配置格式。
# 
# 键名映射关系：
#   scm.gitlab.url         <- 回退 gitlab.url
#   scm.gitlab.project     <- 回退 gitlab.project_id
#   scm.gitlab.token       <- 回退 gitlab.private_token
#   scm.gitlab.default_branch <- 回退 gitlab.ref_name
#   scm.svn.url            <- 回退 svn.url
#   scm.svn.batch_size     <- 回退 svn.batch_size
#   scm.svn.overlap        <- 回退 svn.overlap
# ---------------------------------------------------------------------------
[scm]
# 默认 SCM 类型: "svn" | "git" | "gitlab"
default_type = "gitlab"

# ---------------------------------------------------------------------------
# SVN 配置（推荐使用 [scm.svn]）
# ---------------------------------------------------------------------------
[scm.svn]
# SVN 仓库 URL
url = "https://svn.example.com/repos/project"

# SVN 用户名（可选，也可通过环境变量 SVN_USERNAME 注入）
username = ""

# SVN 密码（建议通过环境变量 SVN_PASSWORD 注入，避免明文存储）
# password = ""  # 请使用环境变量 SVN_PASSWORD

# 每次同步的最大 revision 数
batch_size = 100

# 重叠 revision 数（用于确保不遗漏）
overlap = 0

# ---------------------------------------------------------------------------
# GitLab 配置（推荐使用 [scm.gitlab]）
# ---------------------------------------------------------------------------
[scm.gitlab]
# GitLab 服务器 URL
url = "https://gitlab.example.com"

# GitLab 项目 ID 或路径（如 "group/project"）
project = "group/project"

# GitLab 访问令牌（敏感信息，请通过环境变量注入）
# token = ""  # 请使用环境变量 GITLAB_TOKEN
# 
# 环境变量注入方式：
#   export GITLAB_TOKEN="glpat-xxxxxxxxxxxxxxxxxxxx"
# 
# 也可在 CI/CD 中配置为 Secret Variable

# 默认分支
default_branch = "main"

# 每次同步的最大 commit/MR 数
batch_size = 100

# 请求超时时间（秒）
request_timeout = 60

# ---------------------------------------------------------------------------
# SCM Bulk Commit 阈值配置
# 用于判断 commit 是否为 bulk commit，bulk commit 将使用 diffstat 格式存储
# ---------------------------------------------------------------------------
[scm.bulk_thresholds]
# SVN: changed_paths 数量阈值（超过此数量判定为 bulk）
svn_changed_paths = 100

# Git/GitLab: 变更行数阈值（additions + deletions 超过此数量判定为 bulk）
git_total_changes = 1000

# Git/GitLab: 变更文件数阈值（超过此数量判定为 bulk）
git_files_changed = 50

# 通用: diff 大小阈值（bytes，超过此大小判定为 bulk）
diff_size_bytes = 1048576  # 1MB

# ---------------------------------------------------------------------------
# 增量同步配置
# ---------------------------------------------------------------------------
[scm.incremental]
# 是否启用增量同步（仅同步上次同步后的新提交）
enabled = true

# 每次同步的最大 commit 数量（避免单次同步过多）
batch_size = 100

# 同步时间窗口（天），仅同步最近 N 天的提交（0 表示不限制）
time_window_days = 0

# 失败重试次数
retry_count = 3

# 重试间隔（秒）
retry_interval = 5

# ---------------------------------------------------------------------------
# SCM Sync at Scale 配置
# 用于大规模、高频、分布式场景的同步控制
# ---------------------------------------------------------------------------
[scm.sync]

# 并行同步仓库数（多仓库并行，单仓库内串行）
# - 1: 串行模式，适合调试
# - 4-8: 推荐生产配置
parallelism = 4

# 同步间隔（秒），0 表示手动触发
# 定时任务建议使用外部调度器（如 cron）而非此配置
interval_seconds = 0

# 默认 overlap 值（重叠拉取记录数，用于补偿边界遗漏）
# - 0: 无重叠，效率最高
# - 10-50: 故障恢复后建议临时增大
default_overlap = 0

# 同步模式
# - strict: 遇到错误立即中止，不更新 cursor（适合审计场景）
# - best_effort: 记录错误并跳过，继续处理后续数据（适合日常同步）
mode = "strict"

# 分布式锁超时（秒），防止同一仓库并发同步
lock_timeout = 300

# ---------------------------------------------------------------------------
# Cursor/Watermark 存储配置
# Cursor 存储于 logbook.kv 表，格式: scm.sync/<source_type>_cursor:<repo_id>
# ---------------------------------------------------------------------------
[scm.sync.cursor]

# Cursor 命名空间（logbook.kv 的 namespace）
namespace = "scm.sync"

# Cursor 键名模板，支持变量: {source_type}, {repo_id}
# 示例: svn_cursor:1, gitlab_cursor:2
key_template = "{source_type}_cursor:{repo_id}"

# ---------------------------------------------------------------------------
# Run ID 配置
# Run ID 用于标识每次同步运行，便于追溯和审计
# ---------------------------------------------------------------------------
[scm.sync.run]

# Run ID 前缀
prefix = "sync"

# Run ID 格式: {prefix}-{date}-{seq}
# 示例: sync-20240115-001
# date 格式为 YYYYMMDD，seq 为当日序号

# 运行记录保留天数（存储于 analysis.runs）
history_days = 90

# 是否记录详细运行日志到 analysis.runs
log_to_db = true

# ===========================================================================
# 【已弃用配置 - DEPRECATED】
# 以下配置键已弃用，仅用于向后兼容。请尽快迁移到新的配置格式。
# ===========================================================================

# ---------------------------------------------------------------------------
# 已弃用: [paths] - 请迁移到 [artifacts]
# ---------------------------------------------------------------------------
# 迁移方法:
#   旧: [paths].artifacts_root = "./.agentx/artifacts"
#   新: [artifacts].root = "./.agentx/artifacts"
# ---------------------------------------------------------------------------
[paths]
artifacts_root = "./.agentx/artifacts"  # 【已弃用】请使用 [artifacts].root

# ---------------------------------------------------------------------------
# 已弃用: [bulk] - 请迁移到 [scm.bulk_thresholds]
# ---------------------------------------------------------------------------
# 迁移方法:
#   旧键名                         ->  新键名
#   bulk.svn_changed_paths_threshold   ->  scm.bulk_thresholds.svn_changed_paths
#   bulk.git_total_changes_threshold   ->  scm.bulk_thresholds.git_total_changes
#   bulk.git_files_changed_threshold   ->  scm.bulk_thresholds.git_files_changed
#   bulk.diff_size_threshold           ->  scm.bulk_thresholds.diff_size_bytes
# ---------------------------------------------------------------------------
[bulk]
svn_changed_paths_threshold = 100   # 【已弃用】请使用 scm.bulk_thresholds.svn_changed_paths
git_total_changes_threshold = 1000  # 【已弃用】请使用 scm.bulk_thresholds.git_total_changes
git_files_changed_threshold = 50    # 【已弃用】请使用 scm.bulk_thresholds.git_files_changed
diff_size_threshold = 1048576       # 【已弃用】请使用 scm.bulk_thresholds.diff_size_bytes

# ---------------------------------------------------------------------------
# 已弃用: [gitlab] - 请迁移到 [scm.gitlab]
# ---------------------------------------------------------------------------
# 迁移方法:
#   旧键名                 ->  新键名
#   gitlab.url                 ->  scm.gitlab.url
#   gitlab.project_id          ->  scm.gitlab.project
#   gitlab.private_token       ->  scm.gitlab.token (建议使用环境变量 GITLAB_TOKEN)
#   gitlab.ref_name            ->  scm.gitlab.default_branch
#   gitlab.batch_size          ->  scm.gitlab.batch_size
#   gitlab.request_timeout     ->  scm.gitlab.request_timeout
# ---------------------------------------------------------------------------
# [gitlab]
# url = "https://gitlab.example.com"
# project_id = "group/project"
# private_token = ""   # 【已弃用】请使用环境变量 GITLAB_TOKEN
# ref_name = "main"
# batch_size = 100
# request_timeout = 60

# ---------------------------------------------------------------------------
# 已弃用: [svn] - 请迁移到 [scm.svn]
# ---------------------------------------------------------------------------
# 迁移方法:
#   旧键名         ->  新键名
#   svn.url            ->  scm.svn.url
#   svn.username       ->  scm.svn.username
#   svn.batch_size     ->  scm.svn.batch_size
#   svn.overlap        ->  scm.svn.overlap
# ---------------------------------------------------------------------------
# [svn]
# url = "https://svn.example.com/repos/project"
# username = ""
# batch_size = 100
# overlap = 0

# ===========================================================================
# MinIO 运维配置说明（Docker Compose 环境变量）
# ===========================================================================
# 以下配置通过 docker-compose.unified.yml 的环境变量管理，非本配置文件。
# 此处仅作参考说明。
#
# ---------------------------------------------------------------------------
# 基础配置
# ---------------------------------------------------------------------------
# MINIO_ROOT_USER           MinIO root 用户名（必须）
# MINIO_ROOT_PASSWORD       MinIO root 密码（必须）
# MINIO_BUCKET              存储桶名称（默认: engram）
#
# ---------------------------------------------------------------------------
# 应用用户配置（最小权限隔离，生产环境强烈建议）
# ---------------------------------------------------------------------------
# MINIO_APP_USER            应用用户名（可选，不设置则跳过创建）
# MINIO_APP_PASSWORD        应用用户密码
# MINIO_ALLOWED_PREFIXES    允许访问的前缀列表，逗号分隔
#                           默认: scm/,attachments/,exports/,tmp/
#
# Policy 模板: scripts/ops/minio_bucket_policy.json
#
# ---------------------------------------------------------------------------
# HTTPS/TLS 配置（生产环境强制）
# ---------------------------------------------------------------------------
# MINIO_FORCE_HTTPS         是否强制 HTTPS（默认: false）
# MINIO_CERTS_PATH          证书目录路径（挂载到容器 /certs）
#                           需包含: public.crt 和 private.key
# ENGRAM_S3_VERIFY_SSL      客户端 SSL 验证（生产: true，开发自签名: false）
#
# 启用 HTTPS 步骤:
#   1. 设置 MINIO_FORCE_HTTPS=true
#   2. 取消 docker-compose.yml 中证书挂载的注释
#   3. 将证书放入 MINIO_CERTS_PATH 目录
#   4. 设置 ENGRAM_S3_ENDPOINT=https://minio:9000
#
# ---------------------------------------------------------------------------
# 审计日志配置（可选，不默认启用）
# ---------------------------------------------------------------------------
# MINIO_AUDIT_WEBHOOK_ENDPOINT    Audit Webhook 端点 URL
# MINIO_AUDIT_WEBHOOK_AUTH_TOKEN  Webhook 认证令牌
#
# 配置模板: scripts/ops/minio_audit_webhook.json
# 支持的日志出口:
#   - Webhook（HTTP/HTTPS POST）
#   - Kafka（需额外配置，参考模板中 _alternative_kafka 节）
#   - Logger Webhook（MinIO 内部日志，区别于审计日志）
#
# 手动配置方式（不通过环境变量）:
#   mc admin config set myminio audit_webhook:engram \
#     endpoint='https://logs.example.com/minio' \
#     auth_token='xxx'
#   mc admin service restart myminio
#
# ---------------------------------------------------------------------------
# Artifact URI 格式运维说明
# ---------------------------------------------------------------------------
# Step1 DB 中的 uri 字段默认存储 artifact key（无 scheme 相对路径）。
# 
# 【检查 Physical URI 残留】
#   SELECT uri FROM scm.patch_blobs WHERE uri LIKE 's3://%' OR uri LIKE 'file://%';
#   SELECT uri FROM logbook.attachments WHERE uri LIKE 's3://%' OR uri LIKE 'file://%';
#
# 【迁移 Physical URI 到 Artifact Key】
#   python artifact_migrate.py --update-db --dry-run   # 预览变更
#   python artifact_migrate.py --update-db --execute   # 执行迁移
#
# 【后端切换前检查清单】
#   1. 确认所有 uri 字段为 artifact key 格式（无 scheme 前缀）
#   2. 备份数据库
#   3. 迁移制品文件到新后端
#   4. 更新配置 artifacts.backend
#   5. 验证读取功能正常
# ===========================================================================
