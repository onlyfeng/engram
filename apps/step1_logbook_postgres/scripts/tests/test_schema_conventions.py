"""
test_schema_conventions.py - Schema å‘½åè§„èŒƒæ£€æŸ¥

æ£€æµ‹ Python ä»£ç ä¸­ SQL å­—ç¬¦ä¸²æ˜¯å¦ä½¿ç”¨äº†ç¡¬ç¼–ç çš„ schema å‰ç¼€ã€‚

è§„åˆ™ï¼š
1. SQL è¯­å¥åº”ä½¿ç”¨æ— å‰ç¼€è¡¨åï¼Œä¾èµ– search_path è§£æ
2. ä¸åº”å‡ºç° identity., logbook., scm., analysis., governance. ç­‰ç¡¬ç¼–ç å‰ç¼€
3. ä¾‹å¤–ï¼šschema é‡å†™ç›¸å…³ä»£ç ï¼ˆå¦‚ rewrite_sql_for_schemaï¼‰å…è®¸å¼•ç”¨ schema åç§°

å¤±è´¥æ—¶æä¾›ï¼š
- æ–‡ä»¶è·¯å¾„
- è¡Œå·
- åŒ¹é…å†…å®¹
- å»ºè®®ä¿®å¤æ–¹å¼
"""

import ast
import re
from pathlib import Path
from typing import List, NamedTuple, Optional, Set


class SchemaViolation(NamedTuple):
    """Schema è§„èŒƒè¿åè®°å½•"""
    file_path: str
    line_no: int
    col_offset: int
    matched_text: str
    context: str
    suggestion: str


# éœ€è¦æ£€æµ‹çš„ schema åç§°
SCHEMA_NAMES = ["identity", "logbook", "scm", "analysis", "governance"]

# åŒ¹é… schema.table æ ¼å¼çš„æ­£åˆ™è¡¨è¾¾å¼
# ä½¿ç”¨è¯è¾¹ç•Œ \b ç¡®ä¿ç²¾ç¡®åŒ¹é…ï¼Œå¦‚ scm. è€Œé mechanism.
SCHEMA_PREFIX_PATTERN = re.compile(
    r'\b(' + '|'.join(SCHEMA_NAMES) + r')\.',
    re.IGNORECASE
)

# å…è®¸åŒ…å« schema å‰ç¼€çš„ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¤–æƒ…å†µï¼‰
# è¿™äº›æ¨¡å¼ç”¨äºè¯†åˆ«åº”è·³è¿‡æ£€æŸ¥çš„å­—ç¬¦ä¸²
# æ³¨æ„ï¼šæ­¤åˆ—è¡¨ä»…åŒ…å«åˆæ³•çš„é SQL åœºæ™¯ï¼Œä¸æ³›åŒ–æ”¾è¡ŒçœŸå® SQL è¯­å¥
ALLOWED_PATTERNS = [
    # === ä»£ç ç»“æ„ç›¸å…³ï¼ˆschema é‡å†™/æ­£åˆ™å®šä¹‰ï¼‰ ===
    r'old_name',
    r'new_name',
    r'schema_map',
    r'\\b',  # æ­£åˆ™è¡¨è¾¾å¼ä¸­çš„è¯è¾¹ç•Œ
    r're\.compile',
    
    # === å…ƒæ•°æ®æŸ¥è¯¢ï¼ˆä¸æ˜¯ä¸šåŠ¡è¡¨ï¼Œè€Œæ˜¯ pg_catalog/information_schemaï¼‰ ===
    r'table_schema\s*=',
    r'schema_name\s*=',
    
    # === å¸¸é‡å®šä¹‰ ===
    r'SCHEMA_NAMES\s*=',
    r'DEFAULT_SCHEMA_NAMES',
    r'KV_NAMESPACE\s*=',
    r'NAMESPACE\s*=',
    
    # === é…ç½®é”®åï¼ˆé SQL è¡¨å¼•ç”¨ï¼‰ ===
    # å¦‚ scm.gitlab.*, scm.svn.*, scm.sync.* æ˜¯é…ç½®æ–‡ä»¶é”®å
    r'scm\.(gitlab|svn|bulk_thresholds|incremental|sync)\.',
    r'"scm\.sync\.',
    r"'scm\.sync\.",
    r'\[scm\.',  # é…ç½®èŠ‚ [scm.xxx]
    
    # === item_type å­—æ®µå€¼ï¼ˆå¦‚ "scm.sync.svn"ï¼‰ ===
    r'item_type\s*=.*scm\.',
]

# åº”è·³è¿‡æ£€æŸ¥çš„æ–‡ä»¶ï¼ˆç›¸å¯¹äº scripts/ ç›®å½•ï¼‰
SKIP_FILES: Set[str] = {
    # æµ‹è¯•æ–‡ä»¶ä¸­å¯èƒ½åŒ…å«æµ‹è¯•ç”¨ä¾‹éœ€è¦çš„ schema å‰ç¼€
    "tests/test_schema_conventions.py",  # æœ¬æµ‹è¯•æ–‡ä»¶è‡ªèº«
    "tests/test_schema_prefix_migrate.py",  # ä¸“é—¨æµ‹è¯• schema å‰ç¼€é‡å†™çš„æµ‹è¯•
    "tests/test_step1_smoke.py",  # å†’çƒŸæµ‹è¯•ä¸­éªŒè¯è¡¨ç»“æ„
    "tests/test_evidence_refs_schema.py",  # æµ‹è¯• evidence refs schema
    "tests/test_governance_settings_concurrent.py",  # governance å¹¶å‘æµ‹è¯•ä½¿ç”¨æ¨¡å—è°ƒç”¨
    # scm_integrity_check.py æ˜¯æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å·¥å…·ï¼Œéœ€è¦æ˜¾å¼å¼•ç”¨è¡¨å
    "scm_integrity_check.py",
}

# åº”è·³è¿‡çš„å‡½æ•°åï¼ˆè¿™äº›å‡½æ•°ä¸“é—¨å¤„ç† schema é‡å†™ï¼‰
SKIP_FUNCTIONS: Set[str] = {
    "rewrite_sql_for_schema",
}


def get_scripts_dir() -> Path:
    """è·å– scripts ç›®å½•è·¯å¾„"""
    return Path(__file__).parent.parent


def find_python_files(base_dir: Path) -> List[Path]:
    """
    æŸ¥æ‰¾æ‰€æœ‰ Python æ–‡ä»¶
    
    Args:
        base_dir: åŸºç¡€ç›®å½•
        
    Returns:
        Python æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    files = []
    for py_file in base_dir.rglob("*.py"):
        # è·³è¿‡ __pycache__ ç›®å½•
        if "__pycache__" in str(py_file):
            continue
        files.append(py_file)
    return sorted(files)


def get_skip_function_ranges(source: str) -> List[tuple]:
    """
    è·å–åº”è·³è¿‡çš„å‡½æ•°çš„è¡Œå·èŒƒå›´
    
    Args:
        source: æºä»£ç 
        
    Returns:
        (start_line, end_line) å…ƒç»„åˆ—è¡¨
    """
    try:
        tree = ast.parse(source)
    except SyntaxError:
        return []
    
    ranges = []
    for node in ast.walk(tree):
        if isinstance(node, ast.FunctionDef):
            if node.name in SKIP_FUNCTIONS:
                end_line = getattr(node, 'end_lineno', node.lineno + 100)
                ranges.append((node.lineno, end_line))
    return ranges


def is_in_skip_function(skip_ranges: List[tuple], line_no: int) -> bool:
    """
    æ£€æŸ¥æŒ‡å®šè¡Œæ˜¯å¦åœ¨è·³è¿‡çš„å‡½æ•°å†…
    
    Args:
        skip_ranges: è·³è¿‡å‡½æ•°çš„è¡Œå·èŒƒå›´åˆ—è¡¨
        line_no: è¡Œå·ï¼ˆ1-basedï¼‰
        
    Returns:
        æ˜¯å¦åœ¨è·³è¿‡çš„å‡½æ•°å†…
    """
    for start, end in skip_ranges:
        if start <= line_no <= end:
            return True
    return False


def is_allowed_context(line: str, full_context: str) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦ä¸ºå…è®¸çš„ä¸Šä¸‹æ–‡
    
    Args:
        line: å½“å‰è¡Œ
        full_context: å®Œæ•´ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å‰åå‡ è¡Œï¼‰
        
    Returns:
        æ˜¯å¦ä¸ºå…è®¸çš„ä¸Šä¸‹æ–‡
    """
    combined = line + " " + full_context
    for pattern in ALLOWED_PATTERNS:
        if re.search(pattern, combined, re.IGNORECASE):
            return True
    return False


def is_in_comment(line: str, match_start: int) -> bool:
    """
    æ£€æŸ¥åŒ¹é…æ˜¯å¦åœ¨æ³¨é‡Šä¸­
    
    Args:
        line: å½“å‰è¡Œ
        match_start: åŒ¹é…èµ·å§‹ä½ç½®
        
    Returns:
        æ˜¯å¦åœ¨æ³¨é‡Šä¸­
    """
    # æŸ¥æ‰¾ # çš„ä½ç½®
    hash_pos = line.find('#')
    if hash_pos != -1 and hash_pos < match_start:
        return True
    return False


def is_in_docstring_or_comment_block(source: str, line_no: int) -> bool:
    """
    æ£€æŸ¥è¡Œæ˜¯å¦åœ¨æ–‡æ¡£å­—ç¬¦ä¸²æˆ–å¤šè¡Œæ³¨é‡Šä¸­
    
    ç®€åŒ–å®ç°ï¼šæ£€æŸ¥è¡Œæ˜¯å¦ä»¥ ''' æˆ– \"\"\" åŒ…å›´
    
    Args:
        source: æºä»£ç 
        line_no: è¡Œå·ï¼ˆ1-basedï¼‰
        
    Returns:
        æ˜¯å¦åœ¨æ–‡æ¡£å­—ç¬¦ä¸²ä¸­
    """
    lines = source.split('\n')
    if line_no > len(lines):
        return False
    
    line = lines[line_no - 1]
    
    # å¦‚æœå½“å‰è¡Œæ˜¯æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆä»¥ \"\"\" å¼€å§‹æˆ–ç»“æŸï¼‰
    stripped = line.strip()
    if stripped.startswith('"""') or stripped.startswith("'''"):
        return True
    if stripped.endswith('"""') or stripped.endswith("'''"):
        return True
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å¤šè¡Œå­—ç¬¦ä¸²å†…éƒ¨ï¼ˆç®€åŒ–æ£€æµ‹ï¼‰
    in_triple_quote = False
    quote_char = None
    for i, ln in enumerate(lines[:line_no], 1):
        # è®¡ç®—ä¸‰å¼•å·çš„æ•°é‡
        for q in ['"""', "'''"]:
            count = ln.count(q)
            if count > 0:
                if not in_triple_quote:
                    in_triple_quote = True
                    quote_char = q
                elif quote_char == q:
                    if count % 2 == 1:
                        in_triple_quote = not in_triple_quote
    
    return in_triple_quote


def extract_string_content(node: ast.expr) -> Optional[str]:
    """
    ä» AST èŠ‚ç‚¹æå–å­—ç¬¦ä¸²å†…å®¹
    
    Args:
        node: AST è¡¨è¾¾å¼èŠ‚ç‚¹
        
    Returns:
        å­—ç¬¦ä¸²å†…å®¹ï¼Œéå­—ç¬¦ä¸²èŠ‚ç‚¹è¿”å› None
    """
    if isinstance(node, ast.Constant) and isinstance(node.value, str):
        return node.value
    if isinstance(node, ast.JoinedStr):
        # f-stringï¼Œæå–å¸¸é‡éƒ¨åˆ†
        parts = []
        for value in node.values:
            if isinstance(value, ast.Constant) and isinstance(value.value, str):
                parts.append(value.value)
        return ''.join(parts)
    return None


def check_file(file_path: Path) -> List[SchemaViolation]:
    """
    æ£€æŸ¥å•ä¸ªæ–‡ä»¶ä¸­çš„ schema è§„èŒƒè¿å
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        
    Returns:
        è¿åè®°å½•åˆ—è¡¨
    """
    violations = []
    
    try:
        source = file_path.read_text(encoding='utf-8')
    except Exception as e:
        return []
    
    lines = source.split('\n')
    
    # é¢„å…ˆè§£æ AST è·å–è·³è¿‡å‡½æ•°çš„èŒƒå›´
    skip_ranges = get_skip_function_ranges(source)
    
    # é€è¡Œæ‰«æ
    for line_no, line in enumerate(lines, 1):
        # è·³è¿‡è·³è¿‡å‡½æ•°å†…çš„ä»£ç 
        if is_in_skip_function(skip_ranges, line_no):
            continue
        
        # æŸ¥æ‰¾ schema å‰ç¼€
        for match in SCHEMA_PREFIX_PATTERN.finditer(line):
            # è·³è¿‡æ³¨é‡Š
            if is_in_comment(line, match.start()):
                continue
            
            # è·å–ä¸Šä¸‹æ–‡ï¼ˆå‰å 2 è¡Œï¼‰
            context_start = max(0, line_no - 3)
            context_end = min(len(lines), line_no + 2)
            context_lines = lines[context_start:context_end]
            full_context = '\n'.join(context_lines)
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå…è®¸çš„ä¸Šä¸‹æ–‡
            if is_allowed_context(line, full_context):
                continue
            
            # æå–åŒ¹é…çš„ schema åç§°
            schema_name = match.group(1).lower()
            matched_text = match.group(0)
            
            # ç¡®å®šè¦å±•ç¤ºçš„è¡Œä¸Šä¸‹æ–‡
            display_line = line.strip()
            if len(display_line) > 120:
                # æˆªå–åŒ¹é…ä½ç½®é™„è¿‘çš„å†…å®¹
                start = max(0, match.start() - 40)
                end = min(len(line), match.end() + 40)
                display_line = "..." + line[start:end].strip() + "..."
            
            # ç”Ÿæˆå»ºè®®
            suggestion = (
                f"ç§»é™¤ '{schema_name}.' å‰ç¼€ï¼Œæ”¹ç”¨æ— å‰ç¼€è¡¨åã€‚\n"
                f"  ä¾‹å¦‚: å°† '{schema_name}.table_name' æ”¹ä¸º 'table_name'\n"
                f"  åŸå› : é¡¹ç›®ä½¿ç”¨ search_path ç®¡ç† schemaï¼ŒSQL åº”ä½¿ç”¨æ— å‰ç¼€è¡¨å"
            )
            
            violations.append(SchemaViolation(
                file_path=str(file_path),
                line_no=line_no,
                col_offset=match.start(),
                matched_text=matched_text,
                context=display_line,
                suggestion=suggestion,
            ))
    
    return violations


def check_all_files() -> List[SchemaViolation]:
    """
    æ£€æŸ¥æ‰€æœ‰ Python æ–‡ä»¶
    
    Returns:
        æ‰€æœ‰è¿åè®°å½•
    """
    scripts_dir = get_scripts_dir()
    py_files = find_python_files(scripts_dir)
    
    all_violations = []
    
    for py_file in py_files:
        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        try:
            rel_path = py_file.relative_to(scripts_dir)
        except ValueError:
            rel_path = py_file
        
        # æ£€æŸ¥æ˜¯å¦åœ¨è·³è¿‡åˆ—è¡¨ä¸­
        if str(rel_path) in SKIP_FILES:
            continue
        
        violations = check_file(py_file)
        all_violations.extend(violations)
    
    return all_violations


def format_violations_report(violations: List[SchemaViolation]) -> str:
    """
    æ ¼å¼åŒ–è¿åæŠ¥å‘Š
    
    Args:
        violations: è¿åè®°å½•åˆ—è¡¨
        
    Returns:
        æ ¼å¼åŒ–çš„æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    if not violations:
        return "âœ“ æœªå‘ç° schema å‘½åè§„èŒƒè¿å"
    
    lines = [
        f"å‘ç° {len(violations)} å¤„ schema å‘½åè§„èŒƒè¿å:",
        "",
    ]
    
    # æŒ‰æ–‡ä»¶åˆ†ç»„
    by_file: dict = {}
    for v in violations:
        if v.file_path not in by_file:
            by_file[v.file_path] = []
        by_file[v.file_path].append(v)
    
    for file_path, file_violations in sorted(by_file.items()):
        lines.append(f"ğŸ“„ {file_path}")
        for v in file_violations:
            lines.append(f"  ç¬¬ {v.line_no} è¡Œ, ç¬¬ {v.col_offset} åˆ—: å‘ç° '{v.matched_text}'")
            lines.append(f"    ä¸Šä¸‹æ–‡: {v.context}")
            lines.append(f"    å»ºè®®: {v.suggestion.split(chr(10))[0]}")  # åªæ˜¾ç¤ºç¬¬ä¸€è¡Œå»ºè®®
            lines.append("")
    
    return '\n'.join(lines)


# ============ Pytest æµ‹è¯• ============

# æ˜¯å¦å¯ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆå¤±è´¥åˆ™é˜»æ­¢ CIï¼‰
# è®¾ä¸º False æ—¶ï¼Œæ£€æµ‹åˆ°è¿ååªè¾“å‡ºè­¦å‘Šï¼Œä¸å¯¼è‡´æµ‹è¯•å¤±è´¥
# è¿™å…è®¸å›¢é˜Ÿæ¸è¿›å¼ä¿®å¤ç°æœ‰ä»£ç ä¸­çš„ schema å‰ç¼€é—®é¢˜
#
# ç¯å¢ƒå˜é‡æ§åˆ¶:
#   - CI=1 æˆ– CI=true: å¯ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆCI ç¯å¢ƒé»˜è®¤ä¸¥æ ¼ï¼‰
#   - STRICT_SCHEMA_CHECK=1: æ˜¾å¼å¯ç”¨ä¸¥æ ¼æ¨¡å¼
#   - STRICT_SCHEMA_CHECK=0: æ˜¾å¼ç¦ç”¨ä¸¥æ ¼æ¨¡å¼ï¼ˆè¦†ç›– CI è®¾ç½®ï¼‰
import os

def _get_strict_mode() -> bool:
    """æ ¹æ®ç¯å¢ƒå˜é‡å†³å®šæ˜¯å¦å¯ç”¨ä¸¥æ ¼æ¨¡å¼"""
    # æ˜¾å¼è®¾ç½®ä¼˜å…ˆ
    explicit = os.environ.get("STRICT_SCHEMA_CHECK", "").lower()
    if explicit in ("1", "true", "yes"):
        return True
    if explicit in ("0", "false", "no"):
        return False
    # CI ç¯å¢ƒé»˜è®¤ä¸¥æ ¼
    ci = os.environ.get("CI", "").lower()
    if ci in ("1", "true", "yes"):
        return True
    # é»˜è®¤å®½æ¾æ¨¡å¼
    return False

STRICT_MODE = _get_strict_mode()


def test_no_hardcoded_schema_prefix():
    """
    æµ‹è¯•ï¼šä»£ç ä¸­ä¸åº”æœ‰ç¡¬ç¼–ç çš„ schema å‰ç¼€
    
    æ£€æŸ¥ step1_logbook_postgres/scripts/**/*.py ä¸­çš„ SQL å­—ç¬¦ä¸²ï¼Œ
    ç¡®ä¿ä¸ä½¿ç”¨ identity., logbook., scm., analysis., governance. ç­‰å‰ç¼€ã€‚
    
    æ³¨æ„ï¼šå½“ STRICT_MODE = False æ—¶ï¼Œä»…è¾“å‡ºè­¦å‘Šä¸å¯¼è‡´æµ‹è¯•å¤±è´¥ã€‚
    ä¿®å¤æ‰€æœ‰é—®é¢˜åå¯ä»¥å¯ç”¨ STRICT_MODE æ¥é˜²æ­¢å›å½’ã€‚
    """
    violations = check_all_files()
    
    if violations:
        report = format_violations_report(violations)
        # æ„å»ºè¯¦ç»†çš„é”™è¯¯æ¶ˆæ¯
        error_msg = [
            "",
            "=" * 70,
            "Schema å‘½åè§„èŒƒæ£€æŸ¥" + ("å¤±è´¥" if STRICT_MODE else "è­¦å‘Š"),
            "=" * 70,
            "",
            report,
            "",
            "=" * 70,
            "ä¿®å¤æŒ‡å—:",
            "1. SQL è¯­å¥åº”ä½¿ç”¨æ— å‰ç¼€è¡¨åï¼Œä¾èµ– search_path è§£æ",
            "2. ä¾‹å¦‚: 'SELECT * FROM items' è€Œé 'SELECT * FROM logbook.items'",
            "3. å¦‚æœç¡®å®éœ€è¦ schema å‰ç¼€ï¼ˆå¦‚åŠ¨æ€é‡å†™ï¼‰ï¼Œè¯·å°†å‡½æ•°æ·»åŠ åˆ° SKIP_FUNCTIONS",
            "4. æˆ–å°†æ–‡ä»¶æ·»åŠ åˆ° SKIP_FILESï¼ˆå¦‚æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å·¥å…·ï¼‰",
            "=" * 70,
        ]
        
        # æ˜¾ç¤ºå‰ 10 ä¸ªè¿åçš„è¯¦ç»†ä¿¡æ¯
        for v in violations[:10]:
            error_msg.append(f"\n{v.file_path}:{v.line_no}:{v.col_offset}")
            error_msg.append(f"  å‘ç°: {v.matched_text}")
            error_msg.append(f"  {v.suggestion}")
        
        if len(violations) > 10:
            error_msg.append(f"\n... è¿˜æœ‰ {len(violations) - 10} å¤„è¿åï¼Œè¯¦è§å®Œæ•´æŠ¥å‘Š")
        
        full_msg = '\n'.join(error_msg)
        
        if STRICT_MODE:
            raise AssertionError(full_msg)
        else:
            # éä¸¥æ ¼æ¨¡å¼ï¼šè¾“å‡ºè­¦å‘Šä½†ä¸å¤±è´¥
            import warnings
            warnings.warn(f"\n{full_msg}\n\næç¤º: è®¾ç½® STRICT_MODE = True ä»¥åœ¨ CI ä¸­å¼ºåˆ¶æ£€æŸ¥", stacklevel=2)


def test_schema_check_utility():
    """
    æµ‹è¯•ï¼šéªŒè¯æ£€æŸ¥å·¥å…·æœ¬èº«çš„æ­£ç¡®æ€§
    """
    # æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
    test_cases = [
        # åº”è¯¥åŒ¹é…
        ("SELECT * FROM scm.repos", True, "scm."),
        ("INSERT INTO logbook.items", True, "logbook."),
        ("FROM identity.users", True, "identity."),
        ("analysis.metrics", True, "analysis."),
        ("governance.rules", True, "governance."),
        
        # ä¸åº”è¯¥åŒ¹é…
        ("SELECT * FROM repos", False, None),
        ("INSERT INTO items", False, None),
        ("mechanism.something", False, None),  # ä¸æ˜¯ schema åç§°
        ("schema_name = 'scm'", False, None),  # å¼•å·å†…çš„å€¼
    ]
    
    for text, should_match, expected_prefix in test_cases:
        match = SCHEMA_PREFIX_PATTERN.search(text)
        if should_match:
            assert match is not None, f"åº”è¯¥åŒ¹é…: {text}"
            assert match.group(0) == expected_prefix, f"å‰ç¼€åº”ä¸º {expected_prefix}: {text}"
        else:
            # å¯¹äºå¼•å·å†…çš„æƒ…å†µï¼Œå¯èƒ½ä¼šåŒ¹é…ä½†ä¼šè¢«åç»­è¿‡æ»¤
            pass  # ç®€åŒ–æµ‹è¯•ï¼Œä¸»è¦éªŒè¯åŸºæœ¬åŒ¹é…


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæ—¶æ‰§è¡Œæ£€æŸ¥å¹¶æ‰“å°æŠ¥å‘Š
    violations = check_all_files()
    print(format_violations_report(violations))
    
    if violations:
        exit(1)
    else:
        print("æ‰€æœ‰æ–‡ä»¶æ£€æŸ¥é€šè¿‡ï¼")
        exit(0)
