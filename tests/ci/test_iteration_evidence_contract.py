#!/usr/bin/env python3
"""
check_iteration_evidence_contract.py å•å…ƒæµ‹è¯•

è¦†ç›–åŠŸèƒ½:
1. æ–‡ä»¶åå‘½åè§„èŒƒæ£€æµ‹ - éªŒè¯ canonical å’Œ snapshot æ ¼å¼
2. JSON Schema æ ¡éªŒ - éªŒè¯è¯æ®æ–‡ä»¶ç¬¦åˆ schema
3. å†…å®¹ä¸€è‡´æ€§æ ¡éªŒ - éªŒè¯ iteration_number ä¸æ–‡ä»¶åä¸€è‡´
4. è¾¹ç•Œæƒ…å†µ - ç©ºç›®å½•ã€æ— æ•ˆ JSONã€ç¼ºå¤±å­—æ®µç­‰

Fixtures ä½¿ç”¨ä¸´æ—¶ç›®å½•æ„é€  docs/acceptance/evidence ç»“æ„ã€‚
"""

from __future__ import annotations

import json
import tempfile
from pathlib import Path

import pytest

from scripts.ci.check_iteration_evidence_contract import (
    CANONICAL_PATTERN,
    CURRENT_SCHEMA_PATH,
    EVIDENCE_DIR,
    SCHEMA_PATH,
    SNAPSHOT_PATTERN,
    SNAPSHOT_SHA_PATTERN,
    EvidenceViolation,
    EvidenceWarning,
    get_evidence_files,
    load_schema,
    load_schemas,
    parse_evidence_filename,
    scan_evidence_files,
    validate_bidirectional_reference,
    validate_filename,
    validate_json_content,
    validate_regression_doc_link,
)

# ============================================================================
# Fixtures - ä¸´æ—¶é¡¹ç›®ç›®å½•
# ============================================================================


@pytest.fixture
def temp_evidence_dir():
    """åˆ›å»ºä¸´æ—¶è¯æ®ç›®å½•ç»“æ„"""
    with tempfile.TemporaryDirectory(prefix="test_evidence_") as tmpdir:
        evidence_dir = Path(tmpdir) / "docs" / "acceptance" / "evidence"
        evidence_dir.mkdir(parents=True)
        yield evidence_dir


@pytest.fixture
def valid_evidence_content() -> dict:
    """æœ‰æ•ˆçš„è¯æ®æ–‡ä»¶å†…å®¹"""
    return {
        "$schema": "../../../schemas/iteration_evidence_v2.schema.json",
        "iteration_number": 13,
        "recorded_at": "2026-02-01T20:46:36Z",
        "commit_sha": "abc1234567890",
        "runner": {
            "os": "darwin-24.6.0",
            "python": "3.13.2",
            "arch": "x86_64",
        },
        "commands": [
            {
                "name": "ci",
                "command": "make ci",
                "result": "PASS",
            }
        ],
        "overall_result": "PASS",
        "sensitive_data_declaration": True,
    }


@pytest.fixture
def canonical_evidence_file(temp_evidence_dir: Path, valid_evidence_content: dict) -> Path:
    """Canonical æ ¼å¼çš„è¯æ®æ–‡ä»¶"""
    filepath = temp_evidence_dir / "iteration_13_evidence.json"
    filepath.write_text(json.dumps(valid_evidence_content, indent=2), encoding="utf-8")
    return filepath


@pytest.fixture
def snapshot_evidence_file(temp_evidence_dir: Path, valid_evidence_content: dict) -> Path:
    """Snapshot æ ¼å¼çš„è¯æ®æ–‡ä»¶ï¼ˆæ—  SHAï¼‰"""
    filepath = temp_evidence_dir / "iteration_13_20260201_204636.json"
    filepath.write_text(json.dumps(valid_evidence_content, indent=2), encoding="utf-8")
    return filepath


@pytest.fixture
def snapshot_sha_evidence_file(temp_evidence_dir: Path, valid_evidence_content: dict) -> Path:
    """Snapshot æ ¼å¼çš„è¯æ®æ–‡ä»¶ï¼ˆå¸¦ SHAï¼‰"""
    filepath = temp_evidence_dir / "iteration_13_20260201_204636_abc1234.json"
    filepath.write_text(json.dumps(valid_evidence_content, indent=2), encoding="utf-8")
    return filepath


# ============================================================================
# parse_evidence_filename æµ‹è¯•
# ============================================================================


class TestParseEvidenceFilename:
    """parse_evidence_filename å‡½æ•°æµ‹è¯•"""

    def test_parses_canonical_format(self):
        """æµ‹è¯•è§£æ canonical æ ¼å¼"""
        result = parse_evidence_filename("iteration_13_evidence.json")
        assert result is not None
        assert result["iteration_number"] == 13
        assert result["is_canonical"] is True
        assert result["timestamp"] is None
        assert result["commit_sha"] is None

    def test_parses_canonical_format_various_numbers(self):
        """æµ‹è¯•è§£æä¸åŒè¿­ä»£ç¼–å·çš„ canonical æ ¼å¼"""
        test_cases = [
            ("iteration_1_evidence.json", 1),
            ("iteration_99_evidence.json", 99),
            ("iteration_100_evidence.json", 100),
        ]
        for filename, expected_num in test_cases:
            result = parse_evidence_filename(filename)
            assert result is not None, f"åº”è§£æ: {filename}"
            assert result["iteration_number"] == expected_num
            assert result["is_canonical"] is True

    def test_parses_snapshot_format(self):
        """æµ‹è¯•è§£æ snapshot æ ¼å¼ï¼ˆæ—  SHAï¼‰"""
        result = parse_evidence_filename("iteration_13_20260201_103000.json")
        assert result is not None
        assert result["iteration_number"] == 13
        assert result["is_canonical"] is False
        assert result["timestamp"] == "20260201_103000"
        assert result["commit_sha"] is None

    def test_parses_snapshot_sha_format(self):
        """æµ‹è¯•è§£æ snapshot æ ¼å¼ï¼ˆå¸¦ SHAï¼‰"""
        result = parse_evidence_filename("iteration_13_20260201_103000_abc1234.json")
        assert result is not None
        assert result["iteration_number"] == 13
        assert result["is_canonical"] is False
        assert result["timestamp"] == "20260201_103000"
        assert result["commit_sha"] == "abc1234"

    def test_rejects_invalid_formats(self):
        """æµ‹è¯•æ‹’ç»æ— æ•ˆæ ¼å¼"""
        invalid_filenames = [
            "evidence.json",  # ç¼ºå°‘ iteration å‰ç¼€
            "iteration_evidence.json",  # ç¼ºå°‘ç¼–å·
            "iteration_13.json",  # ç¼ºå°‘ _evidence åç¼€æˆ–æ—¶é—´æˆ³
            "iteration_13_evidence.txt",  # é”™è¯¯æ‰©å±•å
            "ITERATION_13_evidence.json",  # å¤§å†™
            "iteration_abc_evidence.json",  # éæ•°å­—ç¼–å·
            "iteration_13_2026_evidence.json",  # æ—¶é—´æˆ³æ ¼å¼é”™è¯¯
            "random_file.json",  # å®Œå…¨ä¸ç›¸å…³
        ]
        for filename in invalid_filenames:
            result = parse_evidence_filename(filename)
            assert result is None, f"ä¸åº”è§£æ: {filename}"


# ============================================================================
# æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼æµ‹è¯•
# ============================================================================


class TestPatterns:
    """æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼æµ‹è¯•"""

    def test_canonical_pattern(self):
        """æµ‹è¯• CANONICAL_PATTERN"""
        assert CANONICAL_PATTERN.match("iteration_13_evidence.json")
        assert CANONICAL_PATTERN.match("iteration_1_evidence.json")
        assert CANONICAL_PATTERN.match("iteration_999_evidence.json")
        assert not CANONICAL_PATTERN.match("iteration_13.json")
        assert not CANONICAL_PATTERN.match("iteration_evidence.json")

    def test_snapshot_pattern(self):
        """æµ‹è¯• SNAPSHOT_PATTERN"""
        assert SNAPSHOT_PATTERN.match("iteration_13_20260201_103000.json")
        assert not SNAPSHOT_PATTERN.match("iteration_13_evidence.json")
        assert not SNAPSHOT_PATTERN.match("iteration_13_2026_103000.json")  # æ—¶é—´æˆ³æ ¼å¼é”™è¯¯

    def test_snapshot_sha_pattern(self):
        """æµ‹è¯• SNAPSHOT_SHA_PATTERN"""
        assert SNAPSHOT_SHA_PATTERN.match("iteration_13_20260201_103000_abc1234.json")
        assert not SNAPSHOT_SHA_PATTERN.match("iteration_13_20260201_103000.json")
        assert not SNAPSHOT_SHA_PATTERN.match(
            "iteration_13_20260201_103000_ABC1234.json"
        )  # å¤§å†™ SHA


# ============================================================================
# validate_filename æµ‹è¯•
# ============================================================================


class TestValidateFilename:
    """validate_filename å‡½æ•°æµ‹è¯•"""

    def test_accepts_canonical_format(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ¥å— canonical æ ¼å¼"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        filepath.touch()
        result = validate_filename(filepath)
        assert result is None

    def test_accepts_snapshot_format(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ¥å— snapshot æ ¼å¼"""
        filepath = temp_evidence_dir / "iteration_13_20260201_103000.json"
        filepath.touch()
        result = validate_filename(filepath)
        assert result is None

    def test_accepts_snapshot_sha_format(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ¥å— snapshot+SHA æ ¼å¼"""
        filepath = temp_evidence_dir / "iteration_13_20260201_103000_abc1234.json"
        filepath.touch()
        result = validate_filename(filepath)
        assert result is None

    def test_rejects_invalid_format(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ‹’ç»æ— æ•ˆæ ¼å¼"""
        filepath = temp_evidence_dir / "invalid_name.json"
        filepath.touch()
        result = validate_filename(filepath)
        assert result is not None
        assert result.violation_type == "naming"
        assert "ä¸ç¬¦åˆå‘½åè§„èŒƒ" in result.message


# ============================================================================
# validate_json_content æµ‹è¯•
# ============================================================================


class TestValidateJsonContent:
    """validate_json_content å‡½æ•°æµ‹è¯•"""

    def test_accepts_valid_content(
        self, canonical_evidence_file: Path, valid_evidence_content: dict
    ):
        """æµ‹è¯•æ¥å—æœ‰æ•ˆå†…å®¹"""
        schemas = load_schemas()
        violations = validate_json_content(canonical_evidence_file, schemas)
        assert len(violations) == 0

    def test_detects_invalid_json(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ£€æµ‹æ— æ•ˆ JSON"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        filepath.write_text("{invalid json", encoding="utf-8")

        violations = validate_json_content(filepath, load_schemas())
        assert len(violations) == 1
        assert violations[0].violation_type == "content"
        assert "JSON è§£æå¤±è´¥" in violations[0].message

    def test_detects_iteration_number_mismatch(
        self, temp_evidence_dir: Path, valid_evidence_content: dict
    ):
        """æµ‹è¯•æ£€æµ‹ iteration_number ä¸ä¸€è‡´"""
        # æ–‡ä»¶åè¯´æ˜¯ iteration 13ï¼Œä½†å†…å®¹è¯´æ˜¯ 14
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        valid_evidence_content["iteration_number"] = 14
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        violations = validate_json_content(filepath, load_schemas())
        assert len(violations) == 1
        assert violations[0].violation_type == "content"
        assert "iteration_number ä¸ä¸€è‡´" in violations[0].message
        assert "æ–‡ä»¶åæŒ‡ç¤º 13" in violations[0].message
        assert "JSON å†…å®¹ä¸º 14" in violations[0].message

    def test_schema_validation(self, temp_evidence_dir: Path):
        """æµ‹è¯• Schema æ ¡éªŒ"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        # ç¼ºå°‘å¿…éœ€å­—æ®µçš„å†…å®¹
        invalid_content = {
            "iteration_number": 13,
            # ç¼ºå°‘ recorded_at, commit_sha, runner, commands
        }
        filepath.write_text(json.dumps(invalid_content), encoding="utf-8")

        schemas = load_schemas()
        if schemas.get("current") is not None:
            violations = validate_json_content(filepath, schemas)
            # åº”è¯¥æœ‰ schema è¿è§„
            schema_violations = [v for v in violations if v.violation_type == "schema"]
            assert len(schema_violations) >= 1
            assert "Schema æ ¡éªŒå¤±è´¥" in schema_violations[0].message

    def test_schema_validation_missing_required_field(self, temp_evidence_dir: Path):
        """æµ‹è¯• Schema æ ¡éªŒ - ç¼ºå°‘å¿…éœ€å­—æ®µ"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        # åªæœ‰éƒ¨åˆ†å¿…éœ€å­—æ®µ
        content = {
            "iteration_number": 13,
            "recorded_at": "2026-02-01T20:46:36Z",
            # ç¼ºå°‘ commit_sha, runner, commands
        }
        filepath.write_text(json.dumps(content), encoding="utf-8")

        schemas = load_schemas()
        if schemas.get("current") is not None:
            violations = validate_json_content(filepath, schemas)
            schema_violations = [v for v in violations if v.violation_type == "schema"]
            assert len(schema_violations) >= 1

    def test_schema_validation_invalid_field_type(
        self, temp_evidence_dir: Path, valid_evidence_content: dict
    ):
        """æµ‹è¯• Schema æ ¡éªŒ - å­—æ®µç±»å‹é”™è¯¯"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        # iteration_number åº”è¯¥æ˜¯æ•´æ•°ï¼Œä¸æ˜¯å­—ç¬¦ä¸²
        valid_evidence_content["iteration_number"] = "13"
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        schemas = load_schemas()
        if schemas.get("current") is not None:
            violations = validate_json_content(filepath, schemas)
            schema_violations = [v for v in violations if v.violation_type == "schema"]
            assert len(schema_violations) >= 1


# ============================================================================
# get_evidence_files æµ‹è¯•
# ============================================================================


class TestGetEvidenceFiles:
    """get_evidence_files å‡½æ•°æµ‹è¯•"""

    def test_finds_json_files(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ‰¾åˆ° JSON æ–‡ä»¶"""
        (temp_evidence_dir / "iteration_13_evidence.json").touch()
        (temp_evidence_dir / "iteration_14_evidence.json").touch()

        files = get_evidence_files(temp_evidence_dir)
        assert len(files) == 2

    def test_excludes_non_json_files(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ’é™¤é JSON æ–‡ä»¶"""
        (temp_evidence_dir / "iteration_13_evidence.json").touch()
        (temp_evidence_dir / ".gitkeep").touch()
        (temp_evidence_dir / "readme.md").touch()

        files = get_evidence_files(temp_evidence_dir)
        assert len(files) == 1
        assert files[0].name == "iteration_13_evidence.json"

    def test_returns_empty_for_nonexistent_dir(self):
        """æµ‹è¯•ä¸å­˜åœ¨çš„ç›®å½•è¿”å›ç©ºåˆ—è¡¨"""
        files = get_evidence_files(Path("/nonexistent/path"))
        assert files == []

    def test_returns_sorted_files(self, temp_evidence_dir: Path):
        """æµ‹è¯•è¿”å›æ’åºåçš„æ–‡ä»¶åˆ—è¡¨"""
        (temp_evidence_dir / "iteration_15_evidence.json").touch()
        (temp_evidence_dir / "iteration_13_evidence.json").touch()
        (temp_evidence_dir / "iteration_14_evidence.json").touch()

        files = get_evidence_files(temp_evidence_dir)
        assert len(files) == 3
        assert files[0].name == "iteration_13_evidence.json"
        assert files[1].name == "iteration_14_evidence.json"
        assert files[2].name == "iteration_15_evidence.json"


# ============================================================================
# scan_evidence_files æµ‹è¯•
# ============================================================================


class TestScanEvidenceFiles:
    """scan_evidence_files å‡½æ•°æµ‹è¯•"""

    def test_scans_valid_files(self, temp_evidence_dir: Path, canonical_evidence_file: Path):
        """æµ‹è¯•æ‰«ææœ‰æ•ˆæ–‡ä»¶"""
        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)
        assert total_files == 1
        assert len(violations) == 0
        # å¯èƒ½æœ‰ç¼ºå°‘ links çš„è­¦å‘Š

    def test_detects_naming_violations(self, temp_evidence_dir: Path, valid_evidence_content: dict):
        """æµ‹è¯•æ£€æµ‹å‘½åè¿è§„"""
        filepath = temp_evidence_dir / "bad_name.json"
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)
        assert total_files == 1
        naming_violations = [v for v in violations if v.violation_type == "naming"]
        assert len(naming_violations) == 1

    def test_detects_schema_violations(self, temp_evidence_dir: Path):
        """æµ‹è¯•æ£€æµ‹ Schema è¿è§„"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        # ç¼ºå°‘å¿…éœ€å­—æ®µ
        filepath.write_text('{"iteration_number": 13}', encoding="utf-8")

        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)
        assert total_files == 1
        # åº”è¯¥æœ‰ schema è¿è§„ï¼ˆå¦‚æœ jsonschema å¯ç”¨ï¼‰
        # æµ‹è¯•ä¸å‡å®š jsonschema ä¸€å®šå¯ç”¨

    def test_empty_directory(self, temp_evidence_dir: Path):
        """æµ‹è¯•ç©ºç›®å½•"""
        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)
        assert total_files == 0
        assert len(violations) == 0
        assert len(warnings) == 0


# ============================================================================
# EvidenceViolation æ•°æ®ç±»æµ‹è¯•
# ============================================================================


class TestEvidenceViolation:
    """EvidenceViolation æ•°æ®ç±»æµ‹è¯•"""

    def test_str_format_naming(self):
        """æµ‹è¯•å‘½åè¿è§„çš„å­—ç¬¦ä¸²æ ¼å¼"""
        violation = EvidenceViolation(
            file=Path("bad_name.json"),
            violation_type="naming",
            message="æ–‡ä»¶åä¸ç¬¦åˆå‘½åè§„èŒƒ",
        )
        str_repr = str(violation)
        assert "bad_name.json" in str_repr
        assert "[naming]" in str_repr
        assert "æ–‡ä»¶åä¸ç¬¦åˆå‘½åè§„èŒƒ" in str_repr

    def test_str_format_schema(self):
        """æµ‹è¯• Schema è¿è§„çš„å­—ç¬¦ä¸²æ ¼å¼"""
        violation = EvidenceViolation(
            file=Path("iteration_13_evidence.json"),
            violation_type="schema",
            message="Schema æ ¡éªŒå¤±è´¥ @ runner: 'runner' is a required property",
        )
        str_repr = str(violation)
        assert "[schema]" in str_repr
        assert "Schema æ ¡éªŒå¤±è´¥" in str_repr

    def test_str_format_content(self):
        """æµ‹è¯•å†…å®¹è¿è§„çš„å­—ç¬¦ä¸²æ ¼å¼"""
        violation = EvidenceViolation(
            file=Path("iteration_13_evidence.json"),
            violation_type="content",
            message="iteration_number ä¸ä¸€è‡´",
        )
        str_repr = str(violation)
        assert "[content]" in str_repr
        assert "iteration_number ä¸ä¸€è‡´" in str_repr


# ============================================================================
# load_schema æµ‹è¯•
# ============================================================================


class TestLoadSchema:
    """load_schema å‡½æ•°æµ‹è¯•"""

    def test_loads_schema_from_default_path(self):
        """æµ‹è¯•ä»é»˜è®¤è·¯å¾„åŠ è½½ Schema"""
        # åªæœ‰å½“å®é™… schema æ–‡ä»¶å­˜åœ¨æ—¶æ‰è¿è¡Œ
        if CURRENT_SCHEMA_PATH.exists():
            schema = load_schema(CURRENT_SCHEMA_PATH)
            assert schema is not None
            assert "properties" in schema
            assert "iteration_number" in schema["properties"]


# ============================================================================
# é›†æˆæµ‹è¯•
# ============================================================================


class TestIntegration:
    """é›†æˆæµ‹è¯•"""

    def test_mixed_violations(self, temp_evidence_dir: Path, valid_evidence_content: dict):
        """æµ‹è¯•åŒæ—¶å­˜åœ¨å¤šç§è¿è§„"""
        # 1. æœ‰æ•ˆæ–‡ä»¶
        (temp_evidence_dir / "iteration_13_evidence.json").write_text(
            json.dumps(valid_evidence_content), encoding="utf-8"
        )

        # 2. å‘½åè¿è§„
        valid_evidence_content["iteration_number"] = 14
        (temp_evidence_dir / "bad_name.json").write_text(
            json.dumps(valid_evidence_content), encoding="utf-8"
        )

        # 3. å†…å®¹ä¸ä¸€è‡´è¿è§„ï¼ˆiteration_number ä¸æ–‡ä»¶åä¸åŒ¹é…ï¼‰
        mismatched_content = valid_evidence_content.copy()
        mismatched_content["iteration_number"] = 99
        (temp_evidence_dir / "iteration_15_evidence.json").write_text(
            json.dumps(mismatched_content), encoding="utf-8"
        )

        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)

        assert total_files == 3

        # åº”è¯¥æœ‰å‘½åè¿è§„
        naming_violations = [v for v in violations if v.violation_type == "naming"]
        assert len(naming_violations) == 1

        # åº”è¯¥æœ‰å†…å®¹ä¸ä¸€è‡´è¿è§„
        content_violations = [v for v in violations if v.violation_type == "content"]
        assert len(content_violations) >= 1

    def test_real_evidence_directory(self):
        """æµ‹è¯•çœŸå®çš„è¯æ®ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
        if EVIDENCE_DIR.exists():
            violations, warnings, total_files = scan_evidence_files(evidence_dir=EVIDENCE_DIR)
            # çœŸå®ç›®å½•åº”è¯¥æ²¡æœ‰è¿è§„ï¼ˆæˆ–è€…å·²çŸ¥è¿è§„æ•°é‡ï¼‰
            # è¿™é‡ŒåªéªŒè¯è„šæœ¬èƒ½æ­£å¸¸è¿è¡Œ
            assert total_files >= 0
            # ä¸æ–­è¨€å…·ä½“æ•°é‡ï¼Œå› ä¸ºçœŸå®æ•°æ®å¯èƒ½å˜åŒ–


# ============================================================================
# è¾¹ç•Œæƒ…å†µæµ‹è¯•
# ============================================================================


class TestEdgeCases:
    """è¾¹ç•Œæƒ…å†µæµ‹è¯•"""

    def test_empty_json_file(self, temp_evidence_dir: Path):
        """æµ‹è¯•ç©º JSON æ–‡ä»¶"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        filepath.write_text("", encoding="utf-8")

        violations = validate_json_content(filepath, load_schemas())
        assert len(violations) == 1
        assert violations[0].violation_type == "content"
        assert "JSON è§£æå¤±è´¥" in violations[0].message

    def test_json_array_instead_of_object(self, temp_evidence_dir: Path):
        """æµ‹è¯• JSON æ•°ç»„ï¼ˆè€Œéå¯¹è±¡ï¼‰"""
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        filepath.write_text("[]", encoding="utf-8")

        schemas = load_schemas()
        if schemas.get("current") is not None:
            violations = validate_json_content(filepath, schemas)
            # åº”è¯¥æœ‰ schema è¿è§„ï¼ˆæœŸæœ›å¯¹è±¡ï¼Œå¾—åˆ°æ•°ç»„ï¼‰
            schema_violations = [v for v in violations if v.violation_type == "schema"]
            assert len(schema_violations) >= 1

    def test_unicode_content(self, temp_evidence_dir: Path, valid_evidence_content: dict):
        """æµ‹è¯• Unicode å†…å®¹"""
        valid_evidence_content["notes"] = "ä¸­æ–‡å¤‡æ³¨ ğŸ‰"
        filepath = temp_evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(
            json.dumps(valid_evidence_content, ensure_ascii=False), encoding="utf-8"
        )

        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)
        assert total_files == 1
        assert len(violations) == 0
        # å¯èƒ½æœ‰ç¼ºå°‘ links çš„è­¦å‘Š

    def test_large_iteration_number(self, temp_evidence_dir: Path, valid_evidence_content: dict):
        """æµ‹è¯•å¤§è¿­ä»£ç¼–å·"""
        valid_evidence_content["iteration_number"] = 999
        filepath = temp_evidence_dir / "iteration_999_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)
        assert total_files == 1
        assert len(violations) == 0
        # å¯èƒ½æœ‰ç¼ºå°‘ links çš„è­¦å‘Š

    def test_zero_iteration_number_in_filename(
        self, temp_evidence_dir: Path, valid_evidence_content: dict
    ):
        """æµ‹è¯•è¿­ä»£ç¼–å·ä¸º 0 çš„æ–‡ä»¶åï¼ˆåº”è¯¥ä¸åˆè§„ï¼‰"""
        valid_evidence_content["iteration_number"] = 0
        filepath = temp_evidence_dir / "iteration_0_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        violations, warnings, total_files = scan_evidence_files(evidence_dir=temp_evidence_dir)
        # æ–‡ä»¶åå¯ä»¥è§£æï¼Œä½† schema å¯èƒ½è¦æ±‚æ­£æ•´æ•°
        # è¿™é‡Œä¸»è¦éªŒè¯è„šæœ¬ä¸ä¼šå´©æºƒ
        assert total_files == 1


# ============================================================================
# å¸¸é‡è·¯å¾„æµ‹è¯•
# ============================================================================


class TestConstants:
    """å¸¸é‡æµ‹è¯•"""

    def test_evidence_dir_path(self):
        """æµ‹è¯• EVIDENCE_DIR è·¯å¾„æ ¼å¼"""
        assert EVIDENCE_DIR.name == "evidence"
        assert EVIDENCE_DIR.parent.name == "acceptance"
        assert EVIDENCE_DIR.parent.parent.name == "docs"

    def test_schema_path(self):
        """æµ‹è¯• SCHEMA_PATH è·¯å¾„æ ¼å¼"""
        assert SCHEMA_PATH.name == "iteration_evidence_v1.schema.json"
        assert SCHEMA_PATH.parent.name == "schemas"


# ============================================================================
# validate_regression_doc_link æµ‹è¯•
# ============================================================================


@pytest.fixture
def temp_project_root():
    """åˆ›å»ºä¸´æ—¶é¡¹ç›®ç›®å½•ç»“æ„ï¼ˆå« regression æ–‡æ¡£ï¼‰"""
    with tempfile.TemporaryDirectory(prefix="test_project_") as tmpdir:
        root = Path(tmpdir)
        # åˆ›å»ºç›®å½•ç»“æ„
        evidence_dir = root / "docs" / "acceptance" / "evidence"
        evidence_dir.mkdir(parents=True)
        yield root


@pytest.fixture
def valid_evidence_content_with_links() -> dict:
    """å¸¦ links çš„æœ‰æ•ˆè¯æ®æ–‡ä»¶å†…å®¹"""
    return {
        "$schema": "../../../schemas/iteration_evidence_v2.schema.json",
        "iteration_number": 13,
        "recorded_at": "2026-02-01T20:46:36Z",
        "commit_sha": "abc1234567890",
        "runner": {
            "os": "darwin-24.6.0",
            "python": "3.13.2",
            "arch": "x86_64",
        },
        "commands": [
            {
                "name": "ci",
                "command": "make ci",
                "result": "PASS",
            }
        ],
        "overall_result": "PASS",
        "sensitive_data_declaration": True,
        "links": {"regression_doc_url": "docs/acceptance/iteration_13_regression.md"},
    }


class TestValidateRegressionDocLink:
    """validate_regression_doc_link å‡½æ•°æµ‹è¯•"""

    def test_valid_link(self, temp_project_root: Path, valid_evidence_content_with_links: dict):
        """æµ‹è¯•æœ‰æ•ˆçš„ regression_doc_url"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")

        # åˆ›å»º regression æ–‡æ¡£
        regression_doc = temp_project_root / "docs" / "acceptance" / "iteration_13_regression.md"
        regression_doc.write_text("# Iteration 13 Regression\n", encoding="utf-8")

        violations, warnings = validate_regression_doc_link(
            filepath, valid_evidence_content_with_links, temp_project_root
        )

        assert len(violations) == 0
        assert len(warnings) == 0

    def test_missing_links_canonical(self, temp_project_root: Path, valid_evidence_content: dict):
        """æµ‹è¯• canonical æ–‡ä»¶ç¼ºå°‘ links å­—æ®µï¼ˆåº”äº§ç”Ÿè­¦å‘Šï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        violations, warnings = validate_regression_doc_link(
            filepath, valid_evidence_content, temp_project_root
        )

        assert len(violations) == 0
        assert len(warnings) == 1
        assert warnings[0].warning_type == "missing_links"
        assert "ç¼ºå°‘ links å­—æ®µ" in warnings[0].message

    def test_missing_links_snapshot(self, temp_project_root: Path, valid_evidence_content: dict):
        """æµ‹è¯• snapshot æ–‡ä»¶ç¼ºå°‘ links å­—æ®µï¼ˆä¸äº§ç”Ÿè­¦å‘Šï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        # snapshot æ ¼å¼
        filepath = evidence_dir / "iteration_13_20260201_204636.json"
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        violations, warnings = validate_regression_doc_link(
            filepath, valid_evidence_content, temp_project_root
        )

        assert len(violations) == 0
        assert len(warnings) == 0

    def test_missing_regression_doc_url(
        self, temp_project_root: Path, valid_evidence_content: dict
    ):
        """æµ‹è¯• canonical æ–‡ä»¶ links ä¸­ç¼ºå°‘ regression_doc_urlï¼ˆåº”äº§ç”Ÿè­¦å‘Šï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        content = valid_evidence_content.copy()
        content["links"] = {"ci_run_url": "https://example.com"}
        filepath.write_text(json.dumps(content), encoding="utf-8")

        violations, warnings = validate_regression_doc_link(filepath, content, temp_project_root)

        assert len(violations) == 0
        assert len(warnings) == 1
        assert warnings[0].warning_type == "missing_links"
        assert "ç¼ºå°‘ regression_doc_url" in warnings[0].message

    def test_nonexistent_regression_doc(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯• regression_doc_url æŒ‡å‘ä¸å­˜åœ¨çš„æ–‡ä»¶ï¼ˆåº”äº§ç”Ÿè¿è§„ï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")
        # ä¸åˆ›å»º regression æ–‡æ¡£

        violations, warnings = validate_regression_doc_link(
            filepath, valid_evidence_content_with_links, temp_project_root
        )

        assert len(violations) == 1
        assert violations[0].violation_type == "link"
        assert "ä¸å­˜åœ¨" in violations[0].message

    def test_invalid_regression_doc_filename(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯• regression_doc_url æŒ‡å‘æ–‡ä»¶åæ ¼å¼é”™è¯¯çš„æ–‡ä»¶ï¼ˆåº”äº§ç”Ÿè¿è§„ï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"

        content = valid_evidence_content_with_links.copy()
        content["links"] = {"regression_doc_url": "docs/acceptance/bad_name.md"}
        filepath.write_text(json.dumps(content), encoding="utf-8")

        # åˆ›å»ºé”™è¯¯å‘½åçš„æ–‡æ¡£
        bad_doc = temp_project_root / "docs" / "acceptance" / "bad_name.md"
        bad_doc.write_text("# Bad Name\n", encoding="utf-8")

        violations, warnings = validate_regression_doc_link(filepath, content, temp_project_root)

        assert len(violations) == 1
        assert violations[0].violation_type == "link"
        assert "ä¸ç¬¦åˆè§„èŒƒ" in violations[0].message

    def test_mismatched_iteration_number(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯• regression_doc_url è¿­ä»£ç¼–å·ä¸ä¸€è‡´ï¼ˆåº”äº§ç”Ÿè¿è§„ï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"

        # evidence çš„ iteration_number æ˜¯ 13ï¼Œä½†é“¾æ¥æŒ‡å‘ 14
        content = valid_evidence_content_with_links.copy()
        content["links"] = {"regression_doc_url": "docs/acceptance/iteration_14_regression.md"}
        filepath.write_text(json.dumps(content), encoding="utf-8")

        # åˆ›å»º iteration 14 regression æ–‡æ¡£
        regression_doc = temp_project_root / "docs" / "acceptance" / "iteration_14_regression.md"
        regression_doc.write_text("# Iteration 14 Regression\n", encoding="utf-8")

        violations, warnings = validate_regression_doc_link(filepath, content, temp_project_root)

        assert len(violations) == 1
        assert violations[0].violation_type == "link"
        assert "è¿­ä»£ç¼–å·ä¸ä¸€è‡´" in violations[0].message
        assert "13" in violations[0].message
        assert "14" in violations[0].message

    def test_url_format_skipped(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯• URL æ ¼å¼çš„ regression_doc_urlï¼ˆåº”è·³è¿‡æ ¡éªŒï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"

        content = valid_evidence_content_with_links.copy()
        content["links"] = {"regression_doc_url": "https://example.com/docs/iteration_13.md"}
        filepath.write_text(json.dumps(content), encoding="utf-8")

        violations, warnings = validate_regression_doc_link(filepath, content, temp_project_root)

        assert len(violations) == 0
        assert len(warnings) == 0


# ============================================================================
# validate_bidirectional_reference æµ‹è¯•
# ============================================================================


class TestValidateBidirectionalReference:
    """validate_bidirectional_reference å‡½æ•°æµ‹è¯•"""

    def test_valid_bidirectional_reference(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯•æœ‰æ•ˆçš„åŒå‘å¼•ç”¨"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")

        # åˆ›å»ºå¼•ç”¨ evidence çš„ regression æ–‡æ¡£
        regression_doc = temp_project_root / "docs" / "acceptance" / "iteration_13_regression.md"
        regression_doc.write_text(
            "# Iteration 13 Regression\n\n"
            "## éªŒæ”¶è¯æ®\n\n"
            "- [è¯æ®æ–‡ä»¶](evidence/iteration_13_evidence.json)\n",
            encoding="utf-8",
        )

        violations = validate_bidirectional_reference(
            filepath, valid_evidence_content_with_links, temp_project_root
        )

        assert len(violations) == 0

    def test_missing_reference_in_regression_doc(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯• regression æ–‡æ¡£æœªå¼•ç”¨ evidence æ–‡ä»¶ï¼ˆåº”äº§ç”Ÿè¿è§„ï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")

        # åˆ›å»ºæœªå¼•ç”¨ evidence çš„ regression æ–‡æ¡£
        regression_doc = temp_project_root / "docs" / "acceptance" / "iteration_13_regression.md"
        regression_doc.write_text(
            "# Iteration 13 Regression\n\n## æ‰§è¡Œç»“æœ\n\næ‰€æœ‰æµ‹è¯•é€šè¿‡ã€‚\n",
            encoding="utf-8",
        )

        violations = validate_bidirectional_reference(
            filepath, valid_evidence_content_with_links, temp_project_root
        )

        assert len(violations) == 1
        assert violations[0].violation_type == "link"
        assert "åŒå‘å¼•ç”¨ä¸ä¸€è‡´" in violations[0].message

    def test_snapshot_file_skipped(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯• snapshot æ–‡ä»¶è·³è¿‡åŒå‘æ ¡éªŒ"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        # snapshot æ ¼å¼
        filepath = evidence_dir / "iteration_13_20260201_204636.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")

        violations = validate_bidirectional_reference(
            filepath, valid_evidence_content_with_links, temp_project_root
        )

        # snapshot æ–‡ä»¶ä¸è¿›è¡ŒåŒå‘æ ¡éªŒ
        assert len(violations) == 0

    def test_missing_regression_doc_skipped(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯• regression æ–‡æ¡£ä¸å­˜åœ¨æ—¶è·³è¿‡åŒå‘æ ¡éªŒ"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")
        # ä¸åˆ›å»º regression æ–‡æ¡£

        violations = validate_bidirectional_reference(
            filepath, valid_evidence_content_with_links, temp_project_root
        )

        # regression æ–‡æ¡£ä¸å­˜åœ¨æ—¶ä¸è¿›è¡ŒåŒå‘æ ¡éªŒ
        assert len(violations) == 0


# ============================================================================
# scan_evidence_files æ‰©å±•æµ‹è¯•ï¼ˆå« warningsï¼‰
# ============================================================================


class TestScanEvidenceFilesExtended:
    """scan_evidence_files æ‰©å±•æµ‹è¯•ï¼ˆå« warnings è¿”å›å€¼ï¼‰"""

    def test_returns_warnings_for_missing_links(
        self, temp_project_root: Path, valid_evidence_content: dict
    ):
        """æµ‹è¯•è¿”å›ç¼ºå°‘ links çš„è­¦å‘Š"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content), encoding="utf-8")

        violations, warnings, total_files = scan_evidence_files(
            evidence_dir=evidence_dir,
            project_root=temp_project_root,
        )

        assert total_files == 1
        assert len(violations) == 0
        assert len(warnings) == 1
        assert warnings[0].warning_type == "missing_links"

    def test_returns_violations_for_bad_link(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯•è¿”å›åé“¾æ¥çš„è¿è§„"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")
        # ä¸åˆ›å»º regression æ–‡æ¡£

        violations, warnings, total_files = scan_evidence_files(
            evidence_dir=evidence_dir,
            project_root=temp_project_root,
        )

        assert total_files == 1
        # åº”è¯¥æœ‰ link è¿è§„ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨ï¼‰
        link_violations = [v for v in violations if v.violation_type == "link"]
        assert len(link_violations) >= 1

    def test_full_valid_setup(
        self, temp_project_root: Path, valid_evidence_content_with_links: dict
    ):
        """æµ‹è¯•å®Œæ•´æœ‰æ•ˆè®¾ç½®ï¼ˆæ— è¿è§„æ— è­¦å‘Šï¼‰"""
        evidence_dir = temp_project_root / "docs" / "acceptance" / "evidence"
        filepath = evidence_dir / "iteration_13_evidence.json"
        filepath.write_text(json.dumps(valid_evidence_content_with_links), encoding="utf-8")

        # åˆ›å»ºå¼•ç”¨ evidence çš„ regression æ–‡æ¡£
        regression_doc = temp_project_root / "docs" / "acceptance" / "iteration_13_regression.md"
        regression_doc.write_text(
            "# Iteration 13 Regression\n\n"
            "## éªŒæ”¶è¯æ®\n\n"
            "- [è¯æ®æ–‡ä»¶](evidence/iteration_13_evidence.json)\n",
            encoding="utf-8",
        )

        violations, warnings, total_files = scan_evidence_files(
            evidence_dir=evidence_dir,
            project_root=temp_project_root,
        )

        assert total_files == 1
        assert len(violations) == 0
        assert len(warnings) == 0


# ============================================================================
# EvidenceWarning æ•°æ®ç±»æµ‹è¯•
# ============================================================================


class TestEvidenceWarning:
    """EvidenceWarning æ•°æ®ç±»æµ‹è¯•"""

    def test_str_format_missing_links(self):
        """æµ‹è¯•ç¼ºå°‘ links è­¦å‘Šçš„å­—ç¬¦ä¸²æ ¼å¼"""
        warning = EvidenceWarning(
            file=Path("iteration_8_evidence.json"),
            warning_type="missing_links",
            message="ç¼ºå°‘ links å­—æ®µ",
        )
        str_repr = str(warning)
        assert "iteration_8_evidence.json" in str_repr
        assert "[missing_links]" in str_repr
        assert "ç¼ºå°‘ links å­—æ®µ" in str_repr

    def test_str_format_suggestion(self):
        """æµ‹è¯•å»ºè®®è­¦å‘Šçš„å­—ç¬¦ä¸²æ ¼å¼"""
        warning = EvidenceWarning(
            file=Path("iteration_8_evidence.json"),
            warning_type="suggestion",
            message="å»ºè®®æ·»åŠ  regression_doc_url",
        )
        str_repr = str(warning)
        assert "[suggestion]" in str_repr
        assert "å»ºè®®æ·»åŠ " in str_repr
