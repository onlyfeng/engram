# -*- coding: utf-8 -*-
"""
test_object_store_minio_integration.py - ObjectStore MinIO é›†æˆæµ‹è¯•

é€šè¿‡ç¯å¢ƒå˜é‡ ENGRAM_MINIO_INTEGRATION=1 å¯ç”¨æµ‹è¯•ã€‚

æµ‹è¯•è¦†ç›–:
1. å°å¯¹è±¡ put/get
2. exists æ£€æŸ¥
3. Multipart ä¸Šä¼ ï¼ˆ>5MBï¼‰
4. é”™è¯¯åˆ†ç±»ï¼šè®¿é—®ä¸å­˜åœ¨ keyã€é”™è¯¯å‡­è¯

å¯åŠ¨ MinIO:
    docker-compose -f docker-compose.minio.yml up -d

ç¯å¢ƒå˜é‡é…ç½®:
    export ENGRAM_MINIO_INTEGRATION=1
    export ENGRAM_S3_ENDPOINT=http://localhost:9000
    export ENGRAM_S3_ACCESS_KEY=minioadmin
    export ENGRAM_S3_SECRET_KEY=minioadmin
    export ENGRAM_S3_BUCKET=engram-test

è¿è¡Œæµ‹è¯•:
    pytest tests/test_object_store_minio_integration.py -v
"""

import hashlib
import os
import secrets
import sys
import time
from typing import Generator

import pytest

# æ·»åŠ  scripts ç›®å½•åˆ° path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from engram.logbook.artifact_store import (
    ObjectStore,
    ObjectStoreNotConfiguredError,
    ObjectStoreConnectionError,
    ObjectStoreUploadError,
    ObjectStoreDownloadError,
    ArtifactNotFoundError,
    MULTIPART_THRESHOLD,
)


# ============ æµ‹è¯•å¯ç”¨æ¡ä»¶ ============

MINIO_INTEGRATION_ENABLED = os.environ.get("ENGRAM_MINIO_INTEGRATION", "").lower() in ("1", "true", "yes")

pytestmark = pytest.mark.skipif(
    not MINIO_INTEGRATION_ENABLED,
    reason="MinIO é›†æˆæµ‹è¯•æœªå¯ç”¨ï¼Œè®¾ç½® ENGRAM_MINIO_INTEGRATION=1 å¯ç”¨"
)


# ============ Fixtures ============


@pytest.fixture(scope="module")
def minio_config():
    """MinIO é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰"""
    config = {
        "endpoint": os.environ.get("ENGRAM_S3_ENDPOINT", "http://localhost:9000"),
        "access_key": os.environ.get("ENGRAM_S3_ACCESS_KEY", "minioadmin"),
        "secret_key": os.environ.get("ENGRAM_S3_SECRET_KEY", "minioadmin"),
        "bucket": os.environ.get("ENGRAM_S3_BUCKET", "engram-test"),
        "region": os.environ.get("ENGRAM_S3_REGION", "us-east-1"),
    }
    return config


@pytest.fixture(scope="module")
def object_store(minio_config):
    """åˆ›å»º ObjectStore å®ä¾‹"""
    store = ObjectStore(
        endpoint=minio_config["endpoint"],
        access_key=minio_config["access_key"],
        secret_key=minio_config["secret_key"],
        bucket=minio_config["bucket"],
        region=minio_config["region"],
    )
    return store


@pytest.fixture
def unique_key():
    """ç”Ÿæˆå”¯ä¸€çš„å¯¹è±¡é”®ï¼ˆé¿å…æµ‹è¯•é—´å†²çªï¼‰"""
    timestamp = int(time.time() * 1000)
    random_suffix = secrets.token_hex(4)
    return f"test/{timestamp}_{random_suffix}"


@pytest.fixture
def cleanup_keys(object_store):
    """
    æ”¶é›†æµ‹è¯•åˆ›å»ºçš„å¯¹è±¡é”®ï¼Œæµ‹è¯•ç»“æŸåæ¸…ç†
    
    ç”¨æ³•:
        def test_xxx(cleanup_keys):
            key = "test/my_object.txt"
            cleanup_keys.append(key)
            store.put(key, b"content")
    """
    keys = []
    yield keys
    
    # æ¸…ç†æµ‹è¯•åˆ›å»ºçš„å¯¹è±¡
    client = object_store._get_client()
    for key in keys:
        try:
            full_key = object_store._object_key(key)
            client.delete_object(Bucket=object_store.bucket, Key=full_key)
        except Exception:
            pass  # å¿½ç•¥æ¸…ç†å¤±è´¥


# ============ è¿æ¥æµ‹è¯• ============


class TestMinIOConnection:
    """MinIO è¿æ¥æµ‹è¯•"""

    def test_connection_success(self, object_store):
        """æˆåŠŸè¿æ¥åˆ° MinIO"""
        # _get_client åº”æˆåŠŸåˆå§‹åŒ–å®¢æˆ·ç«¯
        client = object_store._get_client()
        assert client is not None
        
        # å°è¯•åˆ—å‡º bucket éªŒè¯è¿æ¥
        response = client.list_buckets()
        bucket_names = [b["Name"] for b in response.get("Buckets", [])]
        assert object_store.bucket in bucket_names, (
            f"Bucket {object_store.bucket} ä¸å­˜åœ¨ï¼Œå¯ç”¨ buckets: {bucket_names}"
        )

    def test_wrong_credentials_error(self, minio_config):
        """é”™è¯¯å‡­è¯åº”å¯¼è‡´æ“ä½œå¤±è´¥"""
        store = ObjectStore(
            endpoint=minio_config["endpoint"],
            access_key="wrong_key",
            secret_key="wrong_secret",
            bucket=minio_config["bucket"],
        )
        
        # è¿æ¥æ—¶ä¸ä¼šæŠ¥é”™ï¼Œä½†æ“ä½œæ—¶ä¼šå¤±è´¥
        with pytest.raises((ObjectStoreUploadError, ObjectStoreConnectionError, Exception)) as exc_info:
            store.put("test/wrong_creds.txt", b"content")
        
        # éªŒè¯é”™è¯¯ä¿¡æ¯ä¸­åŒ…å«è®¤è¯ç›¸å…³ä¿¡æ¯
        error_str = str(exc_info.value).lower()
        # MinIO å¯èƒ½è¿”å›ä¸åŒçš„é”™è¯¯æ¶ˆæ¯
        assert any(kw in error_str for kw in [
            "access", "denied", "credential", "signature", "forbidden",
            "invalidaccesskey", "ä¸Šä¼ åˆ¶å“å¤±è´¥"
        ])


# ============ å°å¯¹è±¡æ“ä½œæµ‹è¯• ============


class TestSmallObjectOperations:
    """å°å¯¹è±¡ put/get/exists æµ‹è¯•"""

    def test_put_get_bytes(self, object_store, unique_key, cleanup_keys):
        """put å’Œ get å­—èŠ‚å†…å®¹"""
        key = f"{unique_key}/bytes.txt"
        cleanup_keys.append(key)
        
        content = b"Hello, MinIO! " + secrets.token_bytes(32)
        expected_sha256 = hashlib.sha256(content).hexdigest()
        
        # Put
        result = object_store.put(key, content)
        
        assert result["uri"] == key
        assert result["sha256"] == expected_sha256
        assert result["size_bytes"] == len(content)
        
        # Get
        retrieved = object_store.get(key)
        assert retrieved == content

    def test_put_get_string(self, object_store, unique_key, cleanup_keys):
        """put å’Œ get å­—ç¬¦ä¸²å†…å®¹"""
        key = f"{unique_key}/string.txt"
        cleanup_keys.append(key)
        
        content_str = "ä½ å¥½ï¼ŒMinIOï¼è¿™æ˜¯ UTF-8 å­—ç¬¦ä¸²æµ‹è¯•ã€‚ğŸš€"
        content_bytes = content_str.encode("utf-8")
        expected_sha256 = hashlib.sha256(content_bytes).hexdigest()
        
        # Put string
        result = object_store.put(key, content_str)
        
        assert result["sha256"] == expected_sha256
        assert result["size_bytes"] == len(content_bytes)
        
        # Get returns bytes
        retrieved = object_store.get(key)
        assert retrieved == content_bytes
        assert retrieved.decode("utf-8") == content_str

    def test_put_get_iterator(self, object_store, unique_key, cleanup_keys):
        """put è¿­ä»£å™¨å†…å®¹"""
        key = f"{unique_key}/iterator.txt"
        cleanup_keys.append(key)
        
        chunks = [b"chunk1_", b"chunk2_", b"chunk3_end"]
        full_content = b"".join(chunks)
        expected_sha256 = hashlib.sha256(full_content).hexdigest()
        
        # Put iterator
        result = object_store.put(key, iter(chunks))
        
        assert result["sha256"] == expected_sha256
        assert result["size_bytes"] == len(full_content)
        
        # Get
        retrieved = object_store.get(key)
        assert retrieved == full_content

    def test_exists_true(self, object_store, unique_key, cleanup_keys):
        """exists å¯¹å­˜åœ¨çš„å¯¹è±¡è¿”å› True"""
        key = f"{unique_key}/exists_true.txt"
        cleanup_keys.append(key)
        
        # å…ˆåˆ›å»ºå¯¹è±¡
        object_store.put(key, b"content for exists test")
        
        # æ£€æŸ¥ exists
        assert object_store.exists(key) is True

    def test_exists_false(self, object_store, unique_key):
        """exists å¯¹ä¸å­˜åœ¨çš„å¯¹è±¡è¿”å› False"""
        key = f"{unique_key}/definitely_not_exists.txt"
        
        assert object_store.exists(key) is False

    def test_overwrite_object(self, object_store, unique_key, cleanup_keys):
        """è¦†ç›–å·²å­˜åœ¨çš„å¯¹è±¡"""
        key = f"{unique_key}/overwrite.txt"
        cleanup_keys.append(key)
        
        content_v1 = b"version 1"
        content_v2 = b"version 2 - updated content"
        
        # å†™å…¥ v1
        result1 = object_store.put(key, content_v1)
        assert result1["size_bytes"] == len(content_v1)
        
        # è¦†ç›–ä¸º v2
        result2 = object_store.put(key, content_v2)
        assert result2["size_bytes"] == len(content_v2)
        
        # è¯»å–åº”ä¸º v2
        retrieved = object_store.get(key)
        assert retrieved == content_v2


# ============ Multipart ä¸Šä¼ æµ‹è¯• ============


class TestMultipartUpload:
    """Multipart ä¸Šä¼ æµ‹è¯•ï¼ˆ>5MBï¼‰"""

    def test_multipart_upload_6mb(self, object_store, unique_key, cleanup_keys):
        """6MB æ–‡ä»¶è§¦å‘ Multipart ä¸Šä¼ """
        key = f"{unique_key}/multipart_6mb.bin"
        cleanup_keys.append(key)
        
        # åˆ›å»º 6MB å†…å®¹ï¼ˆè¶…è¿‡ 5MB é˜ˆå€¼ï¼‰
        size = 6 * 1024 * 1024
        content = secrets.token_bytes(size)
        expected_sha256 = hashlib.sha256(content).hexdigest()
        
        # Put - åº”ä½¿ç”¨ multipart
        result = object_store.put(key, content)
        
        assert result["uri"] == key
        assert result["sha256"] == expected_sha256
        assert result["size_bytes"] == size
        
        # Get å¹¶éªŒè¯å®Œæ•´æ€§
        retrieved = object_store.get(key)
        assert len(retrieved) == size
        assert hashlib.sha256(retrieved).hexdigest() == expected_sha256

    def test_multipart_upload_iterator(self, object_store, unique_key, cleanup_keys):
        """è¿­ä»£å™¨å¤§å†…å®¹è§¦å‘ Multipart ä¸Šä¼ """
        key = f"{unique_key}/multipart_iter.bin"
        cleanup_keys.append(key)
        
        # åˆ›å»ºå¤šä¸ª chunksï¼Œæ€»å¤§å°è¶…è¿‡é˜ˆå€¼
        chunk_size = 2 * 1024 * 1024  # 2MB per chunk
        num_chunks = 4  # æ€»è®¡ 8MB
        
        # é¢„ç”Ÿæˆ chunks ä»¥ä¾¿è®¡ç®— sha256
        chunks = [secrets.token_bytes(chunk_size) for _ in range(num_chunks)]
        full_content = b"".join(chunks)
        expected_sha256 = hashlib.sha256(full_content).hexdigest()
        
        # Put iterator
        result = object_store.put(key, iter(chunks))
        
        assert result["sha256"] == expected_sha256
        assert result["size_bytes"] == len(full_content)
        
        # éªŒè¯
        retrieved = object_store.get(key)
        assert hashlib.sha256(retrieved).hexdigest() == expected_sha256

    def test_multipart_threshold_boundary(self, object_store, unique_key, cleanup_keys):
        """åˆšå¥½è¾¾åˆ° Multipart é˜ˆå€¼è¾¹ç•Œ"""
        key = f"{unique_key}/boundary.bin"
        cleanup_keys.append(key)
        
        # åˆšå¥½ 5MB - åº”è¯¥ä¸è§¦å‘ multipartï¼ˆé˜ˆå€¼æ˜¯ >=ï¼‰
        size = MULTIPART_THRESHOLD
        content = secrets.token_bytes(size)
        expected_sha256 = hashlib.sha256(content).hexdigest()
        
        result = object_store.put(key, content)
        
        assert result["size_bytes"] == size
        
        retrieved = object_store.get(key)
        assert hashlib.sha256(retrieved).hexdigest() == expected_sha256


# ============ é”™è¯¯å¤„ç†æµ‹è¯• ============


class TestErrorHandling:
    """é”™è¯¯åˆ†ç±»å’Œå¼‚å¸¸å¤„ç†æµ‹è¯•"""

    def test_get_nonexistent_key(self, object_store, unique_key):
        """è®¿é—®ä¸å­˜åœ¨çš„ key åº”æŠ›å‡º ArtifactNotFoundError"""
        key = f"{unique_key}/nonexistent_object.txt"
        
        with pytest.raises(ArtifactNotFoundError) as exc_info:
            object_store.get(key)
        
        error = exc_info.value
        assert "ä¸å­˜åœ¨" in str(error) or "NoSuchKey" in str(error) or "not found" in str(error).lower()

    def test_get_info_nonexistent_key(self, object_store, unique_key):
        """get_info å¯¹ä¸å­˜åœ¨çš„ key åº”æŠ›å‡º ArtifactNotFoundError"""
        key = f"{unique_key}/nonexistent_for_info.txt"
        
        with pytest.raises(ArtifactNotFoundError):
            object_store.get_info(key)

    def test_wrong_bucket_error(self, minio_config):
        """è®¿é—®ä¸å­˜åœ¨çš„ bucket åº”æŠ¥é”™"""
        store = ObjectStore(
            endpoint=minio_config["endpoint"],
            access_key=minio_config["access_key"],
            secret_key=minio_config["secret_key"],
            bucket="definitely-nonexistent-bucket-12345",
        )
        
        with pytest.raises((ObjectStoreUploadError, ObjectStoreDownloadError, Exception)):
            store.put("test.txt", b"content")


# ============ å…ƒæ•°æ®å’Œ URL æµ‹è¯• ============


class TestMetadataAndUrl:
    """å…ƒæ•°æ®å’Œ URL ç›¸å…³æµ‹è¯•"""

    def test_get_info_returns_metadata(self, object_store, unique_key, cleanup_keys):
        """get_info è¿”å›æ­£ç¡®çš„å…ƒæ•°æ®"""
        key = f"{unique_key}/metadata.txt"
        cleanup_keys.append(key)
        
        content = b"content for metadata test"
        expected_sha256 = hashlib.sha256(content).hexdigest()
        
        object_store.put(key, content)
        
        info = object_store.get_info(key)
        
        assert info["uri"] == key
        assert info["sha256"] == expected_sha256
        assert info["size_bytes"] == len(content)

    def test_resolve_returns_s3_url(self, object_store, unique_key):
        """resolve è¿”å› S3 URL æ ¼å¼"""
        key = f"{unique_key}/resolve.txt"
        
        url = object_store.resolve(key)
        
        assert url.startswith("s3://")
        assert object_store.bucket in url
        assert key in url

    def test_presigned_url_generation(self, object_store, unique_key, cleanup_keys):
        """ç”Ÿæˆé¢„ç­¾å URL"""
        key = f"{unique_key}/presigned.txt"
        cleanup_keys.append(key)
        
        content = b"content for presigned url"
        object_store.put(key, content)
        
        # ç”Ÿæˆé¢„ç­¾å URL
        presigned_url = object_store.generate_presigned_url(key, expires_in=3600)
        
        assert presigned_url is not None
        assert "http" in presigned_url
        # URL åº”åŒ…å«ç­¾åå‚æ•°
        assert "Signature" in presigned_url or "X-Amz-Signature" in presigned_url


# ============ æµå¼ä¸‹è½½æµ‹è¯• ============


class TestStreamDownload:
    """æµå¼ä¸‹è½½æµ‹è¯•"""

    def test_get_stream_small_file(self, object_store, unique_key, cleanup_keys):
        """æµå¼ä¸‹è½½å°æ–‡ä»¶"""
        key = f"{unique_key}/stream_small.txt"
        cleanup_keys.append(key)
        
        content = b"content for stream test " * 100
        object_store.put(key, content)
        
        # æµå¼è¯»å–
        chunks = list(object_store.get_stream(key))
        retrieved = b"".join(chunks)
        
        assert retrieved == content

    def test_get_stream_large_file(self, object_store, unique_key, cleanup_keys):
        """æµå¼ä¸‹è½½å¤§æ–‡ä»¶"""
        key = f"{unique_key}/stream_large.bin"
        cleanup_keys.append(key)
        
        # 3MB æ–‡ä»¶
        size = 3 * 1024 * 1024
        content = secrets.token_bytes(size)
        expected_sha256 = hashlib.sha256(content).hexdigest()
        
        object_store.put(key, content)
        
        # æµå¼è¯»å–å¹¶è®¡ç®— sha256
        hasher = hashlib.sha256()
        total_size = 0
        for chunk in object_store.get_stream(key, chunk_size=65536):
            hasher.update(chunk)
            total_size += len(chunk)
        
        assert total_size == size
        assert hasher.hexdigest() == expected_sha256


# ============ å‰ç¼€æµ‹è¯• ============


class TestPrefixOperations:
    """å¸¦å‰ç¼€çš„æ“ä½œæµ‹è¯•"""

    def test_operations_with_prefix(self, minio_config, unique_key, cleanup_keys):
        """å¸¦å‰ç¼€çš„ put/get/exists"""
        prefix = "test_prefix/v1"
        store = ObjectStore(
            endpoint=minio_config["endpoint"],
            access_key=minio_config["access_key"],
            secret_key=minio_config["secret_key"],
            bucket=minio_config["bucket"],
            prefix=prefix,
        )
        
        key = f"{unique_key}/prefixed.txt"
        cleanup_keys.append(f"{prefix}/{key}")  # å®é™… key åŒ…å« prefix
        
        content = b"content with prefix"
        
        # Put
        result = store.put(key, content)
        assert result["uri"] == key
        
        # Exists
        assert store.exists(key) is True
        
        # Get
        retrieved = store.get(key)
        assert retrieved == content
        
        # Resolve
        url = store.resolve(key)
        assert prefix in url
