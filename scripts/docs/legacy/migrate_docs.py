#!/usr/bin/env python3
"""
[HISTORICAL] æ–‡æ¡£è¿ç§»å·¥å…·

================================================================================
çŠ¶æ€: å·²å®Œæˆè¿ç§»ï¼Œä»…ä¾›å®¡è®¡
è¿ç§»æ—¥æœŸ: 2026-01-30
è¯´æ˜: æœ¬è„šæœ¬ç”¨äºå°†åˆ†æ•£åœ¨ apps/*/docs/ ä¸‹çš„æ–‡æ¡£é›†ä¸­è¿ç§»åˆ° docs/ ç›®å½•ã€‚
      è¿ç§»å·¥ä½œå·²å®Œæˆï¼Œæœ¬æ–‡ä»¶ä¿ç•™ç”¨äºï¼š
      1. å®¡è®¡è¿½æº¯ - äº†è§£æ–‡æ¡£è¿ç§»çš„å†å²è¿‡ç¨‹
      2. å‚è€ƒå®ç° - å¦‚éœ€ç±»ä¼¼è¿ç§»å¯å‚è€ƒæœ¬å®ç°

      è¯·å‹¿å†æ¬¡è¿è¡Œæœ¬è„šæœ¬æ‰§è¡Œè¿ç§»æ“ä½œã€‚
================================================================================

è¯»å– scripts/docs_migration_map.json æ˜ å°„é…ç½®ï¼Œæ‰§è¡Œæ–‡æ¡£è¿ç§»å¹¶é‡å†™é“¾æ¥ã€‚

åŠŸèƒ½:
- --dry-run: ä»…è¾“å‡ºè®¡åˆ’å˜æ›´ï¼Œä¸å®é™…æ‰§è¡Œ
- --apply: å®é™…ç§»åŠ¨æ–‡ä»¶å¹¶é‡å†™é“¾æ¥
- è¿ç§»åè‡ªåŠ¨è°ƒç”¨ check_links.py éªŒè¯

ç”¨æ³•:
    python migrate_docs.py --dry-run   # é¢„è§ˆå˜æ›´
    python migrate_docs.py --apply     # æ‰§è¡Œè¿ç§»
"""

import argparse
import json
import os
import re
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple

# Markdown é“¾æ¥æ­£åˆ™è¡¨è¾¾å¼
MD_LINK_PATTERN = re.compile(
    r'(\[([^\]]*)\]\()([^)]+)(\))',
    re.MULTILINE
)


def get_repo_root() -> Path:
    """è·å–ä»“åº“æ ¹ç›®å½•"""
    current = Path(__file__).resolve()
    for parent in [current] + list(current.parents):
        if (parent / '.git').exists() or (parent / 'Makefile').exists():
            return parent
    return Path.cwd()


def load_migration_map(repo_root: Path) -> dict:
    """åŠ è½½è¿ç§»æ˜ å°„é…ç½®"""
    map_path = repo_root / 'scripts' / 'docs' / 'legacy' / 'docs_migration_map.json'
    if not map_path.exists():
        raise FileNotFoundError(f"è¿ç§»æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {map_path}")

    with open(map_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def build_path_mapping(migration_map: dict) -> Dict[str, str]:
    """
    æ„å»ºè·¯å¾„æ˜ å°„å­—å…¸

    è¿”å›: {source_path: target_path}
    """
    mapping = {}
    for item in migration_map.get('file_mappings', []):
        source = item['source']
        target = item['target']
        mapping[source] = target
    return mapping


def compute_relative_path(from_file: str, to_file: str) -> str:
    """
    è®¡ç®—ä»ä¸€ä¸ªæ–‡ä»¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶çš„ç›¸å¯¹è·¯å¾„

    Args:
        from_file: æºæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºä»“åº“æ ¹ï¼‰
        to_file: ç›®æ ‡æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºä»“åº“æ ¹ï¼‰

    Returns:
        ç›¸å¯¹è·¯å¾„å­—ç¬¦ä¸²
    """
    from_path = Path(from_file).parent
    to_path = Path(to_file)

    try:
        rel_path = os.path.relpath(to_path, from_path)
        # ç¡®ä¿è·¯å¾„æ ¼å¼ä¸€è‡´ï¼ˆä½¿ç”¨æ­£æ–œæ ï¼‰
        rel_path = rel_path.replace('\\', '/')
        return rel_path
    except ValueError:
        # åœ¨ Windows ä¸Šè·¨é©±åŠ¨å™¨æ—¶å¯èƒ½å¤±è´¥
        return to_file


def rewrite_md_link(
    link_target: str,
    current_file_old_path: str,
    current_file_new_path: str,
    path_mapping: Dict[str, str],
    repo_root: Path
) -> Tuple[str, bool]:
    """
    é‡å†™å•ä¸ª Markdown é“¾æ¥

    Args:
        link_target: åŸå§‹é“¾æ¥ç›®æ ‡
        current_file_old_path: å½“å‰æ–‡ä»¶çš„åŸè·¯å¾„ï¼ˆç›¸å¯¹äºä»“åº“æ ¹ï¼‰
        current_file_new_path: å½“å‰æ–‡ä»¶çš„æ–°è·¯å¾„ï¼ˆç›¸å¯¹äºä»“åº“æ ¹ï¼‰
        path_mapping: æ–‡ä»¶è¿ç§»æ˜ å°„ {old: new}
        repo_root: ä»“åº“æ ¹ç›®å½•

    Returns:
        (æ–°é“¾æ¥ç›®æ ‡, æ˜¯å¦è¢«ä¿®æ”¹)
    """
    # è·³è¿‡å¤–éƒ¨é“¾æ¥
    if any(link_target.startswith(prefix) for prefix in ('http://', 'https://', 'mailto:', 'ftp://')):
        return link_target, False

    # è·³è¿‡çº¯é”šç‚¹é“¾æ¥
    if link_target.startswith('#'):
        return link_target, False

    # åˆ†ç¦»é”šç‚¹
    if '#' in link_target:
        path_part, anchor = link_target.split('#', 1)
        anchor = '#' + anchor
    else:
        path_part, anchor = link_target, ''

    if not path_part:
        return link_target, False

    # è§£æé“¾æ¥æŒ‡å‘çš„ç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºä»“åº“æ ¹ï¼‰
    old_file_dir = Path(current_file_old_path).parent
    linked_file_path = (old_file_dir / path_part).as_posix()

    # è§„èŒƒåŒ–è·¯å¾„ï¼ˆå¤„ç† ../ ç­‰ï¼‰
    try:
        linked_file_path = os.path.normpath(linked_file_path).replace('\\', '/')
    except Exception:
        return link_target, False

    # æ£€æŸ¥é“¾æ¥ç›®æ ‡æ˜¯å¦åœ¨è¿ç§»æ˜ å°„ä¸­
    if linked_file_path in path_mapping:
        # ç›®æ ‡æ–‡ä»¶ä¹Ÿè¢«è¿ç§»äº†ï¼Œè®¡ç®—æ–°çš„ç›¸å¯¹è·¯å¾„
        new_linked_path = path_mapping[linked_file_path]
        new_rel_path = compute_relative_path(current_file_new_path, new_linked_path)
        return new_rel_path + anchor, True

    # ç›®æ ‡æ–‡ä»¶æœªè¿ç§»ï¼Œä½†å½“å‰æ–‡ä»¶è¿ç§»äº†ï¼Œéœ€è¦é‡æ–°è®¡ç®—ç›¸å¯¹è·¯å¾„
    if current_file_old_path != current_file_new_path:
        # æ£€æŸ¥åŸå§‹é“¾æ¥æŒ‡å‘çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        old_target_abs = repo_root / linked_file_path
        if old_target_abs.exists():
            new_rel_path = compute_relative_path(current_file_new_path, linked_file_path)
            return new_rel_path + anchor, True

    return link_target, False


def rewrite_file_content(
    content: str,
    old_path: str,
    new_path: str,
    path_mapping: Dict[str, str],
    repo_root: Path
) -> Tuple[str, List[Tuple[str, str]]]:
    """
    é‡å†™æ–‡ä»¶å†…å®¹ä¸­çš„æ‰€æœ‰é“¾æ¥

    Returns:
        (æ–°å†…å®¹, [(åŸé“¾æ¥, æ–°é“¾æ¥), ...])
    """
    changes = []

    def replace_link(match):
        prefix = match.group(1)  # [text](
        match.group(2)  # text
        link_target = match.group(3)  # path
        suffix = match.group(4)  # )

        new_target, changed = rewrite_md_link(
            link_target, old_path, new_path, path_mapping, repo_root
        )

        if changed:
            changes.append((link_target, new_target))

        return f"{prefix}{new_target}{suffix}"

    new_content = MD_LINK_PATTERN.sub(replace_link, content)
    return new_content, changes


def rewrite_reference_in_code(
    content: str,
    rewrite_rules: List[dict],
    file_path: str
) -> Tuple[str, List[Tuple[str, str]]]:
    """
    æ ¹æ®é‡å†™è§„åˆ™å¤„ç†ä»£ç /é…ç½®æ–‡ä»¶ä¸­çš„æ–‡æ¡£å¼•ç”¨

    Returns:
        (æ–°å†…å®¹, [(åŸå¼•ç”¨, æ–°å¼•ç”¨), ...])
    """
    changes = []

    # æŸ¥æ‰¾é€‚ç”¨äºå½“å‰æ–‡ä»¶çš„è§„åˆ™
    for rule in rewrite_rules:
        if rule.get('path') != file_path:
            continue

        current_ref = rule.get('current_reference')
        new_ref = rule.get('new_reference')

        if not current_ref or not new_ref:
            continue

        if current_ref in content:
            content = content.replace(current_ref, new_ref)
            changes.append((current_ref, new_ref))

    return content, changes


def find_all_md_files(repo_root: Path, exclude_dirs: Set[str] = None) -> List[Path]:
    """æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶"""
    if exclude_dirs is None:
        exclude_dirs = {'node_modules', '.git', 'archives', '__pycache__'}

    md_files = []
    for root, dirs, files in os.walk(repo_root):
        # æ’é™¤ç›®å½•
        dirs[:] = [d for d in dirs if d not in exclude_dirs]

        for file in files:
            if file.endswith('.md'):
                md_files.append(Path(root) / file)

    return md_files


def run_link_check(repo_root: Path, migration_map: dict) -> bool:
    """
    è¿è¡Œé“¾æ¥æ£€æŸ¥è„šæœ¬

    Returns:
        True å¦‚æœæ£€æŸ¥é€šè¿‡
    """
    check_script = repo_root / 'scripts' / 'docs' / 'check_links.py'

    if not check_script.exists():
        print("Warning: é“¾æ¥æ£€æŸ¥è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡éªŒè¯", file=sys.stderr)
        return True

    # æ”¶é›†è¿ç§»åçš„ç›®æ ‡ç›®å½•
    target_dirs = set()
    for item in migration_map.get('file_mappings', []):
        target_path = Path(item['target'])
        target_dirs.add(str(target_path.parent))

    # æ„å»ºå‘½ä»¤è¡Œå‚æ•°ï¼ˆä½¿ç”¨ä½ç½®å‚æ•°ï¼‰
    cmd = [sys.executable, str(check_script)]
    cmd.extend(sorted(target_dirs))

    try:
        result = subprocess.run(
            cmd,
            cwd=repo_root,
            capture_output=True,
            text=True
        )

        if result.returncode != 0:
            print("é“¾æ¥æ£€æŸ¥å¤±è´¥:", file=sys.stderr)
            if result.stdout:
                print(result.stdout)
            if result.stderr:
                print(result.stderr, file=sys.stderr)
            return False

        print(result.stdout)
        return True

    except Exception as e:
        print(f"è¿è¡Œé“¾æ¥æ£€æŸ¥æ—¶å‡ºé”™: {e}", file=sys.stderr)
        return False


def dry_run(repo_root: Path, migration_map: dict) -> int:
    """
    é¢„è§ˆæ¨¡å¼ï¼šæ˜¾ç¤ºè®¡åˆ’çš„å˜æ›´
    """
    path_mapping = build_path_mapping(migration_map)

    print("=" * 60)
    print("æ–‡æ¡£è¿ç§»é¢„è§ˆ (--dry-run)")
    print("=" * 60)
    print()

    # 1. æ–‡ä»¶ç§»åŠ¨è®¡åˆ’
    print("ğŸ“ æ–‡ä»¶ç§»åŠ¨è®¡åˆ’:")
    print("-" * 40)

    for old_path, new_path in path_mapping.items():
        old_abs = repo_root / old_path
        status = "âœ“ å­˜åœ¨" if old_abs.exists() else "âœ— ä¸å­˜åœ¨"
        print(f"  {old_path}")
        print(f"    â†’ {new_path}")
        print(f"      [{status}]")
        print()

    # 2. é“¾æ¥é‡å†™é¢„è§ˆ
    print()
    print("ğŸ”— é“¾æ¥é‡å†™é¢„è§ˆ:")
    print("-" * 40)

    total_link_changes = 0

    for old_path, new_path in path_mapping.items():
        old_abs = repo_root / old_path
        if not old_abs.exists():
            continue

        try:
            content = old_abs.read_text(encoding='utf-8')
        except Exception:
            continue

        _, changes = rewrite_file_content(
            content, old_path, new_path, path_mapping, repo_root
        )

        if changes:
            print(f"  {old_path}:")
            for old_link, new_link in changes:
                print(f"    {old_link} â†’ {new_link}")
            total_link_changes += len(changes)

    if total_link_changes == 0:
        print("  (æ— é“¾æ¥éœ€è¦é‡å†™)")

    # 3. å¼•ç”¨é‡å†™é¢„è§ˆ
    print()
    print("ğŸ“ ä»£ç å¼•ç”¨é‡å†™é¢„è§ˆ:")
    print("-" * 40)

    rewrite_rules = migration_map.get('reference_rewrite_rules', {}).get('files', [])
    ref_changes = 0

    for rule in rewrite_rules:
        if rule.get('current_reference') and rule.get('new_reference'):
            print(f"  {rule['path']}:")
            print(f"    {rule['current_reference']} â†’ {rule['new_reference']}")
            ref_changes += 1
        elif rule.get('action') == 'review':
            print(f"  {rule['path']}: [éœ€è¦äººå·¥å®¡æŸ¥]")

    if ref_changes == 0:
        print("  (æ— å¼•ç”¨éœ€è¦è‡ªåŠ¨é‡å†™)")

    # 4. æ±‡æ€»
    print()
    print("=" * 60)
    print("æ±‡æ€»:")
    print(f"  - å¾…ç§»åŠ¨æ–‡ä»¶: {len(path_mapping)}")
    print(f"  - å¾…é‡å†™é“¾æ¥: {total_link_changes}")
    print(f"  - å¾…é‡å†™å¼•ç”¨: {ref_changes}")
    print()
    print("ä½¿ç”¨ --apply æ‰§è¡Œå®é™…è¿ç§»")
    print("=" * 60)

    return 0


def apply_migration(repo_root: Path, migration_map: dict) -> int:
    """
    æ‰§è¡Œå®é™…è¿ç§»
    """
    path_mapping = build_path_mapping(migration_map)

    print("=" * 60)
    print("æ‰§è¡Œæ–‡æ¡£è¿ç§» (--apply)")
    print("=" * 60)
    print()

    errors = []

    # 1. åˆ›å»ºç›®æ ‡ç›®å½•
    print("ğŸ“ åˆ›å»ºç›®æ ‡ç›®å½•...")
    target_dirs = migration_map.get('target_directories', {})
    for name, dir_path in target_dirs.items():
        target_dir = repo_root / dir_path
        target_dir.mkdir(parents=True, exist_ok=True)
        print(f"  âœ“ {dir_path}")
    print()

    # 2. ç§»åŠ¨æ–‡ä»¶å¹¶é‡å†™é“¾æ¥
    print("ğŸ“„ è¿ç§»æ–‡ä»¶å¹¶é‡å†™é“¾æ¥...")

    for old_path, new_path in path_mapping.items():
        old_abs = repo_root / old_path
        new_abs = repo_root / new_path

        if not old_abs.exists():
            print(f"  âœ— è·³è¿‡ï¼ˆæºæ–‡ä»¶ä¸å­˜åœ¨ï¼‰: {old_path}")
            errors.append(f"æºæ–‡ä»¶ä¸å­˜åœ¨: {old_path}")
            continue

        try:
            # è¯»å–å†…å®¹
            content = old_abs.read_text(encoding='utf-8')

            # é‡å†™é“¾æ¥
            new_content, changes = rewrite_file_content(
                content, old_path, new_path, path_mapping, repo_root
            )

            # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            new_abs.parent.mkdir(parents=True, exist_ok=True)

            # å†™å…¥æ–°ä½ç½®
            new_abs.write_text(new_content, encoding='utf-8')

            # åˆ é™¤åŸæ–‡ä»¶
            old_abs.unlink()

            status = f"({len(changes)} é“¾æ¥é‡å†™)" if changes else ""
            print(f"  âœ“ {old_path} â†’ {new_path} {status}")

        except Exception as e:
            print(f"  âœ— è¿ç§»å¤±è´¥: {old_path} - {e}")
            errors.append(f"è¿ç§»å¤±è´¥ {old_path}: {e}")

    print()

    # 3. é‡å†™å…¶ä»–æ–‡ä»¶ä¸­çš„å¼•ç”¨
    print("ğŸ”— æ›´æ–°å…¶ä»–æ–‡ä»¶ä¸­çš„å¼•ç”¨...")

    rewrite_rules = migration_map.get('reference_rewrite_rules', {}).get('files', [])

    for rule in rewrite_rules:
        file_path = rule.get('path')
        current_ref = rule.get('current_reference')
        new_ref = rule.get('new_reference')

        if not current_ref or not new_ref:
            if rule.get('action') == 'review':
                print(f"  âš  éœ€è¦äººå·¥å®¡æŸ¥: {file_path}")
            continue

        file_abs = repo_root / file_path
        if not file_abs.exists():
            print(f"  âœ— æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        try:
            content = file_abs.read_text(encoding='utf-8')

            if current_ref in content:
                new_content = content.replace(current_ref, new_ref)
                file_abs.write_text(new_content, encoding='utf-8')
                print(f"  âœ“ {file_path}: {current_ref} â†’ {new_ref}")
            else:
                print(f"  - {file_path}: æœªæ‰¾åˆ°å¼•ç”¨ '{current_ref}'")

        except Exception as e:
            print(f"  âœ— æ›´æ–°å¤±è´¥: {file_path} - {e}")
            errors.append(f"æ›´æ–°å¼•ç”¨å¤±è´¥ {file_path}: {e}")

    print()

    # 4. æ›´æ–°æ‰€æœ‰å·²è¿ç§»ç›®å½•ä¸­çš„ MD æ–‡ä»¶çš„è·¨æ–‡ä»¶å¼•ç”¨
    print("ğŸ”„ æ›´æ–°å·²è¿ç§»ç›®å½•ä¸­çš„äº¤å‰å¼•ç”¨...")

    new_docs_dirs = set()
    for new_path in path_mapping.values():
        new_docs_dirs.add(Path(new_path).parent)

    for docs_dir in new_docs_dirs:
        docs_abs = repo_root / docs_dir
        if not docs_abs.exists():
            continue

        for md_file in docs_abs.glob('*.md'):
            try:
                content = md_file.read_text(encoding='utf-8')
                rel_path = str(md_file.relative_to(repo_root)).replace('\\', '/')

                # è¿™ä¸ªæ–‡ä»¶å¦‚æœåœ¨æ˜ å°„ä¸­ï¼Œå·²ç»å¤„ç†è¿‡äº†
                if rel_path in path_mapping.values():
                    continue

                # æ£€æŸ¥æ˜¯å¦æœ‰æŒ‡å‘æ—§è·¯å¾„çš„é“¾æ¥
                new_content, changes = rewrite_file_content(
                    content, rel_path, rel_path, path_mapping, repo_root
                )

                if changes:
                    md_file.write_text(new_content, encoding='utf-8')
                    print(f"  âœ“ {rel_path}: {len(changes)} é“¾æ¥æ›´æ–°")

            except Exception as e:
                print(f"  âœ— å¤„ç†å¤±è´¥: {md_file} - {e}")

    print()

    # 5. è¿è¡Œé“¾æ¥æ£€æŸ¥
    print("=" * 60)
    print("ğŸ” è¿è¡Œé“¾æ¥æ£€æŸ¥éªŒè¯...")
    print()

    if not run_link_check(repo_root, migration_map):
        print()
        print("âŒ é“¾æ¥æ£€æŸ¥å¤±è´¥ï¼è¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ã€‚")
        return 1

    print()
    print("=" * 60)

    if errors:
        print(f"âš  è¿ç§»å®Œæˆï¼Œä½†æœ‰ {len(errors)} ä¸ªè­¦å‘Š:")
        for err in errors:
            print(f"  - {err}")
        return 1
    else:
        print("âœ… è¿ç§»å®Œæˆï¼")

    print("=" * 60)
    return 0


def main():
    print("=" * 60)
    print("[HISTORICAL] æœ¬è„šæœ¬å·²å®Œæˆå†å²ä½¿å‘½ï¼Œä»…ä¾›å®¡è®¡å‚è€ƒ")
    print("è¿ç§»å·¥ä½œå·²äº 2026-01-30 å®Œæˆ")
    print("=" * 60)
    print()

    parser = argparse.ArgumentParser(
        description='[HISTORICAL] æ–‡æ¡£è¿ç§»å·¥å…· - å·²å®Œæˆè¿ç§»ï¼Œä»…ä¾›å®¡è®¡'
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        '--dry-run',
        action='store_true',
        help='é¢„è§ˆæ¨¡å¼ï¼šä»…æ˜¾ç¤ºè®¡åˆ’å˜æ›´ï¼Œä¸å®é™…æ‰§è¡Œ'
    )
    group.add_argument(
        '--apply',
        action='store_true',
        help='æ‰§è¡Œæ¨¡å¼ï¼šå®é™…ç§»åŠ¨æ–‡ä»¶å¹¶é‡å†™é“¾æ¥'
    )

    args = parser.parse_args()

    repo_root = get_repo_root()
    print(f"ä»“åº“æ ¹ç›®å½•: {repo_root}")
    print()

    try:
        migration_map = load_migration_map(repo_root)
    except FileNotFoundError as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"é”™è¯¯: è¿ç§»æ˜ å°„æ–‡ä»¶æ ¼å¼é”™è¯¯ - {e}", file=sys.stderr)
        sys.exit(1)

    if args.dry_run:
        sys.exit(dry_run(repo_root, migration_map))
    elif args.apply:
        sys.exit(apply_migration(repo_root, migration_map))


if __name__ == '__main__':
    main()
