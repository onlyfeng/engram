#!/usr/bin/env python3
"""
è¿­ä»£æ–‡æ¡£å®¡è®¡è„šæœ¬

åŠŸèƒ½:
1. æ‰«æ docs/acceptance/ ç›®å½•ä¸­çš„è¿­ä»£æ–‡ä»¶
2. è§£æ 00_acceptance_matrix.md ç´¢å¼•è¡¨
3. æ£€æŸ¥ SUPERSEDED å£°æ˜ä¸€è‡´æ€§
4. ç”Ÿæˆå®¡è®¡æŠ¥å‘Šï¼ˆMarkdown æ ¼å¼ï¼‰

è¾“å‡º:
- é»˜è®¤è¾“å‡ºåˆ° stdout
- ä½¿ç”¨ --output-dir è¾“å‡ºåˆ° .artifacts/iteration-audit/

ç”¨æ³•:
    # è¾“å‡ºåˆ° stdout
    python scripts/iteration/audit_iteration_docs.py

    # è¾“å‡ºåˆ°æ–‡ä»¶
    python scripts/iteration/audit_iteration_docs.py --output-dir .artifacts/iteration-audit

    # è¯¦ç»†æ¨¡å¼
    python scripts/iteration/audit_iteration_docs.py --verbose

å®šä½è¯´æ˜:
- æœ¬è„šæœ¬ç”¨äºç”Ÿæˆä¸€æ¬¡æ€§å®¡è®¡æŠ¥å‘Š
- å®¡è®¡æŠ¥å‘Šä¸ºé SSOTï¼Œä»…ä½œä¸ºä¸´æ—¶å‚è€ƒ
- CI é—¨ç¦æ£€æŸ¥è¯·ä½¿ç”¨ scripts/ci/check_no_iteration_links_in_docs.py
"""

from __future__ import annotations

import argparse
import re
import sys
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Optional

# ============================================================================
# æ•°æ®ç»“æ„
# ============================================================================


@dataclass
class IterationFile:
    """è¿­ä»£æ–‡ä»¶ä¿¡æ¯ã€‚"""

    iteration_number: int
    file_type: str  # "plan" or "regression"
    path: Path
    has_superseded_header: bool = False
    superseded_successor: Optional[int] = None


@dataclass
class IterationIndexEntry:
    """ç´¢å¼•è¡¨æ¡ç›®ã€‚"""

    iteration_number: int
    date: str
    status: str
    plan_link: Optional[str]
    regression_link: Optional[str]
    description: str
    row_index: int

    @property
    def is_superseded(self) -> bool:
        return "SUPERSEDED" in self.status.upper()

    def get_successor_number(self) -> Optional[int]:
        """ä»æè¿°ä¸­æå–åç»§è¿­ä»£ç¼–å·ã€‚"""
        match = re.search(
            r"å·²è¢«\s*Iteration\s*(\d+)\s*å–ä»£|Superseded\s+by\s+Iteration\s*(\d+)",
            self.description,
            re.IGNORECASE,
        )
        if match:
            return int(match.group(1) or match.group(2))
        return None


@dataclass
class AuditResult:
    """å®¡è®¡ç»“æœã€‚"""

    files: list[IterationFile]
    index_entries: list[IterationIndexEntry]
    inconsistencies: list[tuple[str, int, str]]  # (ç±»å‹, è¿­ä»£å·, æè¿°)
    missing_files: list[str]
    orphan_files: list[str]


# ============================================================================
# æ‰«æä¸è§£æ
# ============================================================================


def scan_iteration_files(acceptance_dir: Path) -> list[IterationFile]:
    """æ‰«æè¿­ä»£æ–‡ä»¶ã€‚"""
    files: list[IterationFile] = []
    pattern = re.compile(r"iteration_(\d+)_(plan|regression)\.md$")

    if not acceptance_dir.exists():
        return files

    for filepath in sorted(acceptance_dir.glob("iteration_*_*.md")):
        match = pattern.match(filepath.name)
        if not match:
            continue

        iter_num = int(match.group(1))
        file_type = match.group(2)

        # æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨æ˜¯å¦æœ‰ superseded å£°æ˜
        # æ³¨æ„ï¼šä»¥ä¸‹æ£€æŸ¥é€»è¾‘ä¸ scripts/ci/check_no_iteration_links_in_docs.py çš„
        # check_regression_file_superseded_header å‡½æ•°ä¿æŒä¸€è‡´ï¼ˆåŒä¸€ regex / åŒä¸€ä½ç½®çº¦æŸï¼‰
        # - ä½ç½®çº¦æŸï¼šæ£€æŸ¥å‰ 20 è¡Œ
        # - æ­£åˆ™è¡¨è¾¾å¼ï¼šr"Superseded\s+by\s+Iteration\s*(\d+)"ï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
        has_header = False
        successor = None
        try:
            content = filepath.read_text(encoding="utf-8")
            for line in content.splitlines()[:20]:
                if re.search(r"Superseded\s+by\s+Iteration\s*(\d+)", line, re.IGNORECASE):
                    has_header = True
                    m = re.search(r"Iteration\s*(\d+)", line, re.IGNORECASE)
                    if m:
                        successor = int(m.group(1))
                    break
        except Exception:
            pass

        files.append(
            IterationFile(
                iteration_number=iter_num,
                file_type=file_type,
                path=filepath,
                has_superseded_header=has_header,
                superseded_successor=successor,
            )
        )

    return files


def parse_acceptance_matrix(matrix_path: Path) -> list[IterationIndexEntry]:
    """è§£æç´¢å¼•è¡¨ã€‚"""
    if not matrix_path.exists():
        return []

    content = matrix_path.read_text(encoding="utf-8")
    entries: list[IterationIndexEntry] = []

    lines = content.splitlines()
    in_index_section = False
    in_table = False
    row_index = 0

    for line in lines:
        if "è¿­ä»£å›å½’è®°å½•ç´¢å¼•" in line and line.strip().startswith("#"):
            in_index_section = True
            continue

        if not in_index_section:
            continue

        if line.strip().startswith("#") and "è¿­ä»£å›å½’è®°å½•ç´¢å¼•" not in line:
            break

        stripped = line.strip()
        if not stripped.startswith("|"):
            continue

        if "è¿­ä»£" in stripped and "æ—¥æœŸ" in stripped:
            in_table = True
            continue
        if re.match(r"^\|[\s\-:]+\|", stripped):
            continue

        if not in_table:
            continue

        cells = [c.strip() for c in stripped.split("|")]
        if len(cells) < 7:
            continue

        iter_cell = cells[1]
        date_cell = cells[2]
        status_cell = cells[3]
        plan_cell = cells[4]
        regression_cell = cells[5]
        desc_cell = cells[6] if len(cells) > 6 else ""

        iter_match = re.search(r"Iteration\s*(\d+)", iter_cell, re.IGNORECASE)
        if not iter_match:
            continue

        iteration_number = int(iter_match.group(1))

        plan_link_match = re.search(r"\[([^\]]+)\]\(([^)]+)\)", plan_cell)
        regression_link_match = re.search(r"\[([^\]]+)\]\(([^)]+)\)", regression_cell)

        entry = IterationIndexEntry(
            iteration_number=iteration_number,
            date=date_cell,
            status=status_cell,
            plan_link=plan_link_match.group(2) if plan_link_match else None,
            regression_link=regression_link_match.group(2) if regression_link_match else None,
            description=desc_cell,
            row_index=row_index,
        )
        entries.append(entry)
        row_index += 1

    return entries


def run_audit(project_root: Path) -> AuditResult:
    """æ‰§è¡Œå®¡è®¡ã€‚"""
    acceptance_dir = project_root / "docs" / "acceptance"
    matrix_path = acceptance_dir / "00_acceptance_matrix.md"

    # æ‰«ææ–‡ä»¶
    files = scan_iteration_files(acceptance_dir)

    # è§£æç´¢å¼•
    index_entries = parse_acceptance_matrix(matrix_path)

    # æ„å»ºç´¢å¼•æ˜ å°„
    indexed_iters = {e.iteration_number: e for e in index_entries}

    # æ£€æŸ¥ä¸ä¸€è‡´
    inconsistencies: list[tuple[str, int, str]] = []
    missing_files: list[str] = []
    orphan_files: list[str] = []

    # æ£€æŸ¥ SUPERSEDED ä¸€è‡´æ€§
    for entry in index_entries:
        if not entry.is_superseded:
            continue

        successor = entry.get_successor_number()
        if successor is None:
            inconsistencies.append(
                (
                    "SUPERSEDED_NO_SUCCESSOR",
                    entry.iteration_number,
                    "ç´¢å¼•æ ‡è®°ä¸º SUPERSEDED ä½†æœªå£°æ˜åç»§",
                )
            )
            continue

        # æ£€æŸ¥ regression æ–‡ä»¶æ˜¯å¦æœ‰ superseded å£°æ˜
        regression_files = [
            f
            for f in files
            if f.iteration_number == entry.iteration_number and f.file_type == "regression"
        ]
        if regression_files:
            rf = regression_files[0]
            if not rf.has_superseded_header:
                inconsistencies.append(
                    (
                        "SUPERSEDED_MISSING_HEADER",
                        entry.iteration_number,
                        f"regression æ–‡ä»¶ç¼ºå°‘ superseded å£°æ˜ï¼ˆæœŸæœ›åç»§: Iteration {successor}ï¼‰",
                    )
                )
            elif rf.superseded_successor != successor:
                inconsistencies.append(
                    (
                        "SUPERSEDED_MISMATCH",
                        entry.iteration_number,
                        f"regression æ–‡ä»¶å£°æ˜åç»§ ({rf.superseded_successor}) ä¸ç´¢å¼• ({successor}) ä¸ä¸€è‡´",
                    )
                )

    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    for entry in index_entries:
        if entry.regression_link and entry.regression_link != "-":
            if not (acceptance_dir / entry.regression_link).exists():
                missing_files.append(entry.regression_link)
        if entry.plan_link and entry.plan_link != "-":
            if not (acceptance_dir / entry.plan_link).exists():
                missing_files.append(entry.plan_link)

    # æ£€æŸ¥å­¤å„¿æ–‡ä»¶
    for f in files:
        if f.iteration_number not in indexed_iters:
            orphan_files.append(f.path.name)

    return AuditResult(
        files=files,
        index_entries=index_entries,
        inconsistencies=inconsistencies,
        missing_files=missing_files,
        orphan_files=orphan_files,
    )


# ============================================================================
# æŠ¥å‘Šç”Ÿæˆ
# ============================================================================


def generate_report(result: AuditResult, project_root: Path) -> str:
    """ç”Ÿæˆ Markdown æ ¼å¼çš„å®¡è®¡æŠ¥å‘Šã€‚"""
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    lines = [
        "# è¿­ä»£æ–‡æ¡£å®¡è®¡æŠ¥å‘Š",
        "",
        "> **ç”Ÿæˆæ—¶é—´**: " + now,
        ">",
        "> **é SSOT**: æœ¬æŠ¥å‘Šä¸ºä¸€æ¬¡æ€§å®¡è®¡å¿«ç…§ï¼Œä¸ä½œä¸ºæƒå¨æ¥æºã€‚",
        "> è¯·ä»¥ `docs/acceptance/00_acceptance_matrix.md` ä¸ºå‡†ã€‚",
        "",
        "---",
        "",
        "## 1. å®¡è®¡èŒƒå›´",
        "",
        "- **ç´¢å¼•æ–‡ä»¶**: `docs/acceptance/00_acceptance_matrix.md`",
        "- **æ‰«æç›®å½•**: `docs/acceptance/`",
        "- **æ‰«ææ¨¡å¼**: `iteration_*_{plan,regression}.md`",
        "",
        "---",
        "",
        "## 2. æ–‡ä»¶æ‰«æç»“æœ",
        "",
        "### 2.1 å‘ç°çš„è¿­ä»£æ–‡ä»¶",
        "",
        "| è¿­ä»£ | Plan æ–‡ä»¶ | Regression æ–‡ä»¶ | Superseded å£°æ˜ |",
        "|------|-----------|-----------------|-----------------|",
    ]

    # æŒ‰è¿­ä»£å·åˆ†ç»„
    iter_nums = sorted(set(f.iteration_number for f in result.files))
    for iter_num in iter_nums:
        plan_files = [
            f for f in result.files if f.iteration_number == iter_num and f.file_type == "plan"
        ]
        regression_files = [
            f
            for f in result.files
            if f.iteration_number == iter_num and f.file_type == "regression"
        ]

        plan_status = f"âœ… `{plan_files[0].path.name}`" if plan_files else "âŒ æ— "
        regression_status = f"âœ… `{regression_files[0].path.name}`" if regression_files else "âŒ æ— "

        superseded_status = "-"
        if regression_files and regression_files[0].has_superseded_header:
            superseded_status = f"âœ… Iteration {regression_files[0].superseded_successor}"
        elif regression_files:
            superseded_status = "âŒ æ— "

        lines.append(
            f"| Iteration {iter_num} | {plan_status} | {regression_status} | {superseded_status} |"
        )

    plan_count = len([f for f in result.files if f.file_type == "plan"])
    regression_count = len([f for f in result.files if f.file_type == "regression"])
    lines.append("")
    lines.append(f"**å…±è®¡**: {regression_count} ä¸ª regression æ–‡ä»¶ï¼Œ{plan_count} ä¸ª plan æ–‡ä»¶")

    # ç´¢å¼•ä¸æ–‡ä»¶å¯¹ç…§
    lines.extend(
        [
            "",
            "---",
            "",
            "## 3. ç´¢å¼•ä¸æ–‡ä»¶ä¸€è‡´æ€§å¯¹ç…§",
            "",
            "### 3.1 è¿­ä»£å›å½’è®°å½•ç´¢å¼•ï¼ˆæ¥è‡ª `00_acceptance_matrix.md`ï¼‰",
            "",
            "| è¿­ä»£ | æ—¥æœŸ | ç´¢å¼•çŠ¶æ€ | ç´¢å¼•è¯´æ˜ |",
            "|------|------|----------|----------|",
        ]
    )

    for entry in result.index_entries:
        lines.append(
            f"| Iteration {entry.iteration_number} | {entry.date} | {entry.status} | {entry.description} |"
        )

    # SUPERSEDED æ£€æŸ¥ç»“æœ
    superseded_entries = [e for e in result.index_entries if e.is_superseded]
    if superseded_entries:
        lines.extend(
            [
                "",
                "### 3.2 Superseded å£°æ˜æ£€æŸ¥ç»“æœ",
                "",
                "| è¿­ä»£ | ç´¢å¼•çŠ¶æ€ | æ–‡ä»¶ Superseded å£°æ˜ | ä¸€è‡´æ€§ | å¤‡æ³¨ |",
                "|------|----------|----------------------|--------|------|",
            ]
        )

        for entry in result.index_entries:
            successor = entry.get_successor_number()
            regression_files = [
                f
                for f in result.files
                if f.iteration_number == entry.iteration_number and f.file_type == "regression"
            ]

            if entry.is_superseded:
                if regression_files:
                    rf = regression_files[0]
                    if rf.has_superseded_header:
                        if rf.superseded_successor == successor:
                            consistency = "âœ… ä¸€è‡´"
                            note = f'å£°æ˜: "Superseded by Iteration {rf.superseded_successor}"'
                        else:
                            consistency = "âŒ **ä¸ä¸€è‡´**"
                            note = f"æ–‡ä»¶å£°æ˜ Iteration {rf.superseded_successor}ï¼Œç´¢å¼•å£°æ˜ Iteration {successor}"
                        file_status = "âœ… æœ‰å£°æ˜"
                    else:
                        consistency = "âŒ **ä¸ä¸€è‡´**"
                        note = "ç´¢å¼•æ ‡è®°ä¸º SUPERSEDEDï¼Œä½†æ–‡ä»¶ç¼ºå°‘å£°æ˜"
                        file_status = "âŒ **æ— å£°æ˜**"
                else:
                    consistency = "âš ï¸ æœªçŸ¥"
                    note = "regression æ–‡ä»¶ä¸å­˜åœ¨"
                    file_status = "-"
            else:
                consistency = "âœ… ä¸€è‡´"
                note = "é SUPERSEDED çŠ¶æ€ï¼Œæ— éœ€å£°æ˜"
                file_status = (
                    "âŒ æ— å£°æ˜"
                    if regression_files and not regression_files[0].has_superseded_header
                    else "-"
                )

            lines.append(
                f"| Iteration {entry.iteration_number} | {entry.status} | {file_status} | {consistency} | {note} |"
            )

    # å‘ç°çš„é—®é¢˜
    lines.extend(
        [
            "",
            "---",
            "",
            "## 4. å‘ç°çš„é—®é¢˜",
            "",
        ]
    )

    if result.inconsistencies or result.missing_files or result.orphan_files:
        if result.inconsistencies:
            lines.append("### 4.1 ğŸ”´ ä¸ä¸€è‡´é¡¹")
            lines.append("")
            lines.append("| # | é—®é¢˜æè¿° | è¿­ä»£ | è¯¦æƒ… |")
            lines.append("|---|----------|------|------|")
            for i, (type_, iter_num, desc) in enumerate(result.inconsistencies, 1):
                lines.append(f"| {i} | **{type_}** | Iteration {iter_num} | {desc} |")
            lines.append("")

        if result.missing_files:
            lines.append("### 4.2 ğŸŸ¡ ç¼ºå¤±æ–‡ä»¶")
            lines.append("")
            for f in result.missing_files:
                lines.append(f"- `{f}`")
            lines.append("")

        if result.orphan_files:
            lines.append("### 4.3 ğŸŸ  å­¤å„¿æ–‡ä»¶ï¼ˆæœªè¢«ç´¢å¼•ï¼‰")
            lines.append("")
            for f in result.orphan_files:
                lines.append(f"- `{f}`")
            lines.append("")
    else:
        lines.append("âœ… æœªå‘ç°é—®é¢˜")
        lines.append("")

    # å®¡è®¡æ€»ç»“
    lines.extend(
        [
            "---",
            "",
            "## 5. å®¡è®¡æ€»ç»“",
            "",
            "| æŒ‡æ ‡ | ç»“æœ |",
            "|------|------|",
            f"| æ€»è¿­ä»£æ•°ï¼ˆç´¢å¼•ä¸­ï¼‰ | {len(result.index_entries)} |",
            f"| Regression æ–‡ä»¶æ•° | {regression_count} |",
            f"| Plan æ–‡ä»¶æ•° | {plan_count} |",
            f"| SUPERSEDED çŠ¶æ€è¿­ä»£ | {len(superseded_entries)} |",
            f"| **ä¸€è‡´æ€§é—®é¢˜æ•°** | **{len(result.inconsistencies)}** |",
            f"| ç¼ºå¤±æ–‡ä»¶æ•° | {len(result.missing_files)} |",
            f"| å­¤å„¿æ–‡ä»¶æ•° | {len(result.orphan_files)} |",
            "",
            "---",
            "",
            "*æŠ¥å‘Šç”Ÿæˆå®Œæˆ*",
        ]
    )

    return "\n".join(lines)


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================


def get_project_root() -> Path:
    """è·å–é¡¹ç›®æ ¹ç›®å½•ã€‚"""
    script_dir = Path(__file__).resolve().parent
    return script_dir.parent.parent


def main() -> int:
    parser = argparse.ArgumentParser(
        description="è¿­ä»£æ–‡æ¡£å®¡è®¡è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=__doc__,
    )
    parser.add_argument(
        "--output-dir",
        "-o",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤è¾“å‡ºåˆ° stdoutï¼‰",
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="è¯¦ç»†æ¨¡å¼",
    )

    args = parser.parse_args()

    project_root = get_project_root()

    if args.verbose:
        print(f"[INFO] é¡¹ç›®æ ¹ç›®å½•: {project_root}", file=sys.stderr)
        print("[INFO] æ‰§è¡Œå®¡è®¡...", file=sys.stderr)

    result = run_audit(project_root)

    if args.verbose:
        print(f"[INFO] æ‰«æåˆ° {len(result.files)} ä¸ªè¿­ä»£æ–‡ä»¶", file=sys.stderr)
        print(f"[INFO] è§£æåˆ° {len(result.index_entries)} ä¸ªç´¢å¼•æ¡ç›®", file=sys.stderr)
        print(f"[INFO] å‘ç° {len(result.inconsistencies)} ä¸ªä¸ä¸€è‡´é¡¹", file=sys.stderr)

    report = generate_report(result, project_root)

    if args.output_dir:
        output_dir = project_root / args.output_dir
        output_dir.mkdir(parents=True, exist_ok=True)
        output_file = output_dir / f"audit_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        output_file.write_text(report, encoding="utf-8")
        print(f"[INFO] æŠ¥å‘Šå·²å†™å…¥: {output_file}", file=sys.stderr)
    else:
        print(report)

    # å¦‚æœæœ‰é—®é¢˜åˆ™è¿”å›éé›¶é€€å‡ºç 
    if result.inconsistencies or result.missing_files:
        return 1
    return 0


if __name__ == "__main__":
    sys.exit(main())
