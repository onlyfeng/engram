#!/usr/bin/env python3
"""
record_acceptance_run.py å•å…ƒæµ‹è¯•

è¦†ç›–åœºæ™¯ï¼š
1. parse_metadata_kv - è§£æ key=value æ ¼å¼
2. merge_metadata - åˆå¹¶ JSON å’Œ key=value å…ƒæ•°æ®
3. record_acceptance_run - æ ¸å¿ƒè®°å½•åŠŸèƒ½ï¼ˆå«æ–°å‚æ•°ï¼‰
4. CLI å‚æ•°è§£æï¼ˆ--command, --metadata-json, --metadata-kvï¼‰
5. å‘åå…¼å®¹æ€§éªŒè¯

æ³¨æ„ï¼š
- æ‰€æœ‰æµ‹è¯•ä½¿ç”¨ pytest tmp_pathï¼Œä¸ä¾èµ–çœŸå®æ–‡ä»¶ç³»ç»Ÿ
- ä½¿ç”¨ mock éš”ç¦»å¤–éƒ¨ä¾èµ–ï¼ˆgit, docker, ç¯å¢ƒå˜é‡ç­‰ï¼‰
"""

import json
import sys
from pathlib import Path
from unittest import mock

import pytest

# å°† scripts/acceptance ç›®å½•æ·»åŠ åˆ° path
sys.path.insert(0, str(Path(__file__).parent.parent / "acceptance"))

from record_acceptance_run import (
    list_artifacts,
    load_summary_duration,
    main,
    merge_metadata,
    parse_metadata_kv,
    record_acceptance_run,
    sanitize_value,
)

# ============================================================================
# Test: sanitize_value (POSTGRES_DSN è„±æ•)
# ============================================================================

class TestSanitizeValue:
    """æµ‹è¯•æ•æ„Ÿå€¼è„±æ•åŠŸèƒ½"""

    def test_sanitize_postgres_dsn_with_password(self):
        """POSTGRES_DSN ä¸­çš„å¯†ç åº”è¢«è„±æ•"""
        dsn = "postgresql://user:secretpassword@localhost:5432/db"
        result = sanitize_value("POSTGRES_DSN", dsn)
        assert result == "postgresql://user:***@localhost:5432/db"
        assert "secretpassword" not in result

    def test_sanitize_postgres_dsn_complex_password(self):
        """å¤æ‚å¯†ç ï¼ˆå«ç‰¹æ®Šå­—ç¬¦ï¼‰åº”è¢«è„±æ•"""
        # æ³¨æ„ï¼šæ­£åˆ™ (://[^:]+:)[^@]+(@) åŒ¹é…åˆ°ç¬¬ä¸€ä¸ª @ ä¸ºæ­¢
        # æ‰€ä»¥æµ‹è¯•ç”¨ä¾‹ä½¿ç”¨ä¸å« @ çš„å¯†ç 
        dsn = "postgresql://admin:P4ss!word#123@db.example.com:5432/mydb"
        result = sanitize_value("POSTGRES_DSN", dsn)
        assert result == "postgresql://admin:***@db.example.com:5432/mydb"
        assert "P4ss!word#123" not in result

    def test_sanitize_postgres_dsn_no_password(self):
        """æ— å¯†ç çš„ DSN ä¸å˜"""
        dsn = "postgresql://user@localhost:5432/db"
        result = sanitize_value("POSTGRES_DSN", dsn)
        # æ²¡æœ‰å¯†ç éƒ¨åˆ†æ—¶ï¼Œæ­£åˆ™ä¸åŒ¹é…ï¼Œè¿”å›åŸå€¼
        assert result == dsn

    def test_non_sensitive_key_not_sanitized(self):
        """éæ•æ„Ÿç¯å¢ƒå˜é‡ä¸åº”è¢«è„±æ•"""
        value = "postgresql://user:password@localhost:5432/db"
        result = sanitize_value("GATEWAY_URL", value)
        # é POSTGRES_DSN ä¸è„±æ•
        assert result == value


# ============================================================================
# Test: list_artifacts
# ============================================================================

class TestListArtifacts:
    """æµ‹è¯• artifacts åˆ—ä¸¾åŠŸèƒ½"""

    def test_list_artifacts_empty_dir(self, tmp_path: Path):
        """ç©ºç›®å½•è¿”å›ç©ºåˆ—è¡¨"""
        artifacts_dir = tmp_path / "empty_artifacts"
        artifacts_dir.mkdir()
        result = list_artifacts(artifacts_dir)
        assert result == []

    def test_list_artifacts_nonexistent_dir(self, tmp_path: Path):
        """ä¸å­˜åœ¨çš„ç›®å½•è¿”å›ç©ºåˆ—è¡¨"""
        artifacts_dir = tmp_path / "nonexistent"
        result = list_artifacts(artifacts_dir)
        assert result == []

    def test_list_artifacts_single_file(self, tmp_path: Path, monkeypatch):
        """åˆ—ä¸¾å•ä¸ªæ–‡ä»¶"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()
        (artifacts_dir / "summary.json").write_text('{"result": "PASS"}')

        # åˆ‡æ¢å·¥ä½œç›®å½•ä½¿ relative_to æ­£å¸¸å·¥ä½œ
        monkeypatch.chdir(tmp_path)

        result = list_artifacts(artifacts_dir)
        assert len(result) == 1
        assert "summary.json" in result[0]

    def test_list_artifacts_multiple_files(self, tmp_path: Path, monkeypatch):
        """åˆ—ä¸¾å¤šä¸ªæ–‡ä»¶ï¼ˆæŒ‰åç§°æ’åºï¼‰"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()
        (artifacts_dir / "summary.json").write_text("{}")
        (artifacts_dir / "steps.log").write_text("step1")
        (artifacts_dir / "health.json").write_text("{}")

        monkeypatch.chdir(tmp_path)

        result = list_artifacts(artifacts_dir)
        assert len(result) == 3
        # éªŒè¯æ’åº
        filenames = [Path(p).name for p in result]
        assert filenames == sorted(filenames)

    def test_list_artifacts_nested_files(self, tmp_path: Path, monkeypatch):
        """åˆ—ä¸¾åµŒå¥—ç›®å½•ä¸­çš„æ–‡ä»¶"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()
        (artifacts_dir / "summary.json").write_text("{}")

        subdir = artifacts_dir / "diagnostics"
        subdir.mkdir()
        (subdir / "logs.txt").write_text("logs")

        monkeypatch.chdir(tmp_path)

        result = list_artifacts(artifacts_dir)
        assert len(result) == 2
        # åº”åŒ…å«é¡¶å±‚å’ŒåµŒå¥—æ–‡ä»¶
        assert any("summary.json" in p for p in result)
        assert any("logs.txt" in p for p in result)


# ============================================================================
# Test: load_summary_duration
# ============================================================================

class TestLoadSummaryDuration:
    """æµ‹è¯• duration è¯»å–åŠŸèƒ½"""

    def test_load_duration_from_summary(self, tmp_path: Path):
        """ä» summary.json è¯»å– duration_seconds"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        summary = {"result": "PASS", "duration_seconds": 120}
        (artifacts_dir / "summary.json").write_text(json.dumps(summary))

        result = load_summary_duration(artifacts_dir)
        assert result == 120

    def test_load_duration_no_summary_file(self, tmp_path: Path):
        """æ—  summary.json æ—¶è¿”å› None"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        result = load_summary_duration(artifacts_dir)
        assert result is None

    def test_load_duration_no_duration_field(self, tmp_path: Path):
        """summary.json æ—  duration_seconds å­—æ®µæ—¶è¿”å› None"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        summary = {"result": "PASS"}
        (artifacts_dir / "summary.json").write_text(json.dumps(summary))

        result = load_summary_duration(artifacts_dir)
        assert result is None

    def test_load_duration_invalid_json(self, tmp_path: Path):
        """summary.json æ— æ•ˆ JSON æ—¶è¿”å› None"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()
        (artifacts_dir / "summary.json").write_text("{invalid json}")

        result = load_summary_duration(artifacts_dir)
        assert result is None

    def test_load_duration_zero_value(self, tmp_path: Path):
        """duration_seconds ä¸º 0 æ—¶åº”æ­£ç¡®è¿”å›"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        summary = {"duration_seconds": 0}
        (artifacts_dir / "summary.json").write_text(json.dumps(summary))

        result = load_summary_duration(artifacts_dir)
        assert result == 0


# ============================================================================
# Test: parse_metadata_kv
# ============================================================================

class TestParseMetadataKv:
    """æµ‹è¯• key=value è§£æåŠŸèƒ½"""

    def test_parse_single_pair(self):
        """è§£æå•ä¸ª key=value å¯¹"""
        result = parse_metadata_kv(["workflow=ci"])
        assert result == {"workflow": "ci"}

    def test_parse_multiple_pairs(self):
        """è§£æå¤šä¸ª key=value å¯¹"""
        result = parse_metadata_kv(["workflow=ci", "profile=http_only", "run_id=12345"])
        assert result == {
            "workflow": "ci",
            "profile": "http_only",
            "run_id": "12345",
        }

    def test_parse_empty_value(self):
        """è§£æç©ºå€¼"""
        result = parse_metadata_kv(["key="])
        assert result == {"key": ""}

    def test_parse_value_with_equals(self):
        """è§£æå€¼ä¸­åŒ…å«ç­‰å·çš„æƒ…å†µ"""
        result = parse_metadata_kv(["url=http://example.com?a=1&b=2"])
        assert result == {"url": "http://example.com?a=1&b=2"}

    def test_parse_none_input(self):
        """è§£æ None è¾“å…¥"""
        result = parse_metadata_kv(None)
        assert result == {}

    def test_parse_empty_list(self):
        """è§£æç©ºåˆ—è¡¨"""
        result = parse_metadata_kv([])
        assert result == {}

    def test_parse_missing_equals_raises(self):
        """ç¼ºå°‘ç­‰å·åº”æŠ›å‡ºå¼‚å¸¸"""
        with pytest.raises(ValueError, match="missing '='"):
            parse_metadata_kv(["invalid"])

    def test_parse_empty_key_raises(self):
        """ç©º key åº”æŠ›å‡ºå¼‚å¸¸"""
        with pytest.raises(ValueError, match="empty key"):
            parse_metadata_kv(["=value"])


# ============================================================================
# Test: merge_metadata
# ============================================================================

class TestMergeMetadata:
    """æµ‹è¯•å…ƒæ•°æ®åˆå¹¶åŠŸèƒ½"""

    def test_merge_json_only(self):
        """ä»… JSON å…ƒæ•°æ®"""
        result = merge_metadata('{"workflow": "ci", "profile": "http_only"}', None)
        assert result == {"workflow": "ci", "profile": "http_only"}

    def test_merge_kv_only(self):
        """ä»… key=value å…ƒæ•°æ®"""
        result = merge_metadata(None, ["workflow=nightly", "github_run_id=99"])
        assert result == {"workflow": "nightly", "github_run_id": "99"}

    def test_merge_both_kv_overrides_json(self):
        """key=value åº”è¦†ç›– JSON ä¸­çš„åŒå key"""
        json_str = '{"workflow": "ci", "profile": "http_only"}'
        kv_list = ["workflow=nightly"]  # è¦†ç›– workflow
        result = merge_metadata(json_str, kv_list)
        assert result == {"workflow": "nightly", "profile": "http_only"}

    def test_merge_both_adds_new_keys(self):
        """key=value å¯æ·»åŠ æ–° key"""
        json_str = '{"workflow": "ci"}'
        kv_list = ["github_run_id=123"]
        result = merge_metadata(json_str, kv_list)
        assert result == {"workflow": "ci", "github_run_id": "123"}

    def test_merge_neither_returns_none(self):
        """å‡æœªæä¾›æ—¶è¿”å› None"""
        result = merge_metadata(None, None)
        assert result is None

    def test_merge_empty_json_and_kv_returns_none(self):
        """ç©ºå­—ç¬¦ä¸²å’Œç©ºåˆ—è¡¨è¿”å› None"""
        result = merge_metadata("", [])
        assert result is None

    def test_merge_invalid_json_raises(self):
        """æ— æ•ˆ JSON åº”æŠ›å‡ºå¼‚å¸¸"""
        with pytest.raises(ValueError, match="Invalid JSON"):
            merge_metadata("{invalid json}", None)

    def test_merge_json_array_raises(self):
        """JSON æ•°ç»„åº”æŠ›å‡ºå¼‚å¸¸"""
        with pytest.raises(ValueError, match="must be a JSON object"):
            merge_metadata('["a", "b"]', None)

    def test_merge_json_primitive_raises(self):
        """JSON åŸå§‹å€¼åº”æŠ›å‡ºå¼‚å¸¸"""
        with pytest.raises(ValueError, match="must be a JSON object"):
            merge_metadata('"string"', None)


# ============================================================================
# Test: record_acceptance_run
# ============================================================================

class TestRecordAcceptanceRun:
    """æµ‹è¯•æ ¸å¿ƒè®°å½•åŠŸèƒ½"""

    @pytest.fixture
    def mock_env(self):
        """Mock ç¯å¢ƒä¾èµ–"""
        with mock.patch.multiple(
            "record_acceptance_run",
            get_git_commit=mock.DEFAULT,
            get_os_version=mock.DEFAULT,
            get_docker_version=mock.DEFAULT,
            get_captured_env=mock.DEFAULT,
        ) as mocks:
            mocks["get_git_commit"].return_value = "abc123def456"
            mocks["get_os_version"].return_value = "Darwin 24.6.0 (arm64)"
            mocks["get_docker_version"].return_value = "Docker version 24.0.6"
            mocks["get_captured_env"].return_value = {"SKIP_DEPLOY": "0"}
            yield mocks

    def test_default_command_is_make_name(self, tmp_path: Path, mock_env):
        """é»˜è®¤ command ä¸º 'make {name}'"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        with mock.patch("record_acceptance_run.Path", wraps=Path) as mock_path:
            # è®© output_dir æŒ‡å‘ tmp_path
            mock_path.return_value = tmp_path / ".artifacts" / "acceptance-runs"

            output_file = record_acceptance_run(
                name="acceptance-logbook-only",
                artifacts_dir=str(artifacts_dir),
                result="PASS",
            )

        with open(output_file) as f:
            record = json.load(f)

        assert record["command"] == "make acceptance-logbook-only"

    def test_custom_command_overrides_default(self, tmp_path: Path, mock_env):
        """--command å‚æ•°è¦†ç›–é»˜è®¤å‘½ä»¤"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        output_file = record_acceptance_run(
            name="acceptance-logbook-only",
            artifacts_dir=str(artifacts_dir),
            result="PASS",
            command="./scripts/custom_test.sh --verbose",
        )

        with open(output_file) as f:
            record = json.load(f)

        assert record["command"] == "./scripts/custom_test.sh --verbose"

    def test_metadata_added_to_record(self, tmp_path: Path, mock_env):
        """metadata å­—å…¸è¢«æ·»åŠ åˆ°è®°å½•ä¸­"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        metadata = {
            "workflow": "ci",
            "profile": "http_only",
            "github_run_id": "12345",
        }

        output_file = record_acceptance_run(
            name="acceptance-unified-min",
            artifacts_dir=str(artifacts_dir),
            result="PASS",
            metadata=metadata,
        )

        with open(output_file) as f:
            record = json.load(f)

        assert "metadata" in record
        assert record["metadata"] == metadata

    def test_no_metadata_field_when_none(self, tmp_path: Path, mock_env):
        """æœªæä¾› metadata æ—¶è®°å½•ä¸­ä¸åº”æœ‰ metadata å­—æ®µ"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        output_file = record_acceptance_run(
            name="acceptance-logbook-only",
            artifacts_dir=str(artifacts_dir),
            result="PASS",
        )

        with open(output_file) as f:
            record = json.load(f)

        assert "metadata" not in record

    def test_backward_compatible_without_new_params(self, tmp_path: Path, mock_env):
        """å‘åå…¼å®¹ï¼šä¸ä½¿ç”¨æ–°å‚æ•°æ—¶è¡Œä¸ºä¸å˜"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        output_file = record_acceptance_run(
            name="acceptance-logbook-only",
            artifacts_dir=str(artifacts_dir),
            result="PASS",
            commit="explicit_commit_sha",
        )

        with open(output_file) as f:
            record = json.load(f)

        # éªŒè¯æ‰€æœ‰åŸæœ‰å­—æ®µ
        assert record["name"] == "acceptance-logbook-only"
        assert record["result"] == "PASS"
        assert record["commit"] == "explicit_commit_sha"
        assert record["command"] == "make acceptance-logbook-only"
        assert "metadata" not in record
        assert "timestamp" in record
        assert "os_version" in record
        assert "artifacts_dir" in record

    def test_all_new_params_together(self, tmp_path: Path, mock_env):
        """åŒæ—¶ä½¿ç”¨æ‰€æœ‰æ–°å‚æ•°"""
        artifacts_dir = tmp_path / "artifacts"
        artifacts_dir.mkdir()

        # åˆ›å»º summary.json
        summary = {"duration_seconds": 120}
        (artifacts_dir / "summary.json").write_text(json.dumps(summary))

        output_file = record_acceptance_run(
            name="acceptance-unified-full",
            artifacts_dir=str(artifacts_dir),
            result="PASS",
            commit="full_test_commit",
            command="make acceptance-unified-full VERIFY_FULL=1",
            metadata={
                "workflow": "nightly",
                "profile": "full",
                "github_run_id": "98765",
            },
        )

        with open(output_file) as f:
            record = json.load(f)

        assert record["name"] == "acceptance-unified-full"
        assert record["commit"] == "full_test_commit"
        assert record["command"] == "make acceptance-unified-full VERIFY_FULL=1"
        assert record["metadata"]["workflow"] == "nightly"
        assert record["metadata"]["profile"] == "full"
        assert record["metadata"]["github_run_id"] == "98765"
        assert record["duration_seconds"] == 120


# ============================================================================
# Test: CLI å‚æ•°è§£æ
# ============================================================================

class TestCLIArguments:
    """æµ‹è¯• CLI å‚æ•°è§£æ"""

    @pytest.fixture
    def mock_record_func(self):
        """Mock record_acceptance_run å‡½æ•°"""
        with mock.patch("record_acceptance_run.record_acceptance_run") as m:
            m.return_value = "/tmp/test_output.json"
            yield m

    def test_cli_basic_args(self, mock_record_func, capsys):
        """åŸºæœ¬å‚æ•°è§£æ"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "acceptance-logbook-only",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
            ]
        ):
            exit_code = main()

        assert exit_code == 0
        mock_record_func.assert_called_once()
        call_kwargs = mock_record_func.call_args[1]
        assert call_kwargs["name"] == "acceptance-logbook-only"
        assert call_kwargs["artifacts_dir"] == ".artifacts/test"
        assert call_kwargs["result"] == "PASS"
        assert call_kwargs["command"] is None
        assert call_kwargs["metadata"] is None

    def test_cli_command_arg(self, mock_record_func):
        """--command å‚æ•°"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "acceptance-unified-min",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
                "--command", "make acceptance-unified-min HTTP_ONLY_MODE=1",
            ]
        ):
            main()

        call_kwargs = mock_record_func.call_args[1]
        assert call_kwargs["command"] == "make acceptance-unified-min HTTP_ONLY_MODE=1"

    def test_cli_metadata_json_arg(self, mock_record_func):
        """--metadata-json å‚æ•°"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "test",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
                "--metadata-json", '{"workflow": "ci", "profile": "http_only"}',
            ]
        ):
            main()

        call_kwargs = mock_record_func.call_args[1]
        assert call_kwargs["metadata"] == {"workflow": "ci", "profile": "http_only"}

    def test_cli_metadata_kv_single(self, mock_record_func):
        """å•ä¸ª --metadata-kv å‚æ•°"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "test",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
                "--metadata-kv", "workflow=nightly",
            ]
        ):
            main()

        call_kwargs = mock_record_func.call_args[1]
        assert call_kwargs["metadata"] == {"workflow": "nightly"}

    def test_cli_metadata_kv_multiple(self, mock_record_func):
        """å¤šä¸ª --metadata-kv å‚æ•°"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "test",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
                "--metadata-kv", "workflow=ci",
                "--metadata-kv", "profile=http_only",
                "--metadata-kv", "github_run_id=12345",
            ]
        ):
            main()

        call_kwargs = mock_record_func.call_args[1]
        assert call_kwargs["metadata"] == {
            "workflow": "ci",
            "profile": "http_only",
            "github_run_id": "12345",
        }

    def test_cli_metadata_json_and_kv_merge(self, mock_record_func):
        """--metadata-json å’Œ --metadata-kv åˆå¹¶"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "test",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
                "--metadata-json", '{"workflow": "ci", "profile": "http_only"}',
                "--metadata-kv", "workflow=nightly",  # è¦†ç›– JSON ä¸­çš„ workflow
                "--metadata-kv", "extra_key=extra_value",  # æ–°å¢
            ]
        ):
            main()

        call_kwargs = mock_record_func.call_args[1]
        assert call_kwargs["metadata"] == {
            "workflow": "nightly",  # è¢« kv è¦†ç›–
            "profile": "http_only",  # ä¿æŒ JSON åŸå€¼
            "extra_key": "extra_value",  # æ–°å¢
        }

    def test_cli_invalid_json_error(self, mock_record_func, capsys):
        """æ— æ•ˆ JSON åº”è¿”å›é”™è¯¯"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "test",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
                "--metadata-json", "{invalid}",
            ]
        ):
            exit_code = main()

        assert exit_code == 1
        captured = capsys.readouterr()
        assert "Invalid JSON" in captured.err

    def test_cli_invalid_kv_error(self, mock_record_func, capsys):
        """æ— æ•ˆ key=value åº”è¿”å›é”™è¯¯"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "test",
                "--artifacts-dir", ".artifacts/test",
                "--result", "PASS",
                "--metadata-kv", "no_equals_sign",
            ]
        ):
            exit_code = main()

        assert exit_code == 1
        captured = capsys.readouterr()
        assert "missing '='" in captured.err

    def test_cli_all_args_together(self, mock_record_func):
        """æ‰€æœ‰å‚æ•°ä¸€èµ·ä½¿ç”¨"""
        with mock.patch(
            "sys.argv",
            [
                "prog",
                "--name", "acceptance-unified-full",
                "--artifacts-dir", ".artifacts/acceptance-unified-full",
                "--result", "PASS",
                "--commit", "abc123",
                "--command", "./run_full_tests.sh",
                "--metadata-json", '{"workflow": "nightly"}',
                "--metadata-kv", "profile=full",
            ]
        ):
            main()

        call_kwargs = mock_record_func.call_args[1]
        assert call_kwargs["name"] == "acceptance-unified-full"
        assert call_kwargs["artifacts_dir"] == ".artifacts/acceptance-unified-full"
        assert call_kwargs["result"] == "PASS"
        assert call_kwargs["commit"] == "abc123"
        assert call_kwargs["command"] == "./run_full_tests.sh"
        assert call_kwargs["metadata"] == {"workflow": "nightly", "profile": "full"}


# ============================================================================
# Test: è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸å¤„ç†
# ============================================================================

class TestEdgeCases:
    """æµ‹è¯•è¾¹ç•Œæ¡ä»¶"""

    def test_metadata_with_special_characters(self):
        """metadata å€¼åŒ…å«ç‰¹æ®Šå­—ç¬¦"""
        kv = ["message=Hello, World!", "url=https://example.com?a=1&b=2"]
        result = parse_metadata_kv(kv)
        assert result["message"] == "Hello, World!"
        assert result["url"] == "https://example.com?a=1&b=2"

    def test_metadata_with_unicode(self):
        """metadata å€¼åŒ…å« Unicode"""
        result = merge_metadata('{"msg": "ä½ å¥½ä¸–ç•Œ"}', ["emoji=ğŸš€"])
        assert result["msg"] == "ä½ å¥½ä¸–ç•Œ"
        assert result["emoji"] == "ğŸš€"

    def test_metadata_with_nested_json(self):
        """metadata JSON åŒ…å«åµŒå¥—å¯¹è±¡"""
        json_str = '{"tags": ["ci", "nightly"], "config": {"verbose": true}}'
        result = merge_metadata(json_str, None)
        assert result["tags"] == ["ci", "nightly"]
        assert result["config"] == {"verbose": True}

    def test_empty_command_string(self, tmp_path: Path):
        """ç©ºå­—ç¬¦ä¸² command åº”è¢«ä¿ç•™"""
        with mock.patch.multiple(
            "record_acceptance_run",
            get_git_commit=mock.MagicMock(return_value="abc123"),
            get_os_version=mock.MagicMock(return_value="Darwin"),
            get_docker_version=mock.MagicMock(return_value=None),
            get_captured_env=mock.MagicMock(return_value={}),
        ):
            artifacts_dir = tmp_path / "artifacts"
            artifacts_dir.mkdir()

            output_file = record_acceptance_run(
                name="test",
                artifacts_dir=str(artifacts_dir),
                result="PASS",
                command="",  # ç©ºå­—ç¬¦ä¸²
            )

            with open(output_file) as f:
                record = json.load(f)

            # ç©ºå­—ç¬¦ä¸²åº”è¢«ä¿ç•™ï¼Œä¸å›é€€åˆ°é»˜è®¤å€¼
            assert record["command"] == ""


# ============================================================================
# Test: Makefile acceptance é™æ€çº¦æŸéªŒè¯
# ============================================================================

class TestMakefileAcceptanceConstraints:
    """
    éªŒè¯ Makefile acceptance targets çš„é™æ€çº¦æŸã€‚

    ä½¿ç”¨ make -n (dry-run) è§£æè¾“å‡ºï¼ŒéªŒè¯ï¼š
    1. ä¼šåˆ›å»º steps.log
    2. ä¼šåˆ›å»º summary.json
    3. ä¼šè°ƒç”¨ record_acceptance_run.py è„šæœ¬

    æ³¨æ„ï¼šä¸å®é™…æ‰§è¡Œ Dockerï¼Œä»…éªŒè¯ Makefile é€»è¾‘ç»“æ„ã€‚
    """

    @pytest.fixture
    def workspace_root(self) -> Path:
        """è·å–å·¥ä½œåŒºæ ¹ç›®å½•ï¼ˆåŒ…å« Makefileï¼‰"""
        # ä» scripts/tests å‘ä¸Šæ‰¾åˆ°åŒ…å« Makefile çš„ç›®å½•
        current = Path(__file__).parent
        for _ in range(5):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾ 5 çº§
            if (current / "Makefile").exists():
                return current
            current = current.parent
        pytest.skip("Cannot find Makefile in workspace")

    @pytest.mark.parametrize("target", [
        "acceptance-unified-min",
        "acceptance-unified-full",
        "acceptance-logbook-only",
    ])
    def test_acceptance_target_creates_artifacts(self, workspace_root: Path, target: str):
        """éªŒè¯ acceptance target ä¼šåˆ›å»º steps.log å’Œ summary.json"""
        import subprocess

        # ä½¿ç”¨ make -n è·å– dry-run è¾“å‡º
        subprocess.run(
            ["make", "-n", target],
            cwd=workspace_root,
            capture_output=True,
            text=True,
            timeout=30,
        )

        # ç»„åˆ stdout å’Œ Makefile å†…å®¹è¿›è¡Œåˆ†æ
        # æ³¨æ„: make -n å¯èƒ½ä¸ä¼šå±•å¼€æ‰€æœ‰ shell å˜é‡ï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥æ£€æŸ¥ Makefile
        makefile_path = workspace_root / "Makefile"
        makefile_content = makefile_path.read_text()

        # æå–å¯¹åº” target çš„å®šä¹‰å—
        target_pattern = f"{target}:"
        assert target_pattern in makefile_content, f"Target {target} not found in Makefile"

        # éªŒè¯ target å®šä¹‰ä¸­åŒ…å«å¿…è¦çš„è¾“å‡ºæ–‡ä»¶
        # æŸ¥æ‰¾è¯¥ target åˆ°ä¸‹ä¸€ä¸ª target ä¹‹é—´çš„å†…å®¹
        lines = makefile_content.split("\n")
        in_target = False
        target_content = []
        for line in lines:
            if line.startswith(f"{target}:"):
                in_target = True
                continue
            if in_target:
                if line and not line.startswith("\t") and not line.startswith(" ") and ":" in line:
                    break  # é‡åˆ°ä¸‹ä¸€ä¸ª target
                target_content.append(line)

        target_block = "\n".join(target_content)

        # éªŒè¯å…³é”®æ–‡ä»¶åˆ›å»º
        assert "steps.log" in target_block, f"{target} should create steps.log"
        assert "summary.json" in target_block, f"{target} should create summary.json"
        assert "record_acceptance_run.py" in target_block, f"{target} should call record_acceptance_run.py"

    def test_acceptance_unified_min_uses_http_only_mode(self, workspace_root: Path):
        """éªŒè¯ acceptance-unified-min ä½¿ç”¨ HTTP_ONLY_MODE"""
        makefile_path = workspace_root / "Makefile"
        makefile_content = makefile_path.read_text()

        # æŸ¥æ‰¾ acceptance-unified-min target
        assert 'HTTP_ONLY_MODE' in makefile_content

        # æ‰¾åˆ° target å®šä¹‰å—
        lines = makefile_content.split("\n")
        in_target = False
        for i, line in enumerate(lines):
            if line.startswith("acceptance-unified-min:"):
                in_target = True
            elif in_target and "HTTP_ONLY_MODE" in line:
                # éªŒè¯è®¾ç½®äº† HTTP_ONLY_MODE=1
                assert "1" in line or '"1"' in line
                return
            elif in_target and not line.startswith("\t") and ":" in line and line.strip():
                break

        # å¦‚æœèƒ½æ‰¾åˆ°åˆ™é€šè¿‡
        assert in_target, "acceptance-unified-min target should exist"


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
