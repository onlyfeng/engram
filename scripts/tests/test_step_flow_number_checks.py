#!/usr/bin/env python3
"""
check_no_step_flow_numbers.py å•å…ƒæµ‹è¯•

è¦†ç›–åœºæ™¯ï¼š
1. å¸¦ç©ºæ ¼çš„æµç¨‹ç¼–å·ï¼ˆStep 1/2/3ï¼‰åº”è¢«æ£€æµ‹åˆ°
2. ä¸å¸¦ç©ºæ ¼çš„åˆ«åï¼ˆStepNï¼‰ã€å•è¯ï¼ˆstepwiseï¼‰ã€ä¸­æ–‡ï¼ˆæ­¥éª¤ 1ï¼‰ç­‰ä¸åº”å‘½ä¸­
3. ç™½åå•è·¯å¾„ä¸ä¼šè¢«æ‰«æ
4. æ’é™¤è§„åˆ™æ­£ç¡®å·¥ä½œ
5. CLI å‚æ•° --fail/--no-fail/--json è¡Œä¸ºä¸€è‡´

æ³¨æ„ï¼š
- æ‰€æœ‰æµ‹è¯•ä½¿ç”¨ pytest tmp_pathï¼Œä¸ä¾èµ–çœŸå®ä»“åº“æ‰«æ
- ä½¿ç”¨è¿è¡Œæ—¶æ‹¼æ¥å­—ç¬¦ä¸²æ„é€ æµ‹è¯•æ•°æ®ï¼Œé¿å…åœ¨æºç ä¸­å‡ºç°æ—§ token
"""

import json
import sys
from pathlib import Path
from unittest import mock

import pytest

# å°† scripts ç›®å½•æ·»åŠ åˆ° path
sys.path.insert(0, str(Path(__file__).parent.parent))

from check_no_step_flow_numbers import (
    ALLOWED_PATHS,
    STEP_FLOW_PATTERN,
    Finding,
    ScanResult,
    is_allowed_path,
    main,
    scan_directory,
    scan_file,
    should_exclude_dir,
    should_exclude_file,
    should_scan_file,
)

# ============================================================================
# è¾…åŠ©å‡½æ•°ï¼šè¿è¡Œæ—¶æ„é€ æµ‹è¯• tokenï¼ˆé¿å…æºç ä¸­å‡ºç°æ—§ tokenï¼‰
# ============================================================================

def _make_step_flow(num: int, case: str = "title", sep: str = " ") -> str:
    """
    è¿è¡Œæ—¶æ„é€ å¸¦ç©ºæ ¼çš„æµç¨‹ç¼–å· token

    Args:
        num: é˜¶æ®µç¼–å· (1, 2, 3)
        case: "lower", "title", "upper"
        sep: åˆ†éš”ç¬¦ï¼ˆé»˜è®¤å•ä¸ªç©ºæ ¼ï¼‰

    Returns:
        æ„é€ çš„ tokenï¼Œå¦‚ "Step 1", "step 2", "STEP 3"
    """
    base = "Step"
    if case == "lower":
        base = "step"
    elif case == "upper":
        base = "STEP"
    return base + sep + str(num)


def _make_alias(num: int, case: str = "lower") -> str:
    """
    è¿è¡Œæ—¶æ„é€ æ— ç©ºæ ¼åˆ«å tokenï¼ˆä¸åº”è¢«æœ¬è„šæœ¬å‘½ä¸­ï¼‰

    Args:
        num: é˜¶æ®µç¼–å· (1, 2, 3)
        case: "lower", "title", "upper"

    Returns:
        æ„é€ çš„ tokenï¼Œå¦‚ "step1", "Step2", "STEP3"
    """
    base = "step"
    if case == "title":
        base = "Step"
    elif case == "upper":
        base = "STEP"
    return f"{base}{num}"


# ============================================================================
# Test: STEP_FLOW_PATTERN æ­£åˆ™åŒ¹é… - åº”å‘½ä¸­åœºæ™¯
# ============================================================================

class TestStepFlowPatternMatches:
    """æµ‹è¯•æµç¨‹ç¼–å·æ­£åˆ™åŒ¹é… - åº”å‘½ä¸­çš„åœºæ™¯"""

    def test_pattern_matches_title_case_space(self):
        """åº”è¯¥åŒ¹é… Step + ç©ºæ ¼ + æ•°å­—"""
        for num in [1, 2, 3]:
            token = _make_step_flow(num, "title")
            match = STEP_FLOW_PATTERN.search(token)
            assert match is not None, f"Should match '{token}'"
            assert match.group().lower() == f"step {num}"

    def test_pattern_matches_lower_case_space(self):
        """åº”è¯¥åŒ¹é… step + ç©ºæ ¼ + æ•°å­—"""
        for num in [1, 2, 3]:
            token = _make_step_flow(num, "lower")
            match = STEP_FLOW_PATTERN.search(token)
            assert match is not None, f"Should match '{token}'"
            assert match.group().lower() == f"step {num}"

    def test_pattern_matches_upper_case_space(self):
        """åº”è¯¥åŒ¹é… STEP + ç©ºæ ¼ + æ•°å­—"""
        for num in [1, 2, 3]:
            token = _make_step_flow(num, "upper")
            match = STEP_FLOW_PATTERN.search(token)
            assert match is not None, f"Should match '{token}'"
            assert match.group().lower() == f"step {num}"

    def test_pattern_matches_mixed_case(self):
        """åº”è¯¥åŒ¹é…æ··åˆå¤§å°å†™"""
        mixed_cases = [
            "sTeP" + " " + "1",
            "StEp" + " " + "2",
            "sTEP" + " " + "3",
        ]
        for token in mixed_cases:
            match = STEP_FLOW_PATTERN.search(token)
            assert match is not None, f"Should match '{token}'"

    def test_pattern_matches_in_sentence(self):
        """åº”è¯¥åŒ¹é…å¥å­ä¸­çš„ token"""
        token = _make_step_flow(1, "title")
        text = f"This is {token}: Initialize the system"
        match = STEP_FLOW_PATTERN.search(text)
        assert match is not None
        assert match.group().lower() == "step 1"

    def test_pattern_matches_with_punctuation(self):
        """åº”è¯¥åŒ¹é…å¸¦æ ‡ç‚¹ç¬¦å·çš„ token"""
        token = _make_step_flow(2, "title")
        texts = [
            f"{token}.",
            f"{token},",
            f"({token})",
            f"'{token}'",
            f"{token}:",
            f"{token};",
        ]
        for text in texts:
            match = STEP_FLOW_PATTERN.search(text)
            assert match is not None, f"Should match in '{text}'"
            assert match.group().lower() == "step 2"

    def test_pattern_matches_at_line_start(self):
        """åº”è¯¥åŒ¹é…è¡Œé¦–çš„ token"""
        token = _make_step_flow(1, "title")
        text = f"{token} - Introduction"
        match = STEP_FLOW_PATTERN.search(text)
        assert match is not None
        assert match.start() == 0

    def test_pattern_matches_at_line_end(self):
        """åº”è¯¥åŒ¹é…è¡Œå°¾çš„ token"""
        token = _make_step_flow(3, "title")
        text = f"Final phase is {token}"
        match = STEP_FLOW_PATTERN.search(text)
        assert match is not None

    def test_pattern_matches_multiple_spaces(self):
        """åº”è¯¥åŒ¹é…å¤šä¸ªç©ºæ ¼çš„æƒ…å†µ"""
        # Step  1ï¼ˆåŒç©ºæ ¼ï¼‰
        token = _make_step_flow(1, "title", sep="  ")
        match = STEP_FLOW_PATTERN.search(token)
        assert match is not None, f"Should match '{token}' (double space)"

    def test_pattern_matches_tab_separator(self):
        """åº”è¯¥åŒ¹é… Tab åˆ†éš”çš„æƒ…å†µ"""
        token = _make_step_flow(1, "title", sep="\t")
        match = STEP_FLOW_PATTERN.search(token)
        assert match is not None, f"Should match '{token}' (tab separator)"


# ============================================================================
# Test: STEP_FLOW_PATTERN æ­£åˆ™åŒ¹é… - ä¸åº”å‘½ä¸­åœºæ™¯
# ============================================================================

class TestStepFlowPatternNotMatches:
    """æµ‹è¯•æµç¨‹ç¼–å·æ­£åˆ™åŒ¹é… - ä¸åº”å‘½ä¸­çš„åœºæ™¯"""

    def test_pattern_not_matches_no_space(self):
        """ä¸åº”è¯¥åŒ¹é…æ— ç©ºæ ¼çš„åˆ«åï¼ˆStepNï¼‰"""
        for num in [1, 2, 3]:
            for case in ["lower", "title", "upper"]:
                token = _make_alias(num, case)
                match = STEP_FLOW_PATTERN.search(token)
                assert match is None, f"Should NOT match '{token}'"

    def test_pattern_not_matches_stepwise(self):
        """ä¸åº”è¯¥åŒ¹é… stepwise ç­‰å•è¯"""
        words = ["stepwise", "Stepwise", "STEPWISE", "stepwisely"]
        for word in words:
            match = STEP_FLOW_PATTERN.search(word)
            assert match is None, f"Should NOT match '{word}'"

    def test_pattern_not_matches_chinese(self):
        """ä¸åº”è¯¥åŒ¹é…ä¸­æ–‡æ­¥éª¤æè¿°"""
        chinese_texts = [
            "æ­¥éª¤ 1",
            "æ­¥éª¤1",
            "ç¬¬ä¸€æ­¥",
            "é˜¶æ®µ 1",
            "æ­¥éª¤ 2",
            "æ­¥éª¤ 3",
        ]
        for text in chinese_texts:
            match = STEP_FLOW_PATTERN.search(text)
            assert match is None, f"Should NOT match '{text}'"

    def test_pattern_not_matches_numbered_list(self):
        """ä¸åº”è¯¥åŒ¹é…æ•°å­—åºå·åˆ—è¡¨ï¼ˆå¦‚ 1. 2. 3.ï¼‰"""
        numbered_items = ["1.", "2.", "3.", "1)", "2)", "3)"]
        for item in numbered_items:
            match = STEP_FLOW_PATTERN.search(item)
            assert match is None, f"Should NOT match '{item}'"

    def test_pattern_not_matches_other_numbers(self):
        """ä¸åº”è¯¥åŒ¹é…å…¶ä»–æ•°å­—ï¼ˆ0, 4, 5 ç­‰ï¼‰"""
        other_nums = [0, 4, 5, 10, 123]
        for num in other_nums:
            token = "Step" + " " + str(num)
            match = STEP_FLOW_PATTERN.search(token)
            assert match is None, f"Should NOT match '{token}'"

    def test_pattern_not_matches_substring(self):
        """ä¸åº”è¯¥åœ¨æ›´é•¿å•è¯ä¸­åŒ¹é…"""
        # footstep ä¸­çš„ step ä¸åº”åŒ¹é…
        words = ["footstep", "doorstep", "misstep", "sidestep"]
        for word in words:
            # å³ä½¿åé¢åŠ ç©ºæ ¼å’Œæ•°å­—ä¹Ÿä¸åº”åŒ¹é…ï¼Œå› ä¸º step å‰æœ‰å­—æ¯
            text = f"{word} 1"
            match = STEP_FLOW_PATTERN.search(text)
            assert match is None, f"Should NOT match '{text}'"

    def test_pattern_not_matches_step_n_pattern(self):
        """ä¸åº”è¯¥åŒ¹é… StepN æ¨¡å¼ï¼ˆæ— ç©ºæ ¼ï¼‰"""
        # è¿™äº›åº”ç”± check_no_legacy_stage_aliases.py æ£€æµ‹
        patterns = [
            "step" + "1",
            "Step" + "2",
            "STEP" + "3",
            "step" + "1" + "_logbook",
            "_" + "step" + "2" + "_",
        ]
        for pattern in patterns:
            match = STEP_FLOW_PATTERN.search(pattern)
            assert match is None, f"Should NOT match '{pattern}'"

    def test_pattern_not_matches_step_without_number(self):
        """ä¸åº”è¯¥åŒ¹é…ä¸å¸¦æ•°å­—çš„ step"""
        texts = ["step", "Step", "STEP", "step forward", "next step"]
        for text in texts:
            match = STEP_FLOW_PATTERN.search(text)
            assert match is None, f"Should NOT match '{text}'"


# ============================================================================
# Test: scan_file å•æ–‡ä»¶æ‰«æ
# ============================================================================

class TestScanFile:
    """æµ‹è¯•å•æ–‡ä»¶æ‰«æåŠŸèƒ½"""

    def test_scan_file_detects_flow_number(self, tmp_path: Path):
        """æ‰«ææ–‡ä»¶åº”æ£€æµ‹åˆ°æµç¨‹ç¼–å·"""
        test_file = tmp_path / "test.py"
        token1 = _make_step_flow(1, "title")
        token2 = _make_step_flow(2, "lower")
        test_file.write_text(f"# {token1}: Initialize\n# {token2}: Configure\n")

        findings = scan_file(test_file, tmp_path)

        assert len(findings) == 2
        assert findings[0].match.lower() == "step 1"
        assert findings[1].match.lower() == "step 2"

    def test_scan_file_ignores_no_space_aliases(self, tmp_path: Path):
        """æ‰«ææ–‡ä»¶åº”å¿½ç•¥æ— ç©ºæ ¼çš„åˆ«å"""
        test_file = tmp_path / "test.py"
        alias1 = _make_alias(1, "lower")
        alias2 = _make_alias(2, "title")
        test_file.write_text(f"import {alias1}_logbook\nfrom {alias2}_module import X\n")

        findings = scan_file(test_file, tmp_path)

        assert len(findings) == 0

    def test_scan_file_mixed_content(self, tmp_path: Path):
        """æ‰«æåŒ…å«æ··åˆå†…å®¹çš„æ–‡ä»¶"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "title")
        alias = _make_alias(1, "lower")
        content = f"""# {flow_num}: Introduction (should match - has space)
# æ­¥éª¤ 1: ä»‹ç» (should NOT match - Chinese)
import {alias}_module  # should NOT match - no space (legacy alias)
# stepwise approach  # should NOT match - different word
"""
        test_file.write_text(content)

        findings = scan_file(test_file, tmp_path)

        # åªåº”åŒ¹é…ç¬¬ 1 è¡Œçš„å¸¦ç©ºæ ¼æµç¨‹ç¼–å·
        assert len(findings) == 1
        assert findings[0].line == 1
        assert findings[0].match.lower() == "step 1"

    def test_scan_file_multiple_on_same_line(self, tmp_path: Path):
        """æ‰«æåŒä¸€è¡Œæœ‰å¤šä¸ªåŒ¹é…çš„æƒ…å†µ"""
        test_file = tmp_path / "test.py"
        token1 = _make_step_flow(1, "title")
        token2 = _make_step_flow(2, "title")
        test_file.write_text(f"# {token1} and {token2}\n")

        findings = scan_file(test_file, tmp_path)

        assert len(findings) == 2
        assert findings[0].match.lower() == "step 1"
        assert findings[1].match.lower() == "step 2"


# ============================================================================
# Test: scan_directory ç›®å½•æ‰«æ
# ============================================================================

class TestScanDirectory:
    """æµ‹è¯•ç›®å½•æ‰«æåŠŸèƒ½"""

    def test_scan_directory_finds_violations(self, tmp_path: Path):
        """æ‰«æç›®å½•åº”æ‰¾åˆ°è¿è§„"""
        flow1 = _make_step_flow(1, "title")
        flow2 = _make_step_flow(2, "upper")

        py_file = tmp_path / "test.py"
        py_file.write_text(f"# {flow1}: Initialize\n")

        md_file = tmp_path / "README.md"
        md_file.write_text(f"# {flow2} Guide\n")

        result = scan_directory(tmp_path)

        assert result.files_scanned >= 2
        assert len(result.findings) == 2

    def test_scan_directory_excludes_dirs(self, tmp_path: Path):
        """æ‰«æç›®å½•åº”æ’é™¤ç‰¹å®šç›®å½•"""
        flow_num = _make_step_flow(1, "title")

        # åˆ›å»º __pycache__ ç›®å½•ï¼ˆåº”è¢«æ’é™¤ï¼‰
        cache_dir = tmp_path / "__pycache__"
        cache_dir.mkdir()
        cache_file = cache_dir / "test.py"
        cache_file.write_text(f"# {flow_num}: Cache\n")

        # åˆ›å»ºæ­£å¸¸ç›®å½•
        src_dir = tmp_path / "src"
        src_dir.mkdir()
        flow2 = _make_step_flow(2, "title")
        src_file = src_dir / "main.py"
        src_file.write_text(f"# {flow2}: Main\n")

        result = scan_directory(tmp_path)

        # åªåº”æ‰¾åˆ° src/main.py ä¸­çš„è¿è§„
        assert len(result.findings) == 1
        assert result.findings[0].file == "src/main.py"

    def test_scan_directory_excludes_libs(self, tmp_path: Path):
        """æ‰«æç›®å½•åº”æ’é™¤ libs ç›®å½•ï¼ˆä¸Šæ¸¸ä¾èµ–ï¼‰"""
        flow_num = _make_step_flow(1, "title")

        # åˆ›å»º libs ç›®å½•ï¼ˆåº”è¢«æ’é™¤ï¼‰
        libs_dir = tmp_path / "libs"
        libs_dir.mkdir()
        lib_file = libs_dir / "upstream.py"
        lib_file.write_text(f"# {flow_num}: Upstream code\n")

        result = scan_directory(tmp_path)

        # libs ç›®å½•åº”è¢«æ’é™¤ï¼Œä¸åº”æœ‰å‘ç°
        assert len(result.findings) == 0

    def test_scan_directory_respects_file_extensions(self, tmp_path: Path):
        """æ‰«æç›®å½•åº”åªæ‰«ææŒ‡å®šæ‰©å±•åçš„æ–‡ä»¶"""
        flow_num = _make_step_flow(1, "title")

        # åˆ›å»º .py æ–‡ä»¶ï¼ˆåº”è¢«æ‰«æï¼‰
        py_file = tmp_path / "test.py"
        py_file.write_text(f"# {flow_num}: Python\n")

        # åˆ›å»º .txt æ–‡ä»¶ï¼ˆä¸åº”è¢«æ‰«æï¼Œä¸åœ¨ SCAN_EXTENSIONS ä¸­ï¼‰
        txt_file = tmp_path / "test.txt"
        txt_file.write_text(f"# {flow_num}: Text\n")

        result = scan_directory(tmp_path)

        # åªåº”æ‰¾åˆ° .py æ–‡ä»¶ä¸­çš„è¿è§„
        assert len(result.findings) == 1
        assert result.findings[0].file == "test.py"


# ============================================================================
# Test: ç™½åå•è·¯å¾„
# ============================================================================

class TestAllowedPaths:
    """æµ‹è¯•ç™½åå•è·¯å¾„åŠŸèƒ½"""

    def test_allowed_path_exact_match(self):
        """ç²¾ç¡®åŒ¹é…çš„ç™½åå•è·¯å¾„"""
        # æ£€æŸ¥è„šæœ¬è‡ªèº«
        assert is_allowed_path("scripts/check_no_step_flow_numbers.py") is True
        # äº’è¡¥è„šæœ¬
        assert is_allowed_path("scripts/check_no_legacy_stage_aliases.py") is True
        # æµ‹è¯•æ–‡ä»¶
        assert is_allowed_path("scripts/tests/test_legacy_alias_checks.py") is True
        assert is_allowed_path("scripts/tests/test_step_flow_checks.py") is True
        # æ¶æ„æ–‡æ¡£
        assert is_allowed_path("docs/architecture/naming.md") is True

    def test_allowed_path_prefix_match(self):
        """å‰ç¼€åŒ¹é…çš„ç™½åå•è·¯å¾„ï¼ˆç›®å½•ï¼‰"""
        # .git/ æ˜¯ç›®å½•å‰ç¼€
        assert is_allowed_path(".git/objects/abc") is True
        assert is_allowed_path(".git/config") is True

    def test_not_allowed_path(self):
        """éç™½åå•è·¯å¾„"""
        assert is_allowed_path("src/main.py") is False
        assert is_allowed_path("scripts/other.py") is False
        assert is_allowed_path("docs/README.md") is False
        # docs/architecture/ ä¸‹å…¶ä»–æ–‡ä»¶ä¸åœ¨ç™½åå•ä¸­
        assert is_allowed_path("docs/architecture/README.md") is False

    def test_allowed_paths_matches_source_definition(self):
        """éªŒè¯æµ‹è¯•è¦†ç›–äº† ALLOWED_PATHS ä¸­çš„æ‰€æœ‰è·¯å¾„"""
        # éªŒè¯æ‰€æœ‰ç²¾ç¡®åŒ¹é…è·¯å¾„
        exact_paths = [p for p in ALLOWED_PATHS if not p.endswith("/")]
        for path in exact_paths:
            assert is_allowed_path(path) is True, f"Expected {path} to be allowed"

        # éªŒè¯æ‰€æœ‰ç›®å½•å‰ç¼€è·¯å¾„
        dir_prefixes = [p for p in ALLOWED_PATHS if p.endswith("/")]
        for prefix in dir_prefixes:
            test_path = prefix + "some/nested/file.txt"
            assert is_allowed_path(test_path) is True, f"Expected {test_path} to be allowed"

    def test_scan_skips_allowed_path(self, tmp_path: Path):
        """æ‰«ææ—¶åº”è·³è¿‡ç™½åå•ä¸­çš„æ–‡ä»¶"""
        # æ¨¡æ‹Ÿç™½åå•è·¯å¾„
        flow_num = _make_step_flow(1, "title")

        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_file = tmp_path / "test.py"
        test_file.write_text(f"# {flow_num}: Test\n")

        # ä½¿ç”¨ mock å°†è¯¥æ–‡ä»¶è·¯å¾„åŠ å…¥ç™½åå•
        with mock.patch(
            "check_no_step_flow_numbers.is_allowed_path",
            side_effect=lambda p: p == "test.py"
        ):
            findings = scan_file(test_file, tmp_path)

        # ç™½åå•æ–‡ä»¶ä¸åº”æœ‰å‘ç°
        assert len(findings) == 0


# ============================================================================
# Test: Finding ç±»
# ============================================================================

class TestFinding:
    """æµ‹è¯• Finding ç±»"""

    def test_finding_to_dict(self):
        """Finding åºåˆ—åŒ–"""
        flow_num = _make_step_flow(2, "title")
        f = Finding(
            file="test.py",
            line=5,
            column=3,
            match=flow_num,
            context=f"{flow_num}: context"
        )

        d = f.to_dict()
        assert d["file"] == "test.py"
        assert d["line"] == 5
        assert d["column"] == 3
        assert d["match"] == flow_num

    def test_finding_to_ci_format(self):
        """Finding CI æ ¼å¼è¾“å‡º"""
        flow_num = _make_step_flow(1, "title")
        f = Finding(file="test.py", line=10, column=5, match=flow_num)

        ci_output = f.to_ci_format()
        assert "test.py:10:5:" in ci_output
        assert flow_num in ci_output


# ============================================================================
# Test: è¾…åŠ©å‡½æ•°
# ============================================================================

class TestHelperFunctions:
    """æµ‹è¯•è¾…åŠ©å‡½æ•°"""

    @pytest.mark.parametrize("dir_name,expected", [
        ("__pycache__", True),
        (".git", True),
        ("node_modules", True),
        (".venv", True),
        ("venv", True),
        ("dist", True),
        ("build", True),
        ("libs", True),     # ä¸Šæ¸¸ä¾èµ–ç›®å½•
        ("patches", True),  # è¡¥ä¸ç›®å½•
        ("src", False),
        ("scripts", False),
    ])
    def test_should_exclude_dir(self, dir_name: str, expected: bool):
        """æµ‹è¯•ç›®å½•æ’é™¤è§„åˆ™"""
        assert should_exclude_dir(dir_name) == expected

    @pytest.mark.parametrize("file_name,expected", [
        ("package-lock.json", True),
        ("poetry.lock", True),
        ("test.min.js", True),
        ("style.min.css", True),
        ("file.pyc", True),
        ("image.png", True),
        ("test.py", False),
        ("README.md", False),
        ("config.json", False),
    ])
    def test_should_exclude_file(self, file_name: str, expected: bool):
        """æµ‹è¯•æ–‡ä»¶æ’é™¤è§„åˆ™"""
        assert should_exclude_file(file_name) == expected

    @pytest.mark.parametrize("file_path,expected", [
        (Path("test.py"), True),
        (Path("script.sh"), True),
        (Path("README.md"), True),
        (Path("config.yml"), True),
        (Path("config.yaml"), True),
        (Path("data.json"), True),
        (Path("schema.sql"), True),
        (Path("pyproject.toml"), True),
        (Path("Makefile"), True),
        (Path("test.txt"), False),
        (Path("image.png"), False),
        (Path("file.exe"), False),
    ])
    def test_should_scan_file(self, file_path: Path, expected: bool):
        """æµ‹è¯•æ–‡ä»¶æ‰«æè§„åˆ™"""
        assert should_scan_file(file_path) == expected


# ============================================================================
# Test: ScanResult ç±»
# ============================================================================

class TestScanResult:
    """æµ‹è¯• ScanResult ç±»"""

    def test_scan_result_default_values(self):
        """ScanResult é»˜è®¤å€¼"""
        result = ScanResult()
        assert result.findings == []
        assert result.files_scanned == 0
        assert result.files_skipped == 0


# ============================================================================
# Test: CLI å‚æ•°
# ============================================================================

class TestCLIArguments:
    """æµ‹è¯• CLI å‚æ•°è§£æå’Œè¡Œä¸º"""

    def test_fail_mode_default(self, tmp_path: Path):
        """é»˜è®¤æ¨¡å¼ï¼ˆ--failï¼‰ï¼šå‘ç°é—®é¢˜æ—¶é€€å‡ºç ä¸º 1"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "title")
        test_file.write_text(f"# {flow_num}: Test\n")

        with mock.patch("sys.argv", ["prog", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit) as exc_info:
                main()
            # å‘ç°é—®é¢˜æ—¶é€€å‡ºç ä¸º 1
            assert exc_info.value.code == 1

    def test_fail_mode_explicit(self, tmp_path: Path):
        """æ˜¾å¼ --fail æ¨¡å¼ï¼šå‘ç°é—®é¢˜æ—¶é€€å‡ºç ä¸º 1"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(2, "title")
        test_file.write_text(f"# {flow_num}: Test\n")

        with mock.patch("sys.argv", ["prog", "--fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit) as exc_info:
                main()
            assert exc_info.value.code == 1

    def test_no_fail_mode(self, tmp_path: Path):
        """--no-fail æ¨¡å¼ï¼šå‘ç°é—®é¢˜æ—¶é€€å‡ºç ä¸º 0"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(3, "title")
        test_file.write_text(f"# {flow_num}: Test\n")

        with mock.patch("sys.argv", ["prog", "--no-fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit) as exc_info:
                main()
            # --no-fail æ¨¡å¼ä¸‹é€€å‡ºç ä¸º 0
            assert exc_info.value.code == 0

    def test_no_fail_overrides_fail(self, tmp_path: Path):
        """--no-fail åº”è¯¥è¦†ç›– --fail"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "upper")
        test_file.write_text(f"# {flow_num}: Test\n")

        # åŒæ—¶æŒ‡å®š --fail å’Œ --no-failï¼Œ--no-fail åº”è¯¥ç”Ÿæ•ˆ
        with mock.patch("sys.argv", ["prog", "--fail", "--no-fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit) as exc_info:
                main()
            assert exc_info.value.code == 0

    def test_no_issues_exit_zero(self, tmp_path: Path):
        """æ— é—®é¢˜æ—¶ï¼Œä»»ä½•æ¨¡å¼ä¸‹é€€å‡ºç éƒ½ä¸º 0"""
        test_file = tmp_path / "test.py"
        # ä½¿ç”¨æ— ç©ºæ ¼åˆ«åï¼ˆä¸åº”è¢«æœ¬è„šæœ¬æ£€æµ‹ï¼‰
        alias = _make_alias(1, "lower")
        test_file.write_text(f"import {alias}_module\n# Clean code\n")

        # é»˜è®¤æ¨¡å¼
        with mock.patch("sys.argv", ["prog", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit) as exc_info:
                main()
            assert exc_info.value.code == 0

    def test_no_issues_exit_zero_with_fail(self, tmp_path: Path):
        """æ— é—®é¢˜æ—¶ï¼Œ--fail æ¨¡å¼ä¸‹é€€å‡ºç ä¹Ÿä¸º 0"""
        test_file = tmp_path / "test.py"
        test_file.write_text("# Clean code without any step flow numbers\n")

        with mock.patch("sys.argv", ["prog", "--fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit) as exc_info:
                main()
            assert exc_info.value.code == 0

    def test_json_output_mode(self, tmp_path: Path, capsys):
        """--json æ¨¡å¼åº”è¾“å‡º JSON æ ¼å¼"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "title")
        test_file.write_text(f"# {flow_num}: Test\n")

        with mock.patch("sys.argv", ["prog", "--json", "--no-fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit):
                main()

        captured = capsys.readouterr()
        output = json.loads(captured.out)
        assert "status" in output
        assert "findings" in output
        assert len(output["findings"]) == 1
        assert output["findings"][0]["match"].lower() == "step 1"

    def test_json_output_status_ok(self, tmp_path: Path, capsys):
        """--json æ¨¡å¼æ— é—®é¢˜æ—¶ status ä¸º ok"""
        test_file = tmp_path / "test.py"
        test_file.write_text("# Clean code\n")

        with mock.patch("sys.argv", ["prog", "--json", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit):
                main()

        captured = capsys.readouterr()
        output = json.loads(captured.out)
        assert output["status"] == "ok"
        assert output["errors"] == 0

    def test_json_output_status_error_fail_mode(self, tmp_path: Path, capsys):
        """--json --fail æ¨¡å¼æœ‰é—®é¢˜æ—¶ status ä¸º error"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "title")
        test_file.write_text(f"# {flow_num}: Test\n")

        with mock.patch("sys.argv", ["prog", "--json", "--fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit):
                main()

        captured = capsys.readouterr()
        output = json.loads(captured.out)
        assert output["status"] == "error"

    def test_json_output_status_warning_no_fail_mode(self, tmp_path: Path, capsys):
        """--json --no-fail æ¨¡å¼æœ‰é—®é¢˜æ—¶ status ä¸º warning"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "title")
        test_file.write_text(f"# {flow_num}: Test\n")

        with mock.patch("sys.argv", ["prog", "--json", "--no-fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit):
                main()

        captured = capsys.readouterr()
        output = json.loads(captured.out)
        assert output["status"] == "warning"

    def test_verbose_mode(self, tmp_path: Path, capsys):
        """--verbose æ¨¡å¼åº”è¾“å‡ºè¯¦ç»†ä¿¡æ¯"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(2, "title")
        test_file.write_text(f"# {flow_num}: Configuration phase\n")

        with mock.patch("sys.argv", ["prog", "--verbose", "--no-fail", "--root", str(tmp_path)]):
            with pytest.raises(SystemExit):
                main()

        captured = capsys.readouterr()
        # verbose æ¨¡å¼åº”åŒ…å«ä¸Šä¸‹æ–‡è¡Œ
        assert flow_num in captured.out or "Configuration" in captured.out


# ============================================================================
# Test: è¾¹ç•Œåœºæ™¯
# ============================================================================

class TestEdgeCases:
    """æµ‹è¯•è¾¹ç•Œåœºæ™¯"""

    def test_empty_file(self, tmp_path: Path):
        """ç©ºæ–‡ä»¶ä¸åº”æœ‰å‘ç°"""
        test_file = tmp_path / "empty.py"
        test_file.write_text("")

        findings = scan_file(test_file, tmp_path)
        assert len(findings) == 0

    def test_binary_like_content(self, tmp_path: Path):
        """åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡ä»¶åº”æ­£å¸¸å¤„ç†"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "title")
        # åŒ…å«ä¸€äº›ç‰¹æ®Šå­—ç¬¦
        test_file.write_text(f"# {flow_num}\n# \x00\x01\x02\n")

        findings = scan_file(test_file, tmp_path)
        assert len(findings) == 1

    def test_unicode_content(self, tmp_path: Path):
        """Unicode å†…å®¹åº”æ­£å¸¸å¤„ç†"""
        test_file = tmp_path / "test.py"
        flow_num = _make_step_flow(1, "title")
        test_file.write_text(f"# {flow_num}: åˆå§‹åŒ– ğŸš€\n# æ­¥éª¤ 1: ä¸­æ–‡ä¸åŒ¹é…\n")

        findings = scan_file(test_file, tmp_path)
        # åªåº”åŒ¹é…è‹±æ–‡çš„ Step 1
        assert len(findings) == 1
        assert findings[0].match.lower() == "step 1"

    def test_all_three_steps(self, tmp_path: Path):
        """åº”æ£€æµ‹æ‰€æœ‰ä¸‰ä¸ªæ­¥éª¤ç¼–å·"""
        test_file = tmp_path / "test.py"
        step1 = _make_step_flow(1, "title")
        step2 = _make_step_flow(2, "title")
        step3 = _make_step_flow(3, "title")
        test_file.write_text(f"# {step1}\n# {step2}\n# {step3}\n")

        findings = scan_file(test_file, tmp_path)
        assert len(findings) == 3
        matches = {f.match.lower() for f in findings}
        assert matches == {"step 1", "step 2", "step 3"}


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
